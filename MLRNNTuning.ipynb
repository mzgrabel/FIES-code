{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc4b5f5-cbe0-436b-a485-8a35cfc6e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4a49bf-42ed-45e3-8a6c-5a9d8e259705",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.read_csv(r'oos_validation_data.csv')  # validation set\n",
    "B = B.drop(B.iloc[:,36:68],axis = 1)\n",
    "\n",
    "C = pd.read_csv(r'development_data.csv') # unmasked set / training set\n",
    "C = C.drop(C.iloc[:,36:68],axis = 1)\n",
    "\n",
    "D = pd.read_csv(r'masked_forecasting_data.csv')  # masked set / test set\n",
    "D = D.drop(D.iloc[:,36:68],axis = 1)\n",
    "\n",
    "C = C.drop(columns=['eDWID'])\n",
    "X_train = C.loc[:, C.columns != 'FIES']\n",
    "y_train = C['FIES']\n",
    "D = D.drop(columns=['eDWID'])\n",
    "X_test = D.loc[:, D.columns != 'FIES']\n",
    "y_test = D['FIES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ab32b3-df62-4d4a-9cd4-6eccf87dd5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1) # reshape train data to 3 dim input\n",
    "\n",
    "def OptimalCutoff(pred, y_test):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame({\n",
    "        'fpr': pd.Series(fpr, index=i),\n",
    "        'tpr': pd.Series(tpr, index=i),\n",
    "        '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "        'tf': pd.Series(tpr - (1 - fpr), index=i),\n",
    "        'thresholds': pd.Series(thresholds, index=i)\n",
    "    })\n",
    "    \n",
    "    roc_t = roc.iloc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "      \n",
    "    return list(roc_t['thresholds'])\n",
    "\n",
    "def RNNTOP(units):\n",
    "\n",
    "    RNN = Sequential()\n",
    "            \n",
    "    RNN.add(LSTM(units = units, return_sequences = True, input_shape = (34, 1))) \n",
    "    RNN.add(Dropout(0.2))\n",
    "    \n",
    "    RNN.add(Dense(units = 1))\n",
    "    \n",
    "    RNN.compile(optimizer= 'adam', loss = 'mean_squared_error',  metrics=['accuracy'])\n",
    "    \n",
    "    history = RNN.fit(X_train_rnn, y_train, epochs = 25, batch_size = 64) # train\n",
    "    \n",
    "    preds = RNN.predict(X_test) \n",
    "    \n",
    "    c = OptimalCutoff(preds[:,0,0], y_test)\n",
    "    \n",
    "    y_pred = np.zeros(len(preds))\n",
    "    for i in range(len(preds)):\n",
    "        if preds[[i]][0][0] >= c:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "            \n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    return RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d6372-e1c9-4e01-b6db-7e1f356b7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a817d71-f3cb-4d13-a66b-ccf6f65e0d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f8d3e-559b-4f4b-b7bd-85d990a5bed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d4d96-9d98-4fb1-885f-1247b0c4207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a308a4-67b6-4504-bf61-2f7f94bcca40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:43:20.436983: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:20.437957: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:20.442710: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:20.455223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:20.475149: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:20.480804: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:20.496696: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.588925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.590380: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.595479: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.597142: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.598405: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.603261: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.608137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.608518: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.609472: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.614467: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.615715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.627415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.627762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.628176: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.628630: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.628831: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.629101: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.633194: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.633480: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.634681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.636555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.642369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.645936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.648155: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.650925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.654037: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.655046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.655445: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.656048: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.656365: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.658162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.658838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.660670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.660701: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.660961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.661633: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.663369: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.664170: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.665832: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.666431: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.666730: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.667627: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.668497: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.668888: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.669604: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.669923: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.671793: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.672057: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.672490: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.672486: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.672632: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.672881: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.673246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.673752: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.675757: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.676419: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.676722: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.676983: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.680168: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.680542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.685094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.686101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.687598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.688723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.688862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.691800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.692012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.693099: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.693716: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.694653: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.698853: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.698880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.699186: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.700391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.705314: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.705770: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.706116: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.708839: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.711144: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.711360: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.711526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.712202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.714549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.714579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.717822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.721868: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.724855: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.726379: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.727452: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.727529: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.727533: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.728420: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.728423: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.728799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.731468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.731866: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.732303: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.732566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.733448: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.735721: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.736543: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.737199: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.738223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.738551: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.740916: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.741176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.743212: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.743651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.744269: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.745380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.746476: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.746820: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.747136: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.747972: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.747977: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.748199: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.748916: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.749405: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.751034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.752376: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.752780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.754743: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.758299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.758620: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.759585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.760673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.763877: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.767716: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.768101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.770266: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.771733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.771999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.772662: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.773306: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.776514: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.777409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.778161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.778631: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.780789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.780792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.783079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.786479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.788547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.788554: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.791751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.792259: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.792712: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.792849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.793257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.794270: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.798475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.799046: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.802069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.802254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.802450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.803199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.805560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.811043: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.811591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.813625: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.814706: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.819742: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.820081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.820481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.822591: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.823219: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.823415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.825915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.827940: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.828141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.828581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.828882: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.830902: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.831871: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.832454: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.833738: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.834657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.835848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.836654: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.838242: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.842255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.842479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.842520: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.846368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.848044: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.849007: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.849116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.851678: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.853520: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.855117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.855135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.860859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.865853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.866704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.869845: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.872002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.872507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.872984: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.875638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.875983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.877627: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.877653: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.878041: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.878592: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.879009: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.883539: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.884280: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.886461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.888394: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.889794: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.890934: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.892219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.892459: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.892648: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.893392: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.893637: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.896313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.897333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.898187: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.898862: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.905208: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.906164: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.906188: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.906314: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.907025: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.907108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.907159: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.909982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.910683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.910967: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.911815: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.911821: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.911911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.912828: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.912828: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.913012: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.913084: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.913530: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.913613: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.913617: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.913706: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.913796: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.913895: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.914226: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.914867: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.915008: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.915579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.915767: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.915861: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.917895: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.917898: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.917900: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.917916: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.917965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.918037: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.919657: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.920229: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.921484: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.921960: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.923306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.923399: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.923764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.924422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.924435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.928190: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.929514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.929519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.929521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.929524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.929524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.930628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.930639: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.930668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.932739: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.933368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.936369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.937107: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.938582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.938763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.939149: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.939655: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.940605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.943294: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.944061: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.944883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.944884: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.948561: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.948564: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.948564: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.948566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.949047: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.949280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.949417: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.950561: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.950607: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.950609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.952067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.952497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.953127: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.954063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.954059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.954065: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.954068: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.954228: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.954885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.955165: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.956383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.957973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.958695: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.960741: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.964263: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.965085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.965450: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.965740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.965859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.966376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.967385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.968107: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.968113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.968131: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.968186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.968538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.969992: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.973773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.973781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.976665: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.981655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.982189: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:21.982280: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 20:43:21.982322: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.983199: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.987440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:21.987666: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:43:21.992950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:21.998393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:21.999401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 20:43:22.002255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:22.007872: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:22.008675: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:22.019174: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 20:43:22.022941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:22.024805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 20:43:22.039125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:43:24.942453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.942786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.943074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.944197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.945329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.945655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.945965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.946354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.947934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.948452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:24.958018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:25.005517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-06 20:43:32.417908: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.425001: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.433162: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.438388: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.480597: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.546704: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.553911: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.681659: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.723265: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.764049: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.783929: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.786238: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.852563: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/50\n",
      "Epoch 1/75\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:43:32.872518: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.907548: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.929452: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.948096: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.960680: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:32.975563: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:32.981728: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.034482: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.050203: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.092906: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.120321: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.129191: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.160059: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.172871: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.174905: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.207168: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.208591: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.214945: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.218258: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.244328: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.249047: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.251346: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.252369: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.257453: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.259169: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:43:33.292107: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.292107: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.297989: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.301321: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.301314: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.315284: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.318951: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.323479: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-06 20:43:33.359234: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.363328: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.366645: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-06 20:43:33.372324: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Epoch 1/75\n",
      "Epoch 1/50\n",
      "Epoch 1/100\n",
      "Epoch 1/50\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/25\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/75\n",
      "Epoch 1/25\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/100\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/75\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/50\n",
      "Epoch 1/25\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/25\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/75\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 52ms/step - accuracy: 0.7323 - loss: 0.196517\n",
      "\u001b[1m 2904/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:40\u001b[0m 64ms/step - accuracy: 0.7065 - loss: 0.1983Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 52ms/step - accuracy: 0.7206 - loss: 0.1964981\n",
      "\u001b[1m3590/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.7330 - loss: 0.1824Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 52ms/step - accuracy: 0.7469 - loss: 0.17881415\n",
      "\u001b[1m 3892/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:41\u001b[0m 48ms/step - accuracy: 0.7186 - loss: 0.1937Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 52ms/step - accuracy: 0.7387 - loss: 0.182402\n",
      "Epoch 2/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 53ms/step - accuracy: 0.7341 - loss: 0.181707\n",
      "\u001b[1m3416/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7158 - loss: 0.1988Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 55ms/step - accuracy: 0.7198 - loss: 0.195910\n",
      "Epoch 2/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 63ms/step - accuracy: 0.7242 - loss: 0.21339737━\u001b[0m \u001b[1m8:59\u001b[0m 51ms/step - accuracy: 0.6\n",
      "\u001b[1m 5557/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:24\u001b[0m 42ms/step - accuracy: 0.7120 - loss: 0.2084Epoch 2/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 64ms/step - accuracy: 0.7400 - loss: 0.18315993\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:10\u001b[0m 49ms/step\n",
      "\u001b[1m4253/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 54ms/step - accuracy: 0.7154 - loss: 0.2276Epoch 2/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 64ms/step - accuracy: 0.7119 - loss: 0.215866\n",
      "\u001b[1m3622/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7481 - loss: 0.1748Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 65ms/step - accuracy: 0.7150 - loss: 0.207216\n",
      "\u001b[1m 4835/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:24\u001b[0m 50ms/step - accuracy: 0.7092 - loss: 0.1959Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 66ms/step - accuracy: 0.7425 - loss: 0.1786171\n",
      "Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 65ms/step - accuracy: 0.7512 - loss: 0.1714959\n",
      "Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 65ms/step - accuracy: 0.7487 - loss: 0.174463\n",
      "\u001b[1m1077/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 52ms/step - accuracy: 0.8084 - loss: 0.1341Epoch 2/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 69ms/step - accuracy: 0.7436 - loss: 0.179938240m \u001b[1m4:\n",
      "Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 78ms/step - accuracy: 0.7385 - loss: 0.1892728\n",
      "\u001b[1m 5542/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:48\u001b[0m 51ms/step - accuracy: 0.7257 - loss: 0.1973Epoch 2/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 45ms/step - accuracy: 0.7483 - loss: 0.1795888\n",
      "\u001b[1m 6529/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:46\u001b[0m 50ms/step - accuracy: 0.7411 - loss: 0.1790Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 53ms/step - accuracy: 0.8040 - loss: 0.1365844052ms/step - accuracy: 0.8036 - loss: 0�━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[\n",
      "\u001b[1m3044/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.8052 - loss: 0.1353Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8101 - loss: 0.1326\n",
      "\u001b[1m3065/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 57ms/step - accuracy: 0.8053 - loss: 0.1353Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8142 - loss: 0.130179\n",
      "\u001b[1m6500/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m50s\u001b[0m 59ms/step - accuracy: 0.7516 - loss: 0.1729Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 53ms/step - accuracy: 0.7531 - loss: 0.170576\n",
      "\u001b[1m 5560/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10:40\u001b[0m 70ms/step - accuracy: 0.7368 - loss: 0.1794Epoch 2/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 53ms/step - accuracy: 0.8112 - loss: 0.132482\n",
      "\u001b[1m1878/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 66ms/step - accuracy: 0.8079 - loss: 0.1339Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 54ms/step - accuracy: 0.7496 - loss: 0.17239111[37m━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 66ms/step - accuracy: 0.8\n",
      "Epoch 2/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 55ms/step - accuracy: 0.7625 - loss: 0.1665217\n",
      "\u001b[1m 6499/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8:28\u001b[0m 62ms/step - accuracy: 0.7430 - loss: 0.1761Epoch 2/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m���━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 56ms/step - accuracy: 0.8087 - loss: 0.1331\n",
      "\u001b[1m 341/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 55ms/step - accuracy: 0.8120 - loss: 0.1296Epoch 3/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 55ms/step - accuracy: 0.7317 - loss: 0.2203588\n",
      "Epoch 2/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 54ms/step - accuracy: 0.7422 - loss: 0.1978\n",
      "\u001b[1m7038/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.7546 - loss: 0.1682Epoch 2/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 55ms/step - accuracy: 0.7572 - loss: 0.168719\n",
      "\u001b[1m 8142/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:28\u001b[0m 50ms/step - accuracy: 0.7493 - loss: 0.1735Epoch 2/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 56ms/step - accuracy: 0.7523 - loss: 0.1705816 - accuracy: 0.8047 - loss: 0\n",
      "Epoch 2/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 56ms/step - accuracy: 0.7527 - loss: 0.18118230\u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:22\u001b[0m 50ms/step - accuracy: 0.7498 - loss: 0\n",
      "\u001b[1m 8070/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 51ms/step - accuracy: 0.7487 - loss: 0.1756Epoch 2/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 56ms/step - accuracy: 0.7610 - loss: 0.16511757\n",
      "\u001b[1m6835/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.7570 - loss: 0.1713Epoch 2/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 57ms/step - accuracy: 0.8057 - loss: 0.135022\n",
      "\u001b[1m7267/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.7557 - loss: 0.1675Epoch 3/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 57ms/step - accuracy: 0.7561 - loss: 0.16728\n",
      "\u001b[1m 8326/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 50ms/step - accuracy: 0.7313 - loss: 0.1900Epoch 2/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 57ms/step - accuracy: 0.7563 - loss: 0.169749\n",
      "\u001b[1m 9825/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 44ms/step - accuracy: 0.7409 - loss: 0.1851Epoch 2/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━���━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 60ms/step - accuracy: 0.7594 - loss: 0.1695\n",
      "\u001b[1m 7214/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7:40\u001b[0m 61ms/step - accuracy: 0.7468 - loss: 0.1736Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 62ms/step - accuracy: 0.8058 - loss: 0.13499854\u001b[37m━━━\u001b[�━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 56ms/step - accurac\n",
      "\u001b[1m1056/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━���━━━━━━━━━━━━━\u001b[0m \u001b[1m5:40\u001b[0m 54ms/step - accuracy: 0.8044 - loss: 0.1345Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 65ms/step - accuracy: 0.8098 - loss: 0.132429\n",
      "Epoch 3/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 64ms/step - accuracy: 0.8054 - loss: 0.13551777\n",
      "Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 66ms/step - accuracy: 0.8061 - loss: 0.13468383 \u001b[1m23s\u001b[0m 69ms/step - accuracy: 0.8079 - loss\n",
      "\u001b[1m 689/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:16\u001b[0m 56ms/step - accuracy: 0.8108 - loss: 0.1315Epoch 3/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 67ms/step - accuracy: 0.8085 - loss: 0.1330088\n",
      "Epoch 3/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 63ms/step - accuracy: 0.8068 - loss: 0.1347784\n",
      "\u001b[1m2079/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 54ms/step - accuracy: 0.8167 - loss: 0.1275Epoch 3/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 67ms/step - accuracy: 0.7425 - loss: 0.181446\n",
      "\u001b[1m2183/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 52ms/step - accuracy: 0.8092 - loss: 0.1322Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 65ms/step - accuracy: 0.8086 - loss: 0.1334163:02\u001b[0m 56ms/step - accuracy: 0.8118 - loss:\n",
      "Epoch 3/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 69ms/step - accuracy: 0.8081 - loss: 0.1335768\n",
      "\u001b[1m11670/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 44ms/step - accuracy: 0.7484 - loss: 0.1792Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 71ms/step - accuracy: 0.7583 - loss: 0.1668942\u001b[0m 50ms/step - accuracy: 0.7\n",
      "Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8098 - loss: 0.131673\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8170 - loss: 0.127233\n",
      "\u001b[1m2968/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:04\u001b[0m 56ms/step - accuracy: 0.8053 - loss: 0.1340Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8154 - loss: 0.127878\n",
      "\u001b[1m3455/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8163 - loss: 0.1281Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 55ms/step - accuracy: 0.8163 - loss: 0.128087\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 76ms/step - accuracy: 0.8112 - loss: 0.131477\n",
      "\u001b[1m11811/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14:49\u001b[0m 51ms/step - accuracy: 0.7476 - loss: 0.1726Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.8156 - loss: 0.12787377[0m \u001b[1m2:30\u001b[0m 51ms/step - accuracy: 0.76\n",
      "Epoch 4/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 58ms/step - accuracy: 0.8127 - loss: 0.12977781�\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 64ms/step - accuracy: 0.8123 - \n",
      "Epoch 4/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 43ms/step - accuracy: 0.7602 - loss: 0.1708\n",
      "Epoch 2/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 44ms/step - accuracy: 0.7575 - loss: 0.172297[1m3:00\u001b[0m 55ms/step - accuracy: 0.8060 - los\n",
      "\u001b[1m12752/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:38\u001b[0m 50ms/step - accuracy: 0.7635 - loss: 0.1640Epoch 2/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 45ms/step - accuracy: 0.8136 - loss: 0.12962460━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 63ms/step - acc\n",
      "\u001b[1m12886/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:32\u001b[0m 51ms/step - accuracy: 0.7681 - loss: 0.1592Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 65ms/step - accuracy: 0.8137 - loss: 0.12983068\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 64ms/step - accuracy: 0.8151 - loss: 0.127970\n",
      "\u001b[1m3351/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8121 - loss: 0.1299Epoch 4/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 64ms/step - accuracy: 0.8123 - loss: 0.129545\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 64ms/step - accuracy: 0.8123 - loss: 0.13003966━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 53ms/ste\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 64ms/step - accuracy: 0.8127 - loss: 0.129766\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 65ms/step - accuracy: 0.8122 - loss: 0.129938\n",
      "Epoch 4/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 50ms/step - accuracy: 0.7544 - loss: 0.1716\n",
      "Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 0.12967272\n",
      "\u001b[1m14418/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7712 - loss: 0.1572Epoch 4/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 50ms/step - accuracy: 0.7561 - loss: 0.1715\n",
      "\u001b[1m10983/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4:11\u001b[0m 68ms/step - accuracy: 0.7622 - loss: 0.1635Epoch 2/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 50ms/step - accuracy: 0.7674 - loss: 0.1613\n",
      "\u001b[1m5403/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 55ms/step - accuracy: 0.8089 - loss: 0.1317Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━��━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 51ms/step - accuracy: 0.7622 - loss: 0.1648\n",
      "Epoch 2/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 51ms/step - accuracy: 0.7681 - loss: 0.1620\n",
      "\u001b[1m6138/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:08\u001b[0m 57ms/step - accuracy: 0.8090 - loss: 0.1325Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 51ms/step - accuracy: 0.7717 - loss: 0.1569\n",
      "\u001b[1m11196/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:56\u001b[0m 67ms/step - accuracy: 0.7628 - loss: 0.1631Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 51ms/step - accuracy: 0.7659 - loss: 0.165865\n",
      "Epoch 2/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 46ms/step - accuracy: 0.8106 - loss: 0.131172\n",
      "Epoch 3/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 70ms/step - accuracy: 0.8134 - loss: 0.129267\n",
      "\u001b[1m2785/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50s\u001b[0m 56ms/step - accuracy: 0.8176 - loss: 0.1265Epoch 4/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 52ms/step - accuracy: 0.7582 - loss: 0.1712\n",
      "Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 55ms/step - accuracy: 0.8136 - loss: 0.129228\n",
      "\u001b[1m 949/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 64ms/step - accuracy: 0.8172 - loss: 0.1275Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━��━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 54ms/step - accuracy: 0.8176 - loss: 0.12648\n",
      "Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 55ms/step - accuracy: 0.8192 - loss: 0.12567\n",
      "\u001b[1m6257/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:00\u001b[0m 55ms/step - accuracy: 0.8092 - loss: 0.1316Epoch 5/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 55ms/step - accuracy: 0.8107 - loss: 0.131230317m━━━━━━━━━━━━━━\u001b[0m \u001b\n",
      "Epoch 3/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 56ms/step - accuracy: 0.8176 - loss: 0.12643229\n",
      "Epoch 5/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 56ms/step - accuracy: 0.8094 - loss: 0.13222931\n",
      "\u001b[1m7209/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.8093 - loss: 0.1324Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 55ms/step - accuracy: 0.8075 - loss: 0.1328305\n",
      "\u001b[1m1544/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 63ms/step - accuracy: 0.8164 - loss: 0.1278Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 56ms/step - accuracy: 0.8143 - loss: 0.1286309\n",
      "Epoch 3/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 55ms/step - accuracy: 0.8091 - loss: 0.132169\n",
      "\u001b[1m1107/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 65ms/step - accuracy: 0.8149 - loss: 0.1276Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8149 - loss: 0.12832229\n",
      "Epoch 5/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 53ms/step - accuracy: 0.8093 - loss: 0.132432\n",
      "Epoch 3/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 55ms/step - accuracy: 0.8117 - loss: 0.13073225[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 62ms/step - accuracy: 0.8152 - loss�━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 61ms/step - accuracy: 0.8142 - lo\n",
      "\u001b[1m 1411/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━��━━━━━━━━━━━━\u001b[0m \u001b[1m11:48\u001b[0m 53ms/step - accuracy: 0.8095 - loss: 0.1319Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 54ms/step - accuracy: 0.8139 - loss: 0.1299299\n",
      "\u001b[1m1040/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 56ms/step - accuracy: 0.8169 - loss: 0.1273Epoch 3/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 55ms/step - accuracy: 0.8095 - loss: 0.1315323�━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:52\u001b[0m 51ms/step - accuracy: 0.8090 - loss: 0.132 - accuracy: 0.8178 - lo\n",
      "\u001b[1m1081/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 55ms/step - accuracy: 0.8169 - loss: 0.1273Epoch 3/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 55ms/step - accuracy: 0.8134 - loss: 0.1294112\n",
      "\u001b[1m12830/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:03\u001b[0m 66ms/step - accuracy: 0.7571 - loss: 0.1690Epoch 3/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 55ms/step - accuracy: 0.8112 - loss: 0.13126489\u001b[0m 63ms/step - accuracy: 0.8181 - loss: 0\n",
      "\u001b[1m2023/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 63ms/step - accuracy: 0.8145 - loss: 0.1286Epoch 3/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 58ms/step - accuracy: 0.8187 - loss: 0.126221\n",
      "Epoch 5/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 60ms/step - accuracy: 0.7693 - loss: 0.159112�━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:39\u001b[0m 66ms/step - accuracy: 0.7�━━━━\u001b[0m\u001b[37m━\n",
      "Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 78ms/step - accuracy: 0.8157 - loss: 0.128152\n",
      "\u001b[1m2537/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 63ms/step - accuracy: 0.8160 - loss: 0.1279Epoch 4/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m924s\u001b[0m 63ms/step - accuracy: 0.7691 - loss: 0.1598\n",
      "\u001b[1m1226/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:37\u001b[0m 55ms/step - accuracy: 0.8166 - loss: 0.1269Epoch 2/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 62ms/step - accuracy: 0.8143 - loss: 0.12831676\u001b[37m━━━━━\n",
      "Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 63ms/step - accuracy: 0.8181 - loss: 0.126416\n",
      "Epoch 5/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 63ms/step - accuracy: 0.8145 - loss: 0.1284661��━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 63ms/s\n",
      "Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 64ms/step - accuracy: 0.8157 - loss: 0.128002\n",
      "\u001b[1m 6226/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:24\u001b[0m 45ms/step - accuracy: 0.8121 - loss: 0.1302Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 63ms/step - accuracy: 0.8151 - loss: 0.1274161645ms/step - accuracy: 0.\n",
      "\u001b[1m 4107/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:14\u001b[0m 52ms/step - accuracy: 0.8101 - loss: 0.1310Epoch 5/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m973s\u001b[0m 66ms/step - accuracy: 0.7615 - loss: 0.1660\n",
      "Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 65ms/step - accuracy: 0.8155 - loss: 0.128104\n",
      "Epoch 5/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 67ms/step - accuracy: 0.7672 - loss: 0.1598\n",
      "Epoch 2/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 67ms/step - accuracy: 0.8092 - loss: 0.132501\n",
      "\u001b[1m3281/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:41\u001b[0m 54ms/step - accuracy: 0.8144 - loss: 0.1282Epoch 3/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 64ms/step - accuracy: 0.8155 - loss: 0.127562\n",
      "\u001b[1m  329/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:57\u001b[0m 67ms/step - accuracy: 0.8119 - loss: 0.1302Epoch 5/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 56ms/step - accuracy: 0.8183 - loss: 0.125921\n",
      "Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 57ms/step - accuracy: 0.8163 - loss: 0.12730\n",
      "Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1004s\u001b[0m 68ms/step - accuracy: 0.7709 - loss: 0.1578\n",
      "Epoch 2/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 50ms/step - accuracy: 0.8161 - loss: 0.12716401━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 49ms/step -━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - accuracy: 0.8199 - loss: 0.12[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:27\u001b[0m 54ms/step - accuracy: 0.8120 - loss: 0.17m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 56ms/step - accuracy: 0.8115 - loss: 0\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 58ms/step - accuracy: 0.8195 - loss: 0.125431\n",
      "\u001b[1m 565/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 61ms/step - accuracy: 0.8196 - loss: 0.1250Epoch 6/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 72ms/step - accuracy: 0.8148 - loss: 0.128411\n",
      "Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 57ms/step - accuracy: 0.8161 - loss: 0.127210\n",
      "\u001b[1m2932/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - accuracy: 0.8189 - loss: 0.1255Epoch 6/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 71ms/step - accuracy: 0.8102 - loss: 0.131604\n",
      "Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 57ms/step - accuracy: 0.8197 - loss: 0.125214\n",
      "\u001b[1m1066/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 58ms/step - accuracy: 0.8161 - loss: 0.1275Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 57ms/step - accuracy: 0.8189 - loss: 0.125618\n",
      "\u001b[1m4541/7353\u001b[0m \u001b[32m━━━━━━��━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 55ms/step - accuracy: 0.8168 - loss: 0.1273Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 47ms/step - accuracy: 0.8133 - loss: 0.129002\n",
      "\u001b[1m1816/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 64ms/step - accuracy: 0.8153 - loss: 0.1277Epoch 4/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 59ms/step - accuracy: 0.8162 - loss: 0.127062\n",
      "Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 58ms/step - accuracy: 0.8176 - loss: 0.126100\n",
      "Epoch 6/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 59ms/step - accuracy: 0.8147 - loss: 0.12740\n",
      "\u001b[1m 9843/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 44ms/step - accuracy: 0.8103 - loss: 0.1314Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 47ms/step - accuracy: 0.8129 - loss: 0.12947\n",
      "Epoch 4/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8191 - loss: 0.12529\n",
      "\u001b[1m6495/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m42s\u001b[0m 49ms/step - accuracy: 0.8122 - loss: 0.1300Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8163 - loss: 0.12738\n",
      "\u001b[1m3459/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8150 - loss: 0.1278Epoch 7/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 50ms/step - accuracy: 0.8145 - loss: 0.12815\n",
      "Epoch 4/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 48ms/step - accuracy: 0.8129 - loss: 0.12902\n",
      "\u001b[1m 5767/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:32\u001b[0m 37ms/step - accuracy: 0.8106 - loss: 0.1306Epoch 4/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 49ms/step - accuracy: 0.8169 - loss: 0.12729\n",
      "Epoch 4/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 58ms/step - accuracy: 0.8149 - loss: 0.127921\n",
      "\u001b[1m25324/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:11\u001b[0m 47ms/step - accuracy: 0.7683 - loss: 0.1617Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 57ms/step - accuracy: 0.8150 - loss: 0.12781\n",
      "\u001b[1m 699/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 45ms/step - accuracy: 0.8231 - loss: 0.1232Epoch 6/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 47ms/step - accuracy: 0.8150 - loss: 0.12817\n",
      "Epoch 4/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 47ms/step - accuracy: 0.8158 - loss: 0.12751\n",
      "Epoch 4/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 48ms/step - accuracy: 0.8126 - loss: 0.12961\n",
      "\u001b[1m 441/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:00\u001b[0m 43ms/step - accuracy: 0.8132 - loss: 0.1290Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8164 - loss: 0.12748\n",
      "Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 49ms/step - accuracy: 0.8152 - loss: 0.12780\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 47ms/step - accuracy: 0.8195 - loss: 0.12518\n",
      "Epoch 7/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 45ms/step - accuracy: 0.8171 - loss: 0.12692\n",
      "Epoch 7/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 47ms/step - accuracy: 0.8123 - loss: 0.12991\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 60ms/step - accuracy: 0.8153 - loss: 0.12761\n",
      "\u001b[1m4123/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 39ms/step - accuracy: 0.8134 - loss: 0.1290Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 53ms/step - accuracy: 0.8156 - loss: 0.12751\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 58ms/step - accuracy: 0.8159 - loss: 0.12740\n",
      "\u001b[1m 484/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:39\u001b[0m 41ms/step - accuracy: 0.8156 - loss: 0.1278Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 53ms/step - accuracy: 0.8156 - loss: 0.12741\n",
      "\u001b[1m1371/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 47ms/step - accuracy: 0.8201 - loss: 0.1249Epoch 6/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 37ms/step - accuracy: 0.8118 - loss: 0.1303\n",
      "\u001b[1m  24/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 52ms/step - accuracy: 0.8190 - loss: 0.1245Epoch 3/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 40ms/step - accuracy: 0.8141 - loss: 0.1287\n",
      "\u001b[1m5356/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 44ms/step - accuracy: 0.8139 - loss: 0.1294Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 51ms/step - accuracy: 0.8165 - loss: 0.127108\n",
      "\u001b[1m 559/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 41ms/step - accuracy: 0.8135 - loss: 0.1289Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8200 - loss: 0.12451\n",
      "\u001b[1m 6619/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:57\u001b[0m 37ms/step - accuracy: 0.8121 - loss: 0.1308Epoch 7/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1236s\u001b[0m 42ms/step - accuracy: 0.7760 - loss: 0.1545\n",
      "\u001b[1m1149/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 48ms/step - accuracy: 0.8204 - loss: 0.1244Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 46ms/step - accuracy: 0.8186 - loss: 0.125320\n",
      "Epoch 7/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 44ms/step - accuracy: 0.7746 - loss: 0.1552\n",
      "\u001b[1m1303/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 55ms/step - accuracy: 0.8164 - loss: 0.1266Epoch 2/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 44ms/step - accuracy: 0.7714 - loss: 0.1571\n",
      "Epoch 2/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 36ms/step - accuracy: 0.8191 - loss: 0.125728\n",
      "Epoch 5/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1297s\u001b[0m 44ms/step - accuracy: 0.7722 - loss: 0.1589\n",
      "\u001b[1m6845/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.8140 - loss: 0.1293Epoch 2/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 38ms/step - accuracy: 0.8150 - loss: 0.1285\n",
      "Epoch 3/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 38ms/step - accuracy: 0.8104 - loss: 0.1313\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 39ms/step - accuracy: 0.8126 - loss: 0.1299\n",
      "Epoch 3/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 38ms/step - accuracy: 0.8134 - loss: 0.1291\n",
      "\u001b[1m1754/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 57ms/step - accuracy: 0.8165 - loss: 0.1266Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 38ms/step - accuracy: 0.8131 - loss: 0.1298\n",
      "\u001b[1m2941/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 37ms/step - accuracy: 0.8115 - loss: 0.1297Epoch 3/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 45ms/step - accuracy: 0.8141 - loss: 0.1292\n",
      "\u001b[1m2591/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.8157 - loss: 0.1272Epoch 4/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 39ms/step - accuracy: 0.8111 - loss: 0.13040�━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:20\u001b[0m 28ms/step - accuracy: 0.8041\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 39ms/step - accuracy: 0.8109 - loss: 0.1309\n",
      "Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 49ms/step - accuracy: 0.8188 - loss: 0.125649\n",
      "\u001b[1m3635/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8203 - loss: 0.1246Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 38ms/step - accuracy: 0.8118 - loss: 0.1306\n",
      "Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8203 - loss: 0.124630\n",
      "\u001b[1m 3491/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:17\u001b[0m 28ms/step - accuracy: 0.8102 - loss: 0.1290Epoch 7/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 42ms/step - accuracy: 0.8137 - loss: 0.12896183━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0\n",
      "\u001b[1m5431/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 34ms/step - accuracy: 0.8140 - loss: 0.1283Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8206 - loss: 0.124381\n",
      "\u001b[1m3125/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.8175 - loss: 0.1263Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 43ms/step - accuracy: 0.8168 - loss: 0.126813\n",
      "Epoch 8/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 51ms/step - accuracy: 0.8156 - loss: 0.127391\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 51ms/step - accuracy: 0.8170 - loss: 0.126649\n",
      "\u001b[1m4753/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 41ms/step - accuracy: 0.8141 - loss: 0.1286Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 50ms/step - accuracy: 0.8174 - loss: 0.1264910\n",
      "\u001b[1m 626/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:05\u001b[0m 45ms/step - accuracy: 0.8112 - loss: 0.1291Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 51ms/step - accuracy: 0.8194 - loss: 0.125119\n",
      "\u001b[1m 2042/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:07\u001b[0m 29ms/step - accuracy: 0.8115 - loss: 0.1293Epoch 8/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8164 - loss: 0.1267793\n",
      "\u001b[1m12783/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:04\u001b[0m 33ms/step - accuracy: 0.8108 - loss: 0.1306Epoch 7/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 36ms/step - accuracy: 0.8137 - loss: 0.128660\n",
      "\u001b[1m5308/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 41ms/step - accuracy: 0.8142 - loss: 0.1286Epoch 5/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 56ms/step - accuracy: 0.8166 - loss: 0.126701\n",
      "\u001b[1m 3084/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:31\u001b[0m 29ms/step - accuracy: 0.8117 - loss: 0.1294Epoch 7/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 37ms/step - accuracy: 0.8110 - loss: 0.1308\n",
      "\u001b[1m 3300/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:28\u001b[0m 29ms/step - accuracy: 0.8146 - loss: 0.1281Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 34ms/step - accuracy: 0.8141 - loss: 0.128312\n",
      "\u001b[1m 189/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 50ms/step - accuracy: 0.8189 - loss: 0.1266Epoch 5/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 50ms/step - accuracy: 0.8157 - loss: 0.127291\n",
      "Epoch 7/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 57ms/step - accuracy: 0.8168 - loss: 0.1266322\n",
      "\u001b[1m6488/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m32s\u001b[0m 37ms/step - accuracy: 0.8186 - loss: 0.1259Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 51ms/step - accuracy: 0.8205 - loss: 0.1245621m 964/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 48ms/step - accuracy: 0.8137 - loss: \n",
      "Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 50ms/step - accuracy: 0.8161 - loss: 0.127179\n",
      "Epoch 7/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1449s\u001b[0m 49ms/step - accuracy: 0.7765 - loss: 0.1534\n",
      "\u001b[1m 4534/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 29ms/step - accuracy: 0.8165 - loss: 0.1276Epoch 2/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 51ms/step - accuracy: 0.8192 - loss: 0.124679\n",
      "\u001b[1m4808/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 46ms/step - accuracy: 0.8182 - loss: 0.1257Epoch 8/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 33ms/step - accuracy: 0.8109 - loss: 0.1306\n",
      "\u001b[1m12564/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:17\u001b[0m 36ms/step - accuracy: 0.8145 - loss: 0.1285Epoch 3/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 37ms/step - accuracy: 0.8160 - loss: 0.127292\n",
      "\u001b[1m 899/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 35ms/step - accuracy: 0.8150 - loss: 0.1271Epoch 5/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 37ms/step - accuracy: 0.8185 - loss: 0.125990\n",
      "Epoch 5/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 40ms/step - accuracy: 0.8153 - loss: 0.127731\n",
      "\u001b[1m7151/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8129 - loss: 0.1290Epoch 5/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 38ms/step - accuracy: 0.8130 - loss: 0.129091\n",
      "Epoch 5/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 41ms/step - accuracy: 0.8144 - loss: 0.1284928\n",
      "\u001b[1m 7158/29412\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:16\u001b[0m 28ms/step - accuracy: 0.8087 - loss: 0.1321Epoch 5/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 39ms/step - accuracy: 0.8102 - loss: 0.1316\n",
      "\u001b[1m 7715/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 30ms/step - accuracy: 0.8163 - loss: 0.1270Epoch 3/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 38ms/step - accuracy: 0.8173 - loss: 0.1261917\n",
      "Epoch 5/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 38ms/step - accuracy: 0.8154 - loss: 0.1280918\n",
      "Epoch 5/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 41ms/step - accuracy: 0.8163 - loss: 0.126401\n",
      "\u001b[1m1652/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 50ms/step - accuracy: 0.8173 - loss: 0.1265Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8191 - loss: 0.125221\n",
      "Epoch 8/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 51ms/step - accuracy: 0.8195 - loss: 0.1252119�━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - accuracy: 0.8152 - los\n",
      "\u001b[1m10348/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 29ms/step - accuracy: 0.8136 - loss: 0.1290Epoch 7/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 37ms/step - accuracy: 0.8118 - loss: 0.13072y: 0.8\n",
      "\u001b[1m2758/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.8179 - loss: 0.1261Epoch 3/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 44ms/step - accuracy: 0.8157 - loss: 0.127191\n",
      "\u001b[1m 8519/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 31ms/step - accuracy: 0.8163 - loss: 0.1270Epoch 5/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 36ms/step - accuracy: 0.8146 - loss: 0.1284\n",
      "\u001b[1m 460/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 44ms/step - accuracy: 0.8180 - loss: 0.1264Epoch 3/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 45ms/step - accuracy: 0.8182 - loss: 0.1257117 29ms/step - accuracy: 0.8\n",
      "\u001b[1m11752/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 29ms/step - accuracy: 0.8137 - loss: 0.1289Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 43ms/step - accuracy: 0.8179 - loss: 0.1261711�━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 52ms/step - accuracy: 0.8218 - los\n",
      "Epoch 9/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8156 - loss: 0.127211\n",
      "\u001b[1m 8253/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 29ms/step - accuracy: 0.8145 - loss: 0.1282Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 52ms/step - accuracy: 0.8199 - loss: 0.1249919\n",
      "\u001b[1m 908/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 40ms/step - accuracy: 0.8196 - loss: 0.1250Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8158 - loss: 0.126881\n",
      "\u001b[1m10612/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8:24\u001b[0m 27ms/step - accuracy: 0.8131 - loss: 0.1302Epoch 8/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 38ms/step - accuracy: 0.8205 - loss: 0.124571\n",
      "\u001b[1m1676/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 57ms/step - accuracy: 0.8159 - loss: 0.1268Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8184 - loss: 0.126316\n",
      "Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 48ms/step - accuracy: 0.8170 - loss: 0.126691917━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 51ms/\n",
      "Epoch 8/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 52ms/step - accuracy: 0.8216 - loss: 0.123901\n",
      "Epoch 9/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8169 - loss: 0.1267710━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:25\u001b[0m 39ms/step - accuracy: 0.8082 - lo\n",
      "Epoch 8/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 47ms/step - accuracy: 0.8169 - loss: 0.127131\n",
      "\u001b[1m 9674/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.1292Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8200 - loss: 0.124428\n",
      "\u001b[1m5639/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 39ms/step - accuracy: 0.8165 - loss: 0.1269Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 57ms/step - accuracy: 0.8173 - loss: 0.12640\n",
      "Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8212 - loss: 0.123611\n",
      "Epoch 9/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 45ms/step - accuracy: 0.8146 - loss: 0.1282818m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 29ms/step - accuracy: 0.8166\n",
      "\u001b[1m6369/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m44s\u001b[0m 45ms/step - accuracy: 0.8152 - loss: 0.1278Epoch 5/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 30ms/step - accuracy: 0.8138 - loss: 0.1289\n",
      "\u001b[1m3959/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 41ms/step - accuracy: 0.8177 - loss: 0.1257Epoch 4/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 35ms/step - accuracy: 0.8158 - loss: 0.127191\n",
      "Epoch 6/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 57ms/step - accuracy: 0.8162 - loss: 0.12679\n",
      "\u001b[1m 6885/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 33ms/step - accuracy: 0.8136 - loss: 0.1290Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 47ms/step - accuracy: 0.8193 - loss: 0.125291\n",
      "Epoch 9/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 45ms/step - accuracy: 0.8152 - loss: 0.127811\n",
      "\u001b[1m1730/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 53ms/step - accuracy: 0.8220 - loss: 0.1235Epoch 5/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 39ms/step - accuracy: 0.8163 - loss: 0.127071\n",
      "Epoch 6/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8198 - loss: 0.12529\n",
      "\u001b[1m 530/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 38ms/step - accuracy: 0.8176 - loss: 0.1274Epoch 8/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 31ms/step - accuracy: 0.8166 - loss: 0.1269\n",
      "Epoch 4/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 29ms/step - accuracy: 0.8179 - loss: 0.1265\n",
      "Epoch 4/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 29ms/step - accuracy: 0.8135 - loss: 0.1295\n",
      "\u001b[1m2899/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8187 - loss: 0.1255Epoch 4/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 37ms/step - accuracy: 0.8158 - loss: 0.127117\n",
      "\u001b[1m14395/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.8166 - loss: 0.1273Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 29ms/step - accuracy: 0.8164 - loss: 0.1275\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8172 - loss: 0.1266129\n",
      "\u001b[1m13991/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.8147 - loss: 0.1283Epoch 9/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 38ms/step - accuracy: 0.8191 - loss: 0.12559\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 29ms/step - accuracy: 0.8166 - loss: 0.1272\n",
      "Epoch 4/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 29ms/step - accuracy: 0.8165 - loss: 0.12781- loss: 0.12\n",
      "Epoch 4/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 36ms/step - accuracy: 0.8154 - loss: 0.127662\n",
      "Epoch 6/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 29ms/step - accuracy: 0.8142 - loss: 0.1284\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 29ms/step - accuracy: 0.8147 - loss: 0.1283\n",
      "\u001b[1m2625/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 50ms/step - accuracy: 0.8188 - loss: 0.1252Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8165 - loss: 0.12629\n",
      "\u001b[1m 494/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 54ms/step - accuracy: 0.8171 - loss: 0.1271Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 42ms/step - accuracy: 0.8185 - loss: 0.12569\n",
      "\u001b[1m3522/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.8203 - loss: 0.1243Epoch 10/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 29ms/step - accuracy: 0.8129 - loss: 0.1291\n",
      "\u001b[1m5065/7353\u001b[0m \u001b[32m━━━━━━━━━━━━��\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 39ms/step - accuracy: 0.8193 - loss: 0.1248Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 49ms/step - accuracy: 0.8179 - loss: 0.12605\n",
      "Epoch 9/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 52ms/step - accuracy: 0.8203 - loss: 0.12435\n",
      "\u001b[1m6920/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.8170 - loss: 0.1262Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 42ms/step - accuracy: 0.8167 - loss: 0.1268789━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:31\u001b[0m 28ms/step - accuracy: 0.8119 -\n",
      "\u001b[1m 408/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 58ms/step - accuracy: 0.8196 - loss: 0.1260Epoch 6/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 54ms/step - accuracy: 0.8175 - loss: 0.1261127\n",
      "\u001b[1m 1161/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:19\u001b[0m 37ms/step - accuracy: 0.8218 - loss: 0.1244Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 53ms/step - accuracy: 0.8217 - loss: 0.12360\n",
      "\u001b[1m 1766/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 37ms/step - accuracy: 0.8158 - loss: 0.1268Epoch 10/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 50ms/step - accuracy: 0.8168 - loss: 0.12636\n",
      "\u001b[1m  520/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:20\u001b[0m 52ms/step - accuracy: 0.8135 - loss: 0.1273Epoch 9/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 41ms/step - accuracy: 0.8170 - loss: 0.12629\n",
      "\u001b[1m 6678/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 39ms/step - accuracy: 0.8183 - loss: 0.1267Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 51ms/step - accuracy: 0.8185 - loss: 0.12570127━━━━- loss\n",
      "\u001b[1m3664/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 37ms/step - accuracy: 0.8176 - loss: 0.1263Epoch 9/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8193 - loss: 0.1249575\n",
      "\u001b[1m 825/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 60ms/step - accuracy: 0.8213 - loss: 0.1238Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 39ms/step - accuracy: 0.8162 - loss: 0.12705767[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:20\u001b[0m 39ms/s\n",
      "Epoch 6/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 40ms/step - accuracy: 0.8183 - loss: 0.1257177��━━\u001b[0m \u001b[1m9:26\u001b[0m 33ms/step - accuracy: 0.8099 - loss: \n",
      "Epoch 6/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 43ms/step - accuracy: 0.8194 - loss: 0.1251797[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 43ms/step - accuracy: 0.8169 - loss: 0.1263ms/step - accuracy: 0.8167 - loss:\n",
      "\u001b[1m5778/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 49ms/step - accuracy: 0.8189 - loss: 0.1254Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 54ms/step - accuracy: 0.8192 - loss: 0.1245727\n",
      "\u001b[1m1508/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 60ms/step - accuracy: 0.8180 - loss: 0.1261Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 63ms/step - accuracy: 0.8172 - loss: 0.1259777━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:07\u001b[0m 50ms/step - accuracy: 0.8189 ━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:24\u001b[0m 41ms/step - accuracy: \n",
      "Epoch 9/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 43ms/step - accuracy: 0.8196 - loss: 0.1248171\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 55ms/step - accuracy: 0.8196 - loss: 0.1244725739ms/step - accuracy: 0.8173 - ��━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 53ms/step - accuracy: 0.8153 - lo�━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:06\u001b[0m 40ms/step - accuracy: 0.81\n",
      "\u001b[1m 612/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:46\u001b[0m 51ms/step - accuracy: 0.8193 - loss: 0.1253Epoch 10/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 59ms/step - accuracy: 0.8201 - loss: 0.1245627━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accura\n",
      "Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 67ms/step - accuracy: 0.8168 - loss: 0.126472\n",
      "Epoch 9/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 47ms/step - accuracy: 0.8183 - loss: 0.12596971m16s\u001b[0m 52ms/step - accuracy: 0.8190 - loss: 0.1\n",
      "\u001b[1m 4604/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:40\u001b[0m 40ms/step - accuracy: 0.8159 - loss: 0.1277Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8177 - loss: 0.1254959u3\u001b[0m 40ms/step -\n",
      "Epoch 11/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 53ms/step - accuracy: 0.8190 - loss: 0.125372\n",
      "\u001b[1m2539/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 63ms/step - accuracy: 0.8175 - loss: 0.1257Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 62ms/step - accuracy: 0.8173 - loss: 0.12659\n",
      "\u001b[1m3330/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 53ms/step - accuracy: 0.8155 - loss: 0.1267Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 40ms/step - accuracy: 0.8172 - loss: 0.12659\n",
      "\u001b[1m2771/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50s\u001b[0m 56ms/step - accuracy: 0.8182 - loss: 0.1258Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 56ms/step - accuracy: 0.8174 - loss: 0.126031\n",
      "\u001b[1m2836/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 56ms/step - accuracy: 0.8182 - loss: 0.1258Epoch 10/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 60ms/step - accuracy: 0.8178 - loss: 0.12617\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 60ms/step - accuracy: 0.8210 - loss: 0.124079342\u001b[0m 59ms/step - accuracy: 0.8200 - loss: 0.124�\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.8138 - loss: 0.1287\u001b[\n",
      "Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8177 - loss: 0.12597\n",
      "Epoch 10/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 40ms/step - accuracy: 0.8138 - loss: 0.1288\n",
      "\u001b[1m 6629/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 40ms/step - accuracy: 0.8154 - loss: 0.1279Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 62ms/step - accuracy: 0.8231 - loss: 0.1227130\n",
      "Epoch 11/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 62ms/step - accuracy: 0.8178 - loss: 0.1257\n",
      "Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 57ms/step - accuracy: 0.8182 - loss: 0.1259755\n",
      "Epoch 10/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 39ms/step - accuracy: 0.8135 - loss: 0.12906s/step - accuracy: 0\n",
      "\u001b[1m 670/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 56ms/step - accuracy: 0.8168 - loss: 0.1270Epoch 4/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 47ms/step - accuracy: 0.8159 - loss: 0.127177\n",
      "\u001b[1m2246/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 50ms/step - accuracy: 0.8174 - loss: 0.1266Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 61ms/step - accuracy: 0.8213 - loss: 0.1235176- los��━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4:33\u001b[0m 39ms/st\n",
      "\u001b[1m12268/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:50\u001b[0m 45ms/step - accuracy: 0.8114 - loss: 0.1301Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 61ms/step - accuracy: 0.8210 - loss: 0.123867\n",
      "\u001b[1m4977/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 56ms/step - accuracy: 0.8169 - loss: 0.1269Epoch 11/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 41ms/step - accuracy: 0.8174 - loss: 0.12687717�━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:16\u001b[0m 32ms/step - accuracy: 0.8109�\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 41ms/step -\n",
      "Epoch 7/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 45ms/step - accuracy: 0.8174 - loss: 0.126467\n",
      "\u001b[1m26161/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:41\u001b[0m 31ms/step - accuracy: 0.8117 - loss: 0.1311Epoch 7/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 44ms/step - accuracy: 0.8184 - loss: 0.125677\n",
      "Epoch 7/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 58ms/step - accuracy: 0.8166 - loss: 0.12737767━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 39ms/step - accuracy: 0.8178 -��━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 56ms/step\n",
      "\u001b[1m6335/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m53s\u001b[0m 53ms/step - accuracy: 0.8162 - loss: 0.1266Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 56ms/step - accuracy: 0.8214 - loss: 0.123767\n",
      "\u001b[1m 2203/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:30\u001b[0m 50ms/step - accuracy: 0.8186 - loss: 0.1272Epoch 11/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 59ms/step - accuracy: 0.8161 - loss: 0.127667\n",
      "\u001b[1m 1959/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:31\u001b[0m 50ms/step - accuracy: 0.8151 - loss: 0.1278Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 49ms/step - accuracy: 0.8186 - loss: 0.1251829\n",
      "Epoch 12/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 61ms/step - accuracy: 0.8201 - loss: 0.1246521\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 78ms/step - accuracy: 0.8175 - loss: 0.125880\n",
      "\u001b[1m10487/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 40ms/step - accuracy: 0.8186 - loss: 0.1261Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 44ms/step - accuracy: 0.8159 - loss: 0.127317\n",
      "Epoch 7/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 44ms/step - accuracy: 0.8202 - loss: 0.124687\n",
      "Epoch 7/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 53ms/step - accuracy: 0.8163 - loss: 0.1266736━━━━━━━━━━━━\u001b[0m \u001b[1m5:08\u001b[0m 42ms/step - accuracy: 0.8423 - \n",
      "\u001b[1m 3175/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:55\u001b[0m 52ms/step - accuracy: 0.8181 - loss: 0.1273Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8177 - loss: 0.12596\n",
      "\u001b[1m28042/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m43s\u001b[0m 32ms/step - accuracy: 0.8117 - loss: 0.1310Epoch 11/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 62ms/step - accuracy: 0.8178 - loss: 0.12607\n",
      "\u001b[1m11435/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 40ms/step - accuracy: 0.8185 - loss: 0.1261Epoch 11/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 47ms/step - accuracy: 0.8117 - loss: 0.1300\n",
      "Epoch 4/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8179 - loss: 0.126177\n",
      "\u001b[1m13471/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:00\u001b[0m 49ms/step - accuracy: 0.8180 - loss: 0.1267Epoch 11/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 56ms/step - accuracy: 0.8170 - loss: 0.1268727\n",
      "\u001b[1m 263/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 60ms/step - accuracy: 0.8167 - loss: 0.1277Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 59ms/step - accuracy: 0.8200 - loss: 0.12417\n",
      "Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 77ms/step - accuracy: 0.8178 - loss: 0.12567\n",
      "\u001b[1m2303/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 45ms/step - accuracy: 0.8212 - loss: 0.1250Epoch 10/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m931s\u001b[0m 32ms/step - accuracy: 0.8142 - loss: 0.1293\n",
      "\u001b[1m2754/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 59ms/step - accuracy: 0.8180 - loss: 0.1260Epoch 3/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 47ms/step - accuracy: 0.8124 - loss: 0.1294\n",
      "\u001b[1m5935/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:09\u001b[0m 49ms/step - accuracy: 0.8185 - loss: 0.1257Epoch 4/25\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m944s\u001b[0m 32ms/step - accuracy: 0.8117 - loss: 0.13106ep - \n",
      "\u001b[1m27522/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:08\u001b[0m 36ms/step - accuracy: 0.8132 - loss: 0.1293Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 60ms/step - accuracy: 0.8223 - loss: 0.12327\n",
      "Epoch 12/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 59ms/step - accuracy: 0.8170 - loss: 0.126060\n",
      "Epoch 11/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 54ms/step - accuracy: 0.8188 - loss: 0.12547871m  87/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 56ms/step - accuracy: 0.8177 - los\n",
      "Epoch 7/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 32ms/step - accuracy: 0.8111 - loss: 0.1309\n",
      "Epoch 3/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 50ms/step - accuracy: 0.8205 - loss: 0.1244636━━━━━━━━━━━\u001b[0m \u001b[1m5:06\u001b[0m 58ms/step - accuracy: 0.8137 \n",
      "Epoch 8/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 49ms/step - accuracy: 0.8179 - loss: 0.12660━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 49ms/step - accuracy: 0.815�━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.8155 - loss: 0.\n",
      "\u001b[1m2815/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m51s\u001b[0m 59ms/step - accuracy: 0.8222 - loss: 0.1237Epoch 4/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 58ms/step - accuracy: 0.8180 - loss: 0.126076\n",
      "Epoch 12/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8175 - loss: 0.12632\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 42ms/step - accuracy: 0.8155 - loss: 0.1277\n",
      "\u001b[1m2802/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50s\u001b[0m 58ms/step - accuracy: 0.8217 - loss: 0.1231Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 55ms/step - accuracy: 0.8174 - loss: 0.126530\n",
      "Epoch 11/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━��━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 48ms/step - accuracy: 0.8187 - loss: 0.12559\n",
      "Epoch 7/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 39ms/step - accuracy: 0.8179 - loss: 0.1259\n",
      "Epoch 5/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 39ms/step - accuracy: 0.8164 - loss: 0.12719\n",
      "\u001b[1m1220/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 57ms/step - accuracy: 0.8237 - loss: 0.1223Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 60ms/step - accuracy: 0.8221 - loss: 0.123728\n",
      "\u001b[1m22369/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4:32\u001b[0m 39ms/step - accuracy: 0.8106 - loss: 0.1311Epoch 12/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 39ms/step - accuracy: 0.8185 - loss: 0.1262\n",
      "\u001b[1m1406/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 53ms/step - accuracy: 0.8188 - loss: 0.1252Epoch 5/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1088s\u001b[0m 37ms/step - accuracy: 0.8133 - loss: 0.12928\n",
      "Epoch 3/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 39ms/step - accuracy: 0.8181 - loss: 0.12601\n",
      "Epoch 5/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━��━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8211 - loss: 0.12376\n",
      "\u001b[1m3285/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 62ms/step - accuracy: 0.8159 - loss: 0.1270Epoch 12/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 58ms/step - accuracy: 0.8217 - loss: 0.123126\n",
      "\u001b[1m4812/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 45ms/step - accuracy: 0.8207 - loss: 0.1249Epoch 12/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 40ms/step - accuracy: 0.8147 - loss: 0.1282\n",
      "\u001b[1m1095/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 60ms/step - accuracy: 0.8164 - loss: 0.1266Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 40ms/step - accuracy: 0.8160 - loss: 0.1275\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 39ms/step - accuracy: 0.8156 - loss: 0.1274\n",
      "\u001b[1m  569/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:21\u001b[0m 40ms/step - accuracy: 0.8151 - loss: 0.1252Epoch 5/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 39ms/step - accuracy: 0.8156 - loss: 0.1281\n",
      "\u001b[1m1283/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 60ms/step - accuracy: 0.8166 - loss: 0.1265Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 48ms/step - accuracy: 0.8195 - loss: 0.1246303\n",
      "\u001b[1m3314/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 51ms/step - accuracy: 0.8185 - loss: 0.1254Epoch 13/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 55ms/step - accuracy: 0.8201 - loss: 0.12472726━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: step - accuracy: 0.8173 - loss: 0.12\n",
      "\u001b[1m 6564/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:36\u001b[0m 49ms/step - accuracy: 0.8153 - loss: 0.1279Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 59ms/step - accuracy: 0.8205 - loss: 0.12397978\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 45ms/step - ac━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:37\u001b[0m 38ms/step - accuracy: 0.8151 - l \n",
      "\u001b[1m   14/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:09\u001b[0m 29ms/step - accuracy: 0.8472 - loss: 0.1200Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8190 - loss: 0.12557728━━\u001b[0mms/step - accuracy: 0.8221 - loss: 0.12━━━━━\n",
      "Epoch 12/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 49ms/step - accuracy: 0.8170 - loss: 0.126827\n",
      "Epoch 8/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8172 - loss: 0.126428\n",
      "Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 62ms/step - accuracy: 0.8180 - loss: 0.126179\n",
      "\u001b[1m 2471/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:07\u001b[0m 40ms/step - accuracy: 0.8169 - loss: 0.1261Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 59ms/step - accuracy: 0.8205 - loss: 0.12407795a\n",
      "Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 76ms/step - accuracy: 0.8186 - loss: 0.125308\n",
      "\u001b[1m3247/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 60ms/step - accuracy: 0.8235 - loss: 0.1225Epoch 11/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 44ms/step - accuracy: 0.8181 - loss: 0.125788\n",
      "\u001b[1m 2248/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:35\u001b[0m 41ms/step - accuracy: 0.8167 - loss: 0.1267Epoch 8/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 45ms/step - accuracy: 0.8206 - loss: 0.12496738step - accuracy: 0.818\n",
      "\u001b[1m1937/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 49ms/step - accuracy: 0.8202 - loss: 0.1246Epoch 8/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 55ms/step - accuracy: 0.8183 - loss: 0.1253252\n",
      "Epoch 12/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 60ms/step - accuracy: 0.8233 - loss: 0.12266717\n",
      "Epoch 13/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 60ms/step - accuracy: 0.8179 - loss: 0.1256290\n",
      "\u001b[1m 2327/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:12\u001b[0m 40ms/step - accuracy: 0.8149 - loss: 0.1289Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 61ms/step - accuracy: 0.8180 - loss: 0.125927\n",
      "\u001b[1m 4811/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:28\u001b[0m 39ms/step - accuracy: 0.8183 - loss: 0.1264Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 43ms/step - accuracy: 0.8196 - loss: 0.124587\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 49ms/step - accuracy: 0.8165 - loss: 0.12685m \u001b[1m1:51\u001b[0m 55ms/step - accuracy: 0.8197 - loss: 0.1\n",
      "Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 80ms/step - accuracy: 0.8178 - loss: 0.1254884939s\u001b[0m 60ms/step - accuracy: 0.8227 - lo��━━━━━━━━\u001b[0m \u001b[1m4:53ep - accuracy: 0.8181 - loss��━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.8\n",
      "\u001b[1m 4773/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:34\u001b[0m 40ms/step - accuracy: 0.8180 - loss: 0.1259Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8200 - loss: 0.124767\n",
      "Epoch 14/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8212 - loss: 0.1237471\n",
      "\u001b[1m1054/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 62ms/step - accuracy: 0.8217 - loss: 0.1230Epoch 13/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 60ms/step - accuracy: 0.8226 - loss: 0.123027\n",
      "\u001b[1m1897/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 56ms/step - accuracy: 0.8197 - loss: 0.1241Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 55ms/step - accuracy: 0.8179 - loss: 0.125688\n",
      "\u001b[1m 335/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 58ms/step - accuracy: 0.8190 - loss: 0.1239Epoch 12/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 45ms/step - accuracy: 0.8160 - loss: 0.127078\n",
      "\u001b[1m 6853/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:48\u001b[0m 52ms/step - accuracy: 0.8121 - loss: 0.1299Epoch 8/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 51ms/step - accuracy: 0.8181 - loss: 0.125717\n",
      "Epoch 8/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 58ms/step - accuracy: 0.8157 - loss: 0.1275785\n",
      "Epoch 7/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 61ms/step - accuracy: 0.8161 - loss: 0.1270595\n",
      "\u001b[1m 4491/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:40\u001b[0m 39ms/step - accuracy: 0.8167 - loss: 0.1271Epoch 7/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8173 - loss: 0.1263792\n",
      "Epoch 9/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 52ms/step - accuracy: 0.8178 - loss: 0.126127\n",
      "\u001b[1m 5987/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:29\u001b[0m 52ms/step - accuracy: 0.8185 - loss: 0.1258Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 59ms/step - accuracy: 0.8206 - loss: 0.123858\n",
      "Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 58ms/step - accuracy: 0.8211 - loss: 0.123368\n",
      "Epoch 13/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 39ms/step - accuracy: 0.8108 - loss: 0.1310\n",
      "\u001b[1m 158/3677\u001b[0m \u001b[37m━━━━━━���━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 50ms/step - accuracy: 0.8211 - loss: 0.1232Epoch 3/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8190 - loss: 0.125478\n",
      "\u001b[1m7292/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8195 - loss: 0.1247Epoch 13/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 49ms/step - accuracy: 0.8195 - loss: 0.124787\n",
      "\u001b[1m2651/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 55ms/step - accuracy: 0.8223 - loss: 0.1228Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 48ms/step - accuracy: 0.8204 - loss: 0.124278\n",
      "Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8184 - loss: 0.1257227\n",
      "Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8203 - loss: 0.123977\n",
      "\u001b[1m1745/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 51ms/step - accuracy: 0.8232 - loss: 0.1226Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 45ms/step - accuracy: 0.8195 - loss: 0.125027\n",
      "Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 60ms/step - accuracy: 0.8185 - loss: 0.125377\n",
      "\u001b[1m1248/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10\u001b[0m 41ms/step - accuracy: 0.8203 - loss: 0.1257Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8223 - loss: 0.122977\n",
      "Epoch 14/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8189 - loss: 0.125278\n",
      "Epoch 13/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 44ms/step - accuracy: 0.8166 - loss: 0.1274\n",
      "\u001b[1m1449/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:01\u001b[0m 41ms/step - accuracy: 0.8200 - loss: 0.1258Epoch 5/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 43ms/step - accuracy: 0.8151 - loss: 0.1280\n",
      "Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 42ms/step - accuracy: 0.8197 - loss: 0.124579\n",
      "Epoch 15/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 45ms/step - accuracy: 0.8201 - loss: 0.124679\n",
      "\u001b[1m4816/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 41ms/step - accuracy: 0.8215 - loss: 0.1239Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 39ms/step - accuracy: 0.8173 - loss: 0.12629470�━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 47ms/step - accuracy: 0.8180 -\n",
      "\u001b[1m  40/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:16\u001b[0m 52ms/step - accuracy: 0.8308 - loss: 0.1217Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 54ms/step - accuracy: 0.8182 - loss: 0.125630\n",
      "Epoch 13/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8185 - loss: 0.1251120━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 37ms/step - accuracy: 0.8200 - lo\n",
      "\u001b[1m3464/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 40ms/step - accuracy: 0.8189 - loss: 0.1260Epoch 12/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 42ms/step - accuracy: 0.8177 - loss: 0.1264787�━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 44ms/step - accuracy: 0.8167 - lo\n",
      "Epoch 9/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 51ms/step - accuracy: 0.8184 - loss: 0.1256295��━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 40ms/step - accuracy: 0.8156 - loss: 0\n",
      "Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 51ms/step - accuracy: 0.8227 - loss: 0.1229285\n",
      "\u001b[1m 309/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 55ms/step - accuracy: 0.8223 - loss: 0.1238Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8207 - loss: 0.12385\n",
      "Epoch 14/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 43ms/step - accuracy: 0.8208 - loss: 0.12428070�━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:07\u001b[0m\n",
      "\u001b[1m1366/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 44ms/step - accuracy: 0.8213 - loss: 0.1235Epoch 9/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 50ms/step - accuracy: 0.8215 - loss: 0.1233287837m━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 51ms/st��━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 43ms/step - accuracy: ━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:50\u001b[0m 38ms/step - accura��━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 42ms/step -\n",
      "\u001b[1m1881/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 42ms/step - accuracy: 0.8208 - loss: 0.1238Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 51ms/step - accuracy: 0.8204 - loss: 0.123858\n",
      "\u001b[1m4108/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 42ms/step - accuracy: 0.8185 - loss: 0.1263Epoch 13/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8192 - loss: 0.1252287\n",
      "\u001b[1m 2111/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:56\u001b[0m 38ms/step - accuracy: 0.8178 - loss: 0.1268Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 42ms/step - accuracy: 0.8165 - loss: 0.126485��━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 62ms/step - accuracy: 0.8182 - l\n",
      "Epoch 9/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 42ms/step - accuracy: 0.8210 - loss: 0.124188\n",
      "\u001b[1m2685/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 46ms/step - accuracy: 0.8194 - loss: 0.1245Epoch 9/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 55ms/step - accuracy: 0.8188 - loss: 0.125278\n",
      "\u001b[1m2876/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.8237 - loss: 0.1223Epoch 13/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 36ms/step - accuracy: 0.8166 - loss: 0.1270\n",
      "Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 56ms/step - accuracy: 0.8196 - loss: 0.124970\n",
      "\u001b[1m5125/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 40ms/step - accuracy: 0.8194 - loss: 0.1246Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 50ms/step - accuracy: 0.8210 - loss: 0.123870\n",
      "Epoch 15/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 43ms/step - accuracy: 0.8132 - loss: 0.1292\n",
      "Epoch 5/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 46ms/step - accuracy: 0.8195 - loss: 0.124570\n",
      "Epoch 16/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 40ms/step - accuracy: 0.8177 - loss: 0.125960\n",
      "Epoch 9/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━���━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 52ms/step - accuracy: 0.8235 - loss: 0.1224\n",
      "\u001b[1m14065/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.8164 - loss: 0.1276Epoch 15/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8185 - loss: 0.125580\n",
      "Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 38ms/step - accuracy: 0.8187 - loss: 0.125886━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m42s\u001b[0m 43ms/s\n",
      "\u001b[1m14291/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.8185 - loss: 0.1257Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 40ms/step - accuracy: 0.8185 - loss: 0.125536\n",
      "\u001b[1m6731/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.8209 - loss: 0.1237Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 38ms/step - accuracy: 0.8189 - loss: 0.1256\n",
      "Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 45ms/step - accuracy: 0.8164 - loss: 0.1276\n",
      "\u001b[1m1549/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 60ms/step - accuracy: 0.8216 - loss: 0.1232Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 38ms/step - accuracy: 0.8185 - loss: 0.1257�━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 48ms/step - accuracy: 0.8171 - loss: 0.12\n",
      "\u001b[1m13892/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.8192 - loss: 0.1254Epoch 6/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 46ms/step - accuracy: 0.8163 - loss: 0.12707077━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8197 - loss: 0.1━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.81s:\n",
      "\u001b[1m14191/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.8168 - loss: 0.1269Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 40ms/step - accuracy: 0.8209 - loss: 0.12378\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8196 - loss: 0.1246922 \u001b[1m50s\u001b[0m 38m\n",
      "\u001b[1m7058/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8196 - loss: 0.1246Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 44ms/step - accuracy: 0.8189 - loss: 0.125360\n",
      "Epoch 9/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 38ms/step - accuracy: 0.8168 - loss: 0.12717\n",
      "\u001b[1m  650/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:14\u001b[0m 44ms/step - accuracy: 0.8254 - loss: 0.1229Epoch 6/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 57ms/step - accuracy: 0.8199 - loss: 0.1247303s/step - accuracy: 0.8216\n",
      "Epoch 14/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8178 - loss: 0.125730\n",
      "Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 48ms/step - accuracy: 0.8183 - loss: 0.12623\n",
      "\u001b[1m5187/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 42ms/step - accuracy: 0.8174 - loss: 0.1262Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8228 - loss: 0.122980\n",
      "Epoch 15/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 38ms/step - accuracy: 0.8191 - loss: 0.1254\n",
      "\u001b[1m14588/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8168 - loss: 0.1269Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 39ms/step - accuracy: 0.8168 - loss: 0.126930\n",
      "\u001b[1m1655/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 54ms/step - accuracy: 0.8223 - loss: 0.1231Epoch 6/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 43ms/step - accuracy: 0.8196 - loss: 0.124560\n",
      "\u001b[1m1660/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 54ms/step - accuracy: 0.8223 - loss: 0.1231Epoch 9/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 44ms/step - accuracy: 0.8182 - loss: 0.126370\n",
      "\u001b[1m14493/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.8155 - loss: 0.1279Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 65ms/step - accuracy: 0.8191 - loss: 0.125090\n",
      "\u001b[1m5013/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 49ms/step - accuracy: 0.8196 - loss: 0.1244Epoch 13/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 38ms/step - accuracy: 0.8155 - loss: 0.1279\n",
      "\u001b[1m19179/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6:23\u001b[0m 37ms/step - accuracy: 0.8159 - loss: 0.1274Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 38ms/step - accuracy: 0.8158 - loss: 0.1275\n",
      "\u001b[1m 571/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:08\u001b[0m 45ms/step - accuracy: 0.8185 - loss: 0.1260Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 46ms/step - accuracy: 0.8186 - loss: 0.1258\n",
      "\u001b[1m1737/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 54ms/step - accuracy: 0.8190 - loss: 0.1250Epoch 5/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8221 - loss: 0.12284\n",
      "Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 53ms/step - accuracy: 0.8201 - loss: 0.124326\n",
      "\u001b[1m11037/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10:26\u001b[0m 34ms/step - accuracy: 0.8137 - loss: 0.1301Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8185 - loss: 0.12548\n",
      "Epoch 15/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 59ms/step - accuracy: 0.8217 - loss: 0.1233246\n",
      "\u001b[1m  867/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:09\u001b[0m 44ms/step - accuracy: 0.8191 - loss: 0.1278Epoch 15/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 42ms/step - accuracy: 0.8177 - loss: 0.126167\n",
      "\u001b[1m 7232/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 40ms/step - accuracy: 0.8162 - loss: 0.1274Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 43ms/step - accuracy: 0.8199 - loss: 0.124397\n",
      "\u001b[1m4399/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 46ms/step - accuracy: 0.8194 - loss: 0.1246Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 57ms/step - accuracy: 0.8187 - loss: 0.12536727━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6:08\u001b[0m 39ms/step - accuracy: 0.8145 - loss: \n",
      "Epoch 14/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8171 - loss: 0.126527\n",
      "Epoch 10/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 46ms/step - accuracy: 0.8197 - loss: 0.124465\n",
      "\u001b[1m19924/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6:06\u001b[0m 39ms/step - accuracy: 0.8145 - loss: 0.1287Epoch 17/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 35ms/step - accuracy: 0.8192 - loss: 0.1254\n",
      "\u001b[1m 5158/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 36ms/step - accuracy: 0.8171 - loss: 0.1264Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 58ms/step - accuracy: 0.8184 - loss: 0.125727\n",
      "\u001b[1m20097/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5:59\u001b[0m 39ms/step - accuracy: 0.8145 - loss: 0.1287Epoch 15/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 54ms/step - accuracy: 0.8221 - loss: 0.123125\n",
      "\u001b[1m 583/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 58ms/step - accuracy: 0.8178 - loss: 0.1254Epoch 16/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 49ms/step - accuracy: 0.8200 - loss: 0.1242626\n",
      "\u001b[1m 1718/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:28\u001b[0m 53ms/step - accuracy: 0.8179 - loss: 0.1253Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 53ms/step - accuracy: 0.8187 - loss: 0.1251457�━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 48ms/step - accuracy: 0.8169 - loss:\n",
      "\u001b[1m 8573/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 40ms/step - accuracy: 0.8162 - loss: 0.1275Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 54ms/step - accuracy: 0.8232 - loss: 0.1224927\n",
      "Epoch 16/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 46ms/step - accuracy: 0.8210 - loss: 0.12415265m10:55\u001b[0m 53ms/step - accurac5\u001b[0m 46ms/step - a\n",
      "\u001b[1m 3800/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:09\u001b[0m 50ms/step - accuracy: 0.8160 - loss: 0.1271Epoch 10/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 53ms/step - accuracy: 0.8223 - loss: 0.123275\n",
      "\u001b[1m1406/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 55ms/step - accuracy: 0.8221 - loss: 0.1231Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 53ms/step - accuracy: 0.8191 - loss: 0.125165\n",
      "\u001b[1m5521/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 44ms/step - accuracy: 0.8178 - loss: 0.1258Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 58ms/step - accuracy: 0.8192 - loss: 0.1245625��━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:22\u001b[0m 56ms/step - accuracy: 0.8\n",
      "\u001b[1m1260/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 55ms/step - accuracy: 0.8194 - loss: 0.1250Epoch 15/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 47ms/step - accuracy: 0.8190 - loss: 0.1254656�\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 43ms/step - accur\n",
      "Epoch 10/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 46ms/step - accuracy: 0.8195 - loss: 0.1245705��━━━━━━━━━━━━━\u001b[0m \u001b[\n",
      "Epoch 10/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 44ms/step - accuracy: 0.8195 - loss: 0.125079\n",
      "\u001b[1m21869/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4:48\u001b[0m 38ms/step - accuracy: 0.8153 - loss: 0.1279Epoch 10/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 56ms/step - accuracy: 0.8192 - loss: 0.124727\n",
      "\u001b[1m3181/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.8186 - loss: 0.1249Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8230 - loss: 0.12246\n",
      "\u001b[1m5062/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 50ms/step - accuracy: 0.8218 - loss: 0.1229Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 55ms/step - accuracy: 0.8219 - loss: 0.12335\n",
      "Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 44ms/step - accuracy: 0.8179 - loss: 0.1258869��━━━━━━━━━━━━\u001b[0m \u001b[1m4:52\u001b[0m 47ms/step - accuracy: 0.8182 - los\n",
      "\u001b[1m3003/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m36s\u001b[0m 54ms/step - accuracy: 0.8221 - loss: 0.1231Epoch 11/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8196 - loss: 0.124645\n",
      "\u001b[1m1099/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:00\u001b[0m 48ms/step - accuracy: 0.8152 - loss: 0.1271Epoch 18/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8182 - loss: 0.125262\n",
      "\u001b[1m25586/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:26\u001b[0m 38ms/step - accuracy: 0.8160 - loss: 0.1273Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 66ms/step - accuracy: 0.8187 - loss: 0.12496\n",
      "\u001b[1m5837/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━��━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 47ms/step - accuracy: 0.8183 - loss: 0.1255Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 42ms/step - accuracy: 0.8217 - loss: 0.12366\n",
      "Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 58ms/step - accuracy: 0.8209 - loss: 0.123688\n",
      "Epoch 16/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 58ms/step - accuracy: 0.8184 - loss: 0.1252627\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:16\u001b[0m 52ms/step - accuracy: 0.8182 - loss: 0.━━━━━━━━━━━━━\u001b[0m \u001b[1m6:34\u001b[0m 43ms/step - accuracy: 0.8156 - loss5/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8184 - loss: 0.125\n",
      "Epoch 15/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8220 - loss: 0.1231\n",
      "\u001b[1m 6578/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:41\u001b[0m 49ms/step - accuracy: 0.8160 - loss: 0.1272Epoch 17/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 58ms/step - accuracy: 0.8196 - loss: 0.12519\n",
      "\u001b[1m10936/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 36ms/step - accuracy: 0.8170 - loss: 0.1265Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8197 - loss: 0.1248728━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 54ms/step - accuracy: 0.8250 - loss\n",
      "\u001b[1m2742/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 54ms/step - accuracy: 0.8239 - loss: 0.1222Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 55ms/step - accuracy: 0.8230 - loss: 0.122662\n",
      "Epoch 17/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 47ms/step - accuracy: 0.8182 - loss: 0.12567\n",
      "\u001b[1m 7245/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:17\u001b[0m 43ms/step - accuracy: 0.8172 - loss: 0.1269Epoch 10/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 50ms/step - accuracy: 0.8179 - loss: 0.12547\n",
      "Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 49ms/step - accuracy: 0.8214 - loss: 0.1232724\n",
      "\u001b[1m2090/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:40\u001b[0m 42ms/step - accuracy: 0.8175 - loss: 0.1259Epoch 10/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 39ms/step - accuracy: 0.8163 - loss: 0.12738�━━━\n",
      "\u001b[1m 9043/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:58\u001b[0m 42ms/step - accuracy: 0.8200 - loss: 0.1254Epoch 6/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 43ms/step - accuracy: 0.8165 - loss: 0.12686\n",
      "Epoch 6/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8235 - loss: 0.122497\n",
      "\u001b[1m3579/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 47ms/step - accuracy: 0.8199 - loss: 0.1249Epoch 17/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 42ms/step - accuracy: 0.8184 - loss: 0.12567\n",
      "Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 53ms/step - accuracy: 0.8189 - loss: 0.124996\n",
      "\u001b[1m1720/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 52ms/step - accuracy: 0.8233 - loss: 0.1226Epoch 17/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 41ms/step - accuracy: 0.8189 - loss: 0.12575\n",
      "\u001b[1m3835/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 46ms/step - accuracy: 0.8168 - loss: 0.1261Epoch 11/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 56ms/step - accuracy: 0.8173 - loss: 0.1263525\n",
      "Epoch 9/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 53ms/step - accuracy: 0.8179 - loss: 0.1259825━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 50ms/step - accuracy: 0.8225 - los\n",
      "\u001b[1m1457/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 50ms/step - accuracy: 0.8225 - loss: 0.1227Epoch 9/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 44ms/step - accuracy: 0.8200 - loss: 0.12442\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 59ms/step - accuracy: 0.8199 - loss: 0.124445\n",
      "Epoch 16/75\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1133s\u001b[0m 39ms/step - accuracy: 0.8161 - loss: 0.1273\n",
      "\u001b[1m 576/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 53ms/step - accuracy: 0.8212 - loss: 0.1233Epoch 4/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 36ms/step - accuracy: 0.8169 - loss: 0.12655[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:�━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:37\u001b[0m 42ms/step - accuracy: \n",
      "Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8196 - loss: 0.1244524\n",
      "Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8198 - loss: 0.124777\n",
      "\u001b[1m2169/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 52ms/step - accuracy: 0.8185 - loss: 0.1254Epoch 19/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8210 - loss: 0.123497\n",
      "\u001b[1m2173/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 52ms/step - accuracy: 0.8185 - loss: 0.1254Epoch 16/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 39ms/step - accuracy: 0.8132 - loss: 0.1294\n",
      "\u001b[1m4058/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 46ms/step - accuracy: 0.8204 - loss: 0.1239Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8198 - loss: 0.1246526\n",
      "\u001b[1m 1244/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:42\u001b[0m 43ms/step - accuracy: 0.8160 - loss: 0.1271Epoch 17/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 47ms/step - accuracy: 0.8209 - loss: 0.12387\n",
      "Epoch 10/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1159s\u001b[0m 39ms/step - accuracy: 0.8144 - loss: 0.12861740/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 55ms/st\n",
      "Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 52ms/step - accuracy: 0.8230 - loss: 0.1221714━━━━\u001b[0m \u001b[1m3:56\u001b[0m 50ms/step�━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:14\u001b[0m 41ms/step - accuracy: 0.8200 \n",
      "\u001b[1m28275/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - accuracy: 0.8155 - loss: 0.1278Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8229 - loss: 0.1227526�━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:49\u001b[0m 42ms/step - accuracy: 0.8176 - loss: 0━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 58ms/step - accuracy: 0.8204 - loss:\n",
      "\u001b[1m5068/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 42ms/step - accuracy: 0.8227 - loss: 0.1228Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 58ms/step - accuracy: 0.8222 - loss: 0.123155\n",
      "\u001b[1m12275/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:41\u001b[0m 42ms/step - accuracy: 0.8200 - loss: 0.1254Epoch 17/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8232 - loss: 0.12237666�━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m\n",
      "\u001b[1m6719/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 47ms/step - accuracy: 0.8206 - loss: 0.1244Epoch 18/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8187 - loss: 0.1252628\n",
      "Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 64ms/step - accuracy: 0.8186 - loss: 0.125076\n",
      "Epoch 15/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1147s\u001b[0m 39ms/step - accuracy: 0.8156 - loss: 0.1278[1m21s\u001b[0m 47ms/st\n",
      "\u001b[1m11216/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 42ms/step - accuracy: 0.8162 - loss: 0.1271Epoch 4/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 41ms/step - accuracy: 0.8194 - loss: 0.125326\n",
      "\u001b[1m3562/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 45ms/step - accuracy: 0.8202 - loss: 0.1253Epoch 7/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 45ms/step - accuracy: 0.8154 - loss: 0.1278\n",
      "Epoch 6/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 47ms/step - accuracy: 0.8207 - loss: 0.1243982\n",
      "\u001b[1m6449/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m38s\u001b[0m 43ms/step - accuracy: 0.8226 - loss: 0.1229Epoch 11/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 47ms/step - accuracy: 0.8176 - loss: 0.125768\n",
      "\u001b[1m3754/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 48ms/step - accuracy: 0.8180 - loss: 0.1262Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 58ms/step - accuracy: 0.8198 - loss: 0.124528\n",
      "\u001b[1m4050/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 45ms/step - accuracy: 0.8201 - loss: 0.1253Epoch 16/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 42ms/step - accuracy: 0.8200 - loss: 0.1251\n",
      "Epoch 7/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 44ms/step - accuracy: 0.8187 - loss: 0.125048\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 42ms/step - accuracy: 0.8202 - loss: 0.1248\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 58ms/step - accuracy: 0.8203 - loss: 0.124658\n",
      "Epoch 17/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8231 - loss: 0.12257428\n",
      "\u001b[1m2847/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 58ms/step - accuracy: 0.8207 - loss: 0.1242Epoch 18/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 43ms/step - accuracy: 0.8179 - loss: 0.125778\n",
      "Epoch 12/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8195 - loss: 0.12447828━━━━━━━━━━━\u001b[0m \u001b[1m5:34\u001b[0m 49ms/step - accurac\n",
      "\u001b[1m 3921/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:59\u001b[0m 42ms/step - accuracy: 0.8168 - loss: 0.1261Epoch 18/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 43ms/step - accuracy: 0.8225 - loss: 0.122946\n",
      "\u001b[1m 4767/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━���━━━━━━━━━━━\u001b[0m \u001b[1m7:37\u001b[0m 46ms/step - accuracy: 0.8186 - loss: 0.1256Epoch 12/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 42ms/step - accuracy: 0.8199 - loss: 0.12542\n",
      "Epoch 7/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 46ms/step - accuracy: 0.8206 - loss: 0.123824\n",
      "\u001b[1m 3004/29412\u001b[0m \u001b[32m���━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:53\u001b[0m 43ms/step - accuracy: 0.8155 - loss: 0.1280Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 42ms/step - accuracy: 0.8176 - loss: 0.1262\n",
      "\u001b[1m 537/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 55ms/step - accuracy: 0.8235 - loss: 0.1219Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 49ms/step - accuracy: 0.8217 - loss: 0.123947\n",
      "\u001b[1m 241/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 55ms/step - accuracy: 0.8204 - loss: 0.1241Epoch 20/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━��━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 58ms/step - accuracy: 0.8205 - loss: 0.1243628━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 60ms/step - accuracy: 0.8228 - loss\n",
      "\u001b[1m 5120/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:43\u001b[0m 42ms/step - accuracy: 0.8160 - loss: 0.1270Epoch 17/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 45ms/step - accuracy: 0.8161 - loss: 0.12736step - accuracy: 0.8205 - loss: 0.\n",
      "\u001b[1m5560/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 51ms/step - accuracy: 0.8210 - loss: 0.1241Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 37ms/step - accuracy: 0.8190 - loss: 0.1249\n",
      "\u001b[1m2140/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 55ms/step - accuracy: 0.8250 - loss: 0.1220Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8198 - loss: 0.124122\n",
      "Epoch 16/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 42ms/step - accuracy: 0.8167 - loss: 0.12699\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 56ms/step - accuracy: 0.8216 - loss: 0.123127\n",
      "\u001b[1m13782/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.8163 - loss: 0.1271Epoch 17/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 42ms/step - accuracy: 0.8173 - loss: 0.1266\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 54ms/step - accuracy: 0.8203 - loss: 0.124067\n",
      "\u001b[1m6101/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - accuracy: 0.8171 - loss: 0.1261Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8216 - loss: 0.12293728\n",
      "\u001b[1m1158/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 59ms/step - accuracy: 0.8191 - loss: 0.1252Epoch 18/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 42ms/step - accuracy: 0.8163 - loss: 0.1271\n",
      "Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8239 - loss: 0.122246\n",
      "Epoch 19/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 43ms/step - accuracy: 0.8197 - loss: 0.12532653 - accuracy: 0.82\n",
      "\u001b[1m2971/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 48ms/step - accuracy: 0.8219 - loss: 0.1238Epoch 12/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 49ms/step - accuracy: 0.8172 - loss: 0.125946\n",
      "\u001b[1m 712/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 53ms/step - accuracy: 0.8183 - loss: 0.1256Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 59ms/step - accuracy: 0.8226 - loss: 0.12256686m5632/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1\n",
      "\u001b[1m1889/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 56ms/step - accuracy: 0.8197 - loss: 0.1245Epoch 18/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 42ms/step - accuracy: 0.8174 - loss: 0.125947\n",
      "Epoch 12/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 50ms/step - accuracy: 0.8209 - loss: 0.124086\n",
      "Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8195 - loss: 0.1249467\n",
      "Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 55ms/step - accuracy: 0.8247 - loss: 0.122126\n",
      "\u001b[1m 874/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 58ms/step - accuracy: 0.8208 - loss: 0.1233Epoch 19/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 48ms/step - accuracy: 0.8180 - loss: 0.12605626━━━━━━━━━━━\u001b[0m \u001b[1m16:13\u001b[0m 42ms/step - accuracy: 0\n",
      "\u001b[1m 6681/29412\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:44\u001b[0m 42ms/step - accuracy: 0.8148 - loss: 0.1286Epoch 11/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 45ms/step - accuracy: 0.8205 - loss: 0.1241264 - accuracy: 0.8134 - loss281 - loss\n",
      "\u001b[1m3292/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 64ms/step - accuracy: 0.8204 - loss: 0.1241Epoch 11/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1080s\u001b[0m 37ms/step - accuracy: 0.8138 - loss: 0.1295\n",
      "\u001b[1m3779/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 41ms/step - accuracy: 0.8215 - loss: 0.1234Epoch 4/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 64ms/step - accuracy: 0.8204 - loss: 0.124127\n",
      "Epoch 16/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 50ms/step - accuracy: 0.8188 - loss: 0.1253m2:25\u001b[0m 45ms/step - accuracy: 0.8198 - loss: 0.1\n",
      "Epoch 6/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 53ms/step - accuracy: 0.8230 - loss: 0.122646\n",
      "Epoch 19/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 42ms/step - accuracy: 0.8222 - loss: 0.12315828[0m 47ms/step - accuracy: 0.8168 - ��━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:05\u001b[0m 41ms/step \n",
      "Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8199 - loss: 0.124446\n",
      "\u001b[1m 4123/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:34\u001b[0m 43ms/step - accuracy: 0.8171 - loss: 0.1258Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8217 - loss: 0.123656460m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:41\u001b[0m 43ms/step - ac\n",
      "Epoch 21/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 55ms/step - accuracy: 0.8191 - loss: 0.125666\n",
      "\u001b[1m 4926/14706\u001b[0m \u001b[32m━━━━��━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:20\u001b[0m 45ms/step - accuracy: 0.8137 - loss: 0.1282Epoch 10/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 54ms/step - accuracy: 0.8177 - loss: 0.125926\n",
      "\u001b[1m1390/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 54ms/step - accuracy: 0.8209 - loss: 0.1236Epoch 10/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 56ms/step - accuracy: 0.8196 - loss: 0.12468988[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m�━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m23s\u001b[0m 60ms/step - accuracy: 0.8193 - los\n",
      "Epoch 17/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 59ms/step - accuracy: 0.8194 - loss: 0.1250568844\n",
      "\u001b[1m2679/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 49ms/step - accuracy: 0.8174 - loss: 0.1255Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8196 - loss: 0.12456667\u001b[0m\u001b[37m━━━\n",
      "\u001b[1m6481/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - accuracy: 0.8172 - loss: 0.1259Epoch 19/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8230 - loss: 0.12256669\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:m 55ms/s\n",
      "\u001b[1m1820/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 64ms/step - accuracy: 0.8200 - loss: 0.1242Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 58ms/step - accuracy: 0.8200 - loss: 0.12402623[37m━━\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - acc\n",
      "Epoch 18/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8234 - loss: 0.12232626\n",
      "\u001b[1m7008/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.8219 - loss: 0.1237Epoch 20/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 44ms/step - accuracy: 0.8192 - loss: 0.12464786━━━━━━━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 55m\n",
      "\u001b[1m7128/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.8219 - loss: 0.1237Epoch 12/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 41ms/step - accuracy: 0.8218 - loss: 0.1233283\n",
      "\u001b[1m1882/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:40\u001b[0m 51ms/step - accuracy: 0.8154 - loss: 0.1267Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 47ms/step - accuracy: 0.8219 - loss: 0.123726\n",
      "\u001b[1m3066/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 46ms/step - accuracy: 0.8184 - loss: 0.1256Epoch 12/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 47ms/step - accuracy: 0.8174 - loss: 0.125887\n",
      "\u001b[1m 281/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 54ms/step - accuracy: 0.8239 - loss: 0.1223Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 55ms/step - accuracy: 0.8219 - loss: 0.122867\n",
      "\u001b[1m 490/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 52ms/step - accuracy: 0.8204 - loss: 0.1230Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 55ms/step - accuracy: 0.8202 - loss: 0.123957\n",
      "\u001b[1m 4286/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:39\u001b[0m 37ms/step - accuracy: 0.8128 - loss: 0.1291Epoch 17/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 45ms/step - accuracy: 0.8193 - loss: 0.1251684[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 41ms/step - accuracy: 0.8200 - loss:\n",
      "\u001b[1m 397/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 52ms/step - accuracy: 0.8243 - loss: 0.1221Epoch 13/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8200 - loss: 0.12416727\n",
      "Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8238 - loss: 0.12172728\n",
      "\u001b[1m12010/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:03\u001b[0m 46ms/step - accuracy: 0.8179 - loss: 0.1260Epoch 20/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 58ms/step - accuracy: 0.8238 - loss: 0.12216\n",
      "\u001b[1m  77/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 51ms/step - accuracy: 0.8223 - loss: 0.1261Epoch 19/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━��━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 46ms/step - accuracy: 0.8207 - loss: 0.12398\n",
      "\u001b[1m3575/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 43ms/step - accuracy: 0.8206 - loss: 0.1239Epoch 12/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 52ms/step - accuracy: 0.8236 - loss: 0.12206767m2630/3677\u001b[0m \u001b[32m━━━━━\n",
      "Epoch 20/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8196 - loss: 0.124667\n",
      "\u001b[1m3375/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 54ms/step - accuracy: 0.8198 - loss: 0.1252Epoch 20/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 37ms/step - accuracy: 0.8180 - loss: 0.1263\n",
      "\u001b[1m 6512/29412\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:09\u001b[0m 37ms/step - accuracy: 0.8135 - loss: 0.1288Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 48ms/step - accuracy: 0.8221 - loss: 0.123568587m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 44ms/step - accuracy: 0.8202 - lo677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0\n",
      "Epoch 22/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 65ms/step - accuracy: 0.8202 - loss: 0.124228\n",
      "\u001b[1m 8319/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:24\u001b[0m 41ms/step - accuracy: 0.8164 - loss: 0.1260Epoch 17/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 42ms/step - accuracy: 0.8204 - loss: 0.124727\n",
      "Epoch 13/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 41ms/step - accuracy: 0.8166 - loss: 0.1268\n",
      "Epoch 7/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8206 - loss: 0.1242484\n",
      "\u001b[1m13202/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m11:04\u001b[0m 41ms/step - accuracy: 0.8159 - loss: 0.1273Epoch 18/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 42ms/step - accuracy: 0.8197 - loss: 0.1249663\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 46ms/step - accuracy: 0.8179 - loss: 0.1260\n",
      "\u001b[1m5908/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:02\u001b[0m 43ms/step - accuracy: 0.8207 - loss: 0.1238Epoch 7/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 58ms/step - accuracy: 0.8197 - loss: 0.1246274━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m10:39\u001b[0m 41ms/step - accuracy: 0.8159 - lo\n",
      "\u001b[1m11573/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 42ms/step - accuracy: 0.8201 - loss: 0.1251Epoch 19/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8199 - loss: 0.1246\n",
      "Epoch 20/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 49ms/step - accuracy: 0.8184 - loss: 0.1252276\n",
      "\u001b[1m2407/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 44ms/step - accuracy: 0.8174 - loss: 0.1259Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8221 - loss: 0.122668\n",
      "\u001b[1m3159/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - accuracy: 0.8191 - loss: 0.1242Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 52ms/step - accuracy: 0.8238 - loss: 0.12228858━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m48s\u001b[0m 55ms/step - accuracy: 0\n",
      "\u001b[1m 9506/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:37\u001b[0m 42ms/step - accuracy: 0.8173 - loss: 0.1265Epoch 21/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 50ms/step - accuracy: 0.8216 - loss: 0.123558\n",
      "\u001b[1m11493/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 44ms/step - accuracy: 0.8148 - loss: 0.1279Epoch 12/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 42ms/step - accuracy: 0.8219 - loss: 0.1231726\n",
      "Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 56ms/step - accuracy: 0.8196 - loss: 0.124257\n",
      "Epoch 19/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 46ms/step - accuracy: 0.8186 - loss: 0.12567856�━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:02\u001b[0m 42ms/step - accuracy: 0.82\n",
      "\u001b[1m15854/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9:17\u001b[0m 41ms/step - accuracy: 0.8147 - loss: 0.1286Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8232 - loss: 0.122568\n",
      "\u001b[1m1704/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 46ms/step - accuracy: 0.8226 - loss: 0.1234Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 55ms/step - accuracy: 0.8192 - loss: 0.124226\n",
      "\u001b[1m11918/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:57\u001b[0m 42ms/step - accuracy: 0.8174 - loss: 0.1258Epoch 18/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 44ms/step - accuracy: 0.8208 - loss: 0.123866\n",
      "\u001b[1m11958/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:49\u001b[0m 40ms/step - accuracy: 0.8163 - loss: 0.1267Epoch 12/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 40ms/step - accuracy: 0.8209 - loss: 0.124066ms/step - accuracy: 0.818\n",
      "Epoch 8/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8255 - loss: 0.1215652\n",
      "\u001b[1m3334/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.8232 - loss: 0.1222Epoch 21/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8194 - loss: 0.124565\n",
      "Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 59ms/step - accuracy: 0.8231 - loss: 0.1222687━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9:2\n",
      "\u001b[1m10434/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m12:05\u001b[0m 38ms/step - accuracy: 0.8135 - loss: 0.1289Epoch 20/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8232 - loss: 0.1223123 \u001b[1m1:58\u001b[0m 53ms/step - accuracy: 0.8206 - \n",
      "Epoch 21/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8208 - loss: 0.1241788�━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m50s\u001b[0m 40ms/step - accuracy: 0.8163 - \n",
      "Epoch 21/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 37ms/step - accuracy: 0.8199 - loss: 0.1245\n",
      "\u001b[1m 1686/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:45\u001b[0m 40ms/step - accuracy: 0.8215 - loss: 0.1235Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 54ms/step - accuracy: 0.8171 - loss: 0.126148\n",
      "Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 47ms/step - accuracy: 0.8224 - loss: 0.123348\n",
      "\u001b[1m13134/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:06\u001b[0m 42ms/step - accuracy: 0.8183 - loss: 0.1264Epoch 23/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 55ms/step - accuracy: 0.8192 - loss: 0.12556\n",
      "\u001b[1m11858/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m11:14\u001b[0m 38ms/step - accuracy: 0.8135 - loss: 0.1289Epoch 11/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 45ms/step - accuracy: 0.8200 - loss: 0.12455\n",
      "\u001b[1m17256/29412\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m8:00\u001b[0m 40ms/step - accuracy: 0.8163 - loss: 0.1270Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 42ms/step - accuracy: 0.8205 - loss: 0.1247\n",
      "Epoch 8/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 40ms/step - accuracy: 0.8164 - loss: 0.12676\n",
      "\u001b[1m  888/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:09\u001b[0m 44ms/step - accuracy: 0.8250 - loss: 0.1228Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 42ms/step - accuracy: 0.8175 - loss: 0.1258\n",
      "\u001b[1m 2697/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:07\u001b[0m 41ms/step - accuracy: 0.8216 - loss: 0.1237Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 45ms/step - accuracy: 0.8150 - loss: 0.1277\n",
      "\u001b[1m7306/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8218 - loss: 0.1233Epoch 7/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 44ms/step - accuracy: 0.8218 - loss: 0.123388\n",
      "\u001b[1m3463/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 43ms/step - accuracy: 0.8243 - loss: 0.1224Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 67ms/step - accuracy: 0.8207 - loss: 0.12417258\n",
      "Epoch 18/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 47ms/step - accuracy: 0.8221 - loss: 0.123368\n",
      "\u001b[1m  714/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:55\u001b[0m 43ms/step - accuracy: 0.8242 - loss: 0.1218Epoch 13/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 59ms/step - accuracy: 0.8200 - loss: 0.1245323�━━\u001b[0m \u001b[1m10:05\u001b[0m 43ms\n",
      "\u001b[1m14505/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.8169 - loss: 0.1260Epoch 20/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 42ms/step - accuracy: 0.8182 - loss: 0.12653\n",
      "\u001b[1m3447/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 46ms/step - accuracy: 0.8223 - loss: 0.1235Epoch 8/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 42ms/step - accuracy: 0.8169 - loss: 0.1260\n",
      "Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 54ms/step - accuracy: 0.8205 - loss: 0.12417\n",
      "Epoch 19/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8244 - loss: 0.121956\n",
      "\u001b[1m20662/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:03\u001b[0m 42ms/step - accuracy: 0.8170 - loss: 0.1266Epoch 21/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 53ms/step - accuracy: 0.8238 - loss: 0.121826\n",
      "\u001b[1m13940/29412\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m9:52\u001b[0m 38ms/step - accuracy: 0.8136 - loss: 0.1289Epoch 22/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 47ms/step - accuracy: 0.8191 - loss: 0.12515626━━━━━━━━━━━\u001b[0m \u001b[1m8:51\u001b[0m 43ms/step - accuracy: 0.8205 -\n",
      "\u001b[1m 1482/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:36\u001b[0m 44ms/step - accuracy: 0.8226 - loss: 0.1228Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 44ms/step - accuracy: 0.8185 - loss: 0.125266\n",
      "\u001b[1m 631/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 63ms/step - accuracy: 0.8221 - loss: 0.1225Epoch 14/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 47ms/step - accuracy: 0.8214 - loss: 0.123772\n",
      "\u001b[1m  504/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:16\u001b[0m 39ms/step - accuracy: 0.8152 - loss: 0.1298Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 42ms/step - accuracy: 0.8171 - loss: 0.1266\n",
      "\u001b[1m4045/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 49ms/step - accuracy: 0.8180 - loss: 0.1259Epoch 8/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 57ms/step - accuracy: 0.8214 - loss: 0.123866\n",
      "\u001b[1m 996/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:04\u001b[0m 48ms/step - accuracy: 0.8210 - loss: 0.1232Epoch 20/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8237 - loss: 0.122089566759/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m25s\n",
      "\u001b[1m3328/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.8196 - loss: 0.1247Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8200 - loss: 0.1238629\n",
      "Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8249 - loss: 0.12154\n",
      "Epoch 22/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 43ms/step - accuracy: 0.8198 - loss: 0.124782\n",
      "\u001b[1m3616/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8207 - loss: 0.1237Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 55ms/step - accuracy: 0.8197 - loss: 0.124754\n",
      "Epoch 21/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8207 - loss: 0.123854\n",
      "\u001b[1m 3228/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:18\u001b[0m 43ms/step - accuracy: 0.8227 - loss: 0.1236Epoch 21/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 44ms/step - accuracy: 0.8192 - loss: 0.1251655�\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6:06\u001b[0\n",
      "\u001b[1m20743/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:03\u001b[0m 42ms/step - accuracy: 0.8161 - loss: 0.1272Epoch 14/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8235 - loss: 0.1224426\n",
      "\u001b[1m1016/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 54ms/step - accuracy: 0.8219 - loss: 0.1234Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 59ms/step - accuracy: 0.8234 - loss: 0.1222766\n",
      "Epoch 21/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 51ms/step - accuracy: 0.8193 - loss: 0.1248124\n",
      "Epoch 13/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 45ms/step - accuracy: 0.8222 - loss: 0.12343\n",
      "\u001b[1m2652/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 54ms/step - accuracy: 0.8212 - loss: 0.1237Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 48ms/step - accuracy: 0.8184 - loss: 0.12576\n",
      "\u001b[1m 6131/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:15\u001b[0m 44ms/step - accuracy: 0.8220 - loss: 0.1237Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 51ms/step - accuracy: 0.8208 - loss: 0.12376\n",
      "\u001b[1m 949/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 56ms/step - accuracy: 0.8227 - loss: 0.1229Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8232 - loss: 0.12213\n",
      "\u001b[1m 5540/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m5:54\u001b[0m 39ms/step - accuracy: 0.8174 - loss: 0.1263Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 61ms/step - accuracy: 0.8207 - loss: 0.123652\n",
      "\u001b[1m5920/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m57s\u001b[0m 40ms/step - accuracy: 0.8225 - loss: 0.1226Epoch 19/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 52ms/step - accuracy: 0.8230 - loss: 0.12216\n",
      "\u001b[1m1826/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 41ms/step - accuracy: 0.8232 - loss: 0.1223Epoch 23/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 48ms/step - accuracy: 0.8206 - loss: 0.1244\n",
      "\u001b[1m3344/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 39ms/step - accuracy: 0.8194 - loss: 0.1251Epoch 7/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 57ms/step - accuracy: 0.8201 - loss: 0.12447\n",
      "\u001b[1m 8979/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 40ms/step - accuracy: 0.8211 - loss: 0.1241Epoch 21/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8201 - loss: 0.124352\n",
      "Epoch 20/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 50ms/step - accuracy: 0.8252 - loss: 0.121042\n",
      "\u001b[1m25147/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:55\u001b[0m 41ms/step - accuracy: 0.8161 - loss: 0.1272Epoch 23/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 51ms/step - accuracy: 0.8188 - loss: 0.124532\n",
      "Epoch 22/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 39ms/step - accuracy: 0.8227 - loss: 0.12265\n",
      "Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8254 - loss: 0.12135\n",
      "Epoch 23/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 47ms/step - accuracy: 0.8198 - loss: 0.125247\n",
      "Epoch 12/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 48ms/step - accuracy: 0.8181 - loss: 0.12554\n",
      "\u001b[1m27188/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:22\u001b[0m 37ms/step - accuracy: 0.8165 - loss: 0.1269Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8206 - loss: 0.12416\n",
      "Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 47ms/step - accuracy: 0.8234 - loss: 0.122972\n",
      "Epoch 25/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 37ms/step - accuracy: 0.8173 - loss: 0.1263\n",
      "\u001b[1m6851/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.8219 - loss: 0.1231Epoch 8/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 40ms/step - accuracy: 0.8200 - loss: 0.12406\n",
      "\u001b[1m 420/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 39ms/step - accuracy: 0.8164 - loss: 0.1256Epoch 14/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 45ms/step - accuracy: 0.8219 - loss: 0.1231726 44ms/step - accuracy: 0.8221\n",
      "\u001b[1m23757/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3:18\u001b[0m 35ms/step - accuracy: 0.8139 - loss: 0.1287Epoch 14/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 41ms/step - accuracy: 0.8200 - loss: 0.12456\n",
      "Epoch 15/25\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 40ms/step - accuracy: 0.8173 - loss: 0.1265━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 44ms/step - acc\n",
      "Epoch 5/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 40ms/step - accuracy: 0.8147 - loss: 0.1285\n",
      "\u001b[1m2803/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m46s\u001b[0m 54ms/step - accuracy: 0.8215 - loss: 0.1236Epoch 5/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 40ms/step - accuracy: 0.8188 - loss: 0.1257\n",
      "Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 42ms/step - accuracy: 0.8217 - loss: 0.12375\n",
      "\u001b[1m3407/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.8246 - loss: 0.1214Epoch 15/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 43ms/step - accuracy: 0.8221 - loss: 0.123266━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 38ms/step - accuracy: 0.8191 - loss:\n",
      "\u001b[1m11303/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 37ms/step - accuracy: 0.8198 - loss: 0.1242Epoch 14/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8245 - loss: 0.121466\n",
      "\u001b[1m2439/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 49ms/step - accuracy: 0.8248 - loss: 0.1215Epoch 24/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 40ms/step - accuracy: 0.8161 - loss: 0.1273378/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 50ms/step - accuracy: 0.8211 - loss:\n",
      "\u001b[1m5226/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 37ms/step - accuracy: 0.8239 - loss: 0.1223Epoch 5/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 48ms/step - accuracy: 0.8242 - loss: 0.121623\n",
      "\u001b[1m2097/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 50ms/step - accuracy: 0.8206 - loss: 0.1240Epoch 23/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 37ms/step - accuracy: 0.8211 - loss: 0.1241\n",
      "Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 44ms/step - accuracy: 0.8210 - loss: 0.123664\n",
      "Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8213 - loss: 0.123754\n",
      "\u001b[1m10096/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 36ms/step - accuracy: 0.8169 - loss: 0.1263Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 49ms/step - accuracy: 0.8233 - loss: 0.1223480.8210 - loss: 0.12\n",
      "Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8211 - loss: 0.123168\n",
      "Epoch 21/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 49ms/step - accuracy: 0.8209 - loss: 0.123944\n",
      "\u001b[1m3349/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 39ms/step - accuracy: 0.8202 - loss: 0.1249Epoch 22/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 34ms/step - accuracy: 0.8212 - loss: 0.1240\n",
      "\u001b[1m5050/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 38ms/step - accuracy: 0.8208 - loss: 0.1235Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 50ms/step - accuracy: 0.8215 - loss: 0.123545\n",
      "Epoch 20/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 42ms/step - accuracy: 0.8230 - loss: 0.12267\n",
      "Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 49ms/step - accuracy: 0.8249 - loss: 0.121425\n",
      "\u001b[1m 4604/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 29ms/step - accuracy: 0.8159 - loss: 0.1267Epoch 24/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 36ms/step - accuracy: 0.8198 - loss: 0.1243\n",
      "Epoch 9/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 35ms/step - accuracy: 0.8173 - loss: 0.1267\n",
      "\u001b[1m14342/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.8191 - loss: 0.1252Epoch 8/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 40ms/step - accuracy: 0.8190 - loss: 0.124965\n",
      "\u001b[1m 2601/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:20\u001b[0m 26ms/step - accuracy: 0.8203 - loss: 0.1243Epoch 14/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 43ms/step - accuracy: 0.8193 - loss: 0.125047\n",
      "\u001b[1m 104/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 46ms/step - accuracy: 0.8206 - loss: 0.1229Epoch 14/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 36ms/step - accuracy: 0.8191 - loss: 0.1252\n",
      "Epoch 9/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 39ms/step - accuracy: 0.8211 - loss: 0.123435\n",
      "\u001b[1m13625/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m37s\u001b[0m 34ms/step - accuracy: 0.8171 - loss: 0.1263Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 35ms/step - accuracy: 0.8174 - loss: 0.1268\n",
      "Epoch 9/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 35ms/step - accuracy: 0.8170 - loss: 0.1264\n",
      "\u001b[1m6131/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m47s\u001b[0m 39ms/step - accuracy: 0.8196 - loss: 0.1251Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 51ms/step - accuracy: 0.8240 - loss: 0.1220259\n",
      "\u001b[1m 1163/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:07\u001b[0m 32ms/step - accuracy: 0.8254 - loss: 0.1223Epoch 23/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 34ms/step - accuracy: 0.8171 - loss: 0.1263\n",
      "\u001b[1m 1638/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:48\u001b[0m 31ms/step - accuracy: 0.8243 - loss: 0.1228Epoch 9/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 36ms/step - accuracy: 0.8230 - loss: 0.122446\n",
      "Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 51ms/step - accuracy: 0.8217 - loss: 0.123725\n",
      "\u001b[1m2215/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 36ms/step - accuracy: 0.8200 - loss: 0.1239Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8204 - loss: 0.123966\n",
      "\u001b[1m12940/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m47s\u001b[0m 27ms/step - accuracy: 0.8191 - loss: 0.1255Epoch 23/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 49ms/step - accuracy: 0.8243 - loss: 0.121666\n",
      "Epoch 24/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8237 - loss: 0.121947\n",
      "\u001b[1m2822/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 36ms/step - accuracy: 0.8210 - loss: 0.1246Epoch 23/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 38ms/step - accuracy: 0.8229 - loss: 0.122825\n",
      "\u001b[1m 2290/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:29\u001b[0m 31ms/step - accuracy: 0.8190 - loss: 0.1252Epoch 15/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 39ms/step - accuracy: 0.8254 - loss: 0.121227\n",
      "\u001b[1m 4748/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:10\u001b[0m 31ms/step - accuracy: 0.8230 - loss: 0.1228Epoch 27/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 51ms/step - accuracy: 0.8213 - loss: 0.123365\n",
      "Epoch 21/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 36ms/step - accuracy: 0.8201 - loss: 0.124357\n",
      "\u001b[1m10022/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:40\u001b[0m 27ms/step - accuracy: 0.8184 - loss: 0.1261Epoch 16/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 50ms/step - accuracy: 0.8218 - loss: 0.122947\n",
      "\u001b[1m2547/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - accuracy: 0.8260 - loss: 0.1208Epoch 22/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 38ms/step - accuracy: 0.8198 - loss: 0.124325\n",
      "\u001b[1m3050/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 34ms/step - accuracy: 0.8236 - loss: 0.1230Epoch 15/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 27ms/step - accuracy: 0.8191 - loss: 0.12542\n",
      "\u001b[1m1363/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 38ms/step - accuracy: 0.8180 - loss: 0.1246Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 37ms/step - accuracy: 0.8196 - loss: 0.124547\n",
      "Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 49ms/step - accuracy: 0.8248 - loss: 0.121327\n",
      "Epoch 25/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 47ms/step - accuracy: 0.8207 - loss: 0.123627\n",
      "Epoch 22/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 49ms/step - accuracy: 0.8214 - loss: 0.12336\n",
      "Epoch 24/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 38ms/step - accuracy: 0.8226 - loss: 0.123167\n",
      "Epoch 15/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 49ms/step - accuracy: 0.8207 - loss: 0.1239526cy: 0.8237 - loss: 0\n",
      "\u001b[1m1123/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 50ms/step - accuracy: 0.8218 - loss: 0.1226Epoch 25/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 31ms/step - accuracy: 0.8203 - loss: 0.1244\n",
      "\u001b[1m 6057/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:29\u001b[0m 31ms/step - accuracy: 0.8202 - loss: 0.1243Epoch 8/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 49ms/step - accuracy: 0.8259 - loss: 0.120957\n",
      "Epoch 25/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 38ms/step - accuracy: 0.8236 - loss: 0.12204\n",
      "Epoch 15/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 50ms/step - accuracy: 0.8231 - loss: 0.12234\n",
      "Epoch 24/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 29ms/step - accuracy: 0.8176 - loss: 0.1260\n",
      "\u001b[1m6205/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 35ms/step - accuracy: 0.8232 - loss: 0.1228Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 45ms/step - accuracy: 0.8226 - loss: 0.122832\n",
      "\u001b[1m6816/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.8209 - loss: 0.1243Epoch 25/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 40ms/step - accuracy: 0.8249 - loss: 0.12153\n",
      "\u001b[1m3994/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 35ms/step - accuracy: 0.8226 - loss: 0.1225Epoch 28/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 35ms/step - accuracy: 0.8209 - loss: 0.124334\n",
      "\u001b[1m4774/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 38ms/step - accuracy: 0.8200 - loss: 0.1245Epoch 15/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 35ms/step - accuracy: 0.8216 - loss: 0.1232\n",
      "Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 38ms/step - accuracy: 0.8192 - loss: 0.12516\n",
      "Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 35ms/step - accuracy: 0.8231 - loss: 0.12284\n",
      "Epoch 15/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 50ms/step - accuracy: 0.8249 - loss: 0.12144\n",
      "\u001b[1m2698/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 50ms/step - accuracy: 0.8257 - loss: 0.1209Epoch 24/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 48ms/step - accuracy: 0.8216 - loss: 0.12336\n",
      "\u001b[1m12016/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 27ms/step - accuracy: 0.8152 - loss: 0.1275Epoch 24/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 49ms/step - accuracy: 0.8257 - loss: 0.12084\n",
      "\u001b[1m3464/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8226 - loss: 0.1225Epoch 26/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 50ms/step - accuracy: 0.8237 - loss: 0.1220707━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7:07\u001b[0m 29ms/step - accura\n",
      "Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 50ms/step - accuracy: 0.8226 - loss: 0.12256\n",
      "Epoch 24/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 52ms/step - accuracy: 0.8209 - loss: 0.1233324\n",
      "Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 50ms/step - accuracy: 0.8218 - loss: 0.12335\n",
      "Epoch 23/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 40ms/step - accuracy: 0.8198 - loss: 0.1247625\n",
      "\u001b[1m7301/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8233 - loss: 0.1223Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 37ms/step - accuracy: 0.8233 - loss: 0.12234\n",
      "Epoch 16/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8196 - loss: 0.124871\n",
      "\u001b[1m2921/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 36ms/step - accuracy: 0.8198 - loss: 0.1249Epoch 14/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 39ms/step - accuracy: 0.8196 - loss: 0.1241427\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 28ms/step - accuracy: 0.8206 - loss: 0.\n",
      "\u001b[1m3023/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.8228 - loss: 0.1228Epoch 16/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 36ms/step - accuracy: 0.8227 - loss: 0.12254\n",
      "\u001b[1m15321/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 27ms/step - accuracy: 0.8153 - loss: 0.1275Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 51ms/step - accuracy: 0.8262 - loss: 0.12086�━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.8251 - loss: 0.1\n",
      "Epoch 26/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 52ms/step - accuracy: 0.8213 - loss: 0.1237627\n",
      "Epoch 26/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 36ms/step - accuracy: 0.8199 - loss: 0.124369\n",
      "Epoch 16/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 29ms/step - accuracy: 0.8204 - loss: 0.12416\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 32ms/step - accuracy: 0.8212 - loss: 0.1239\n",
      "\u001b[1m1872/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 51ms/step - accuracy: 0.8271 - loss: 0.1206Epoch 10/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 29ms/step - accuracy: 0.8220 - loss: 0.1234\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.8252 - loss: 0.1213327�━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.8201 - loss: 0.12\n",
      "Epoch 29/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 47ms/step - accuracy: 0.8228 - loss: 0.12286\n",
      "Epoch 26/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 29ms/step - accuracy: 0.8201 - loss: 0.1244\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 45ms/step - accuracy: 0.8246 - loss: 0.12143\n",
      "\u001b[1m  898/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:13\u001b[0m 27ms/step - accuracy: 0.8225 - loss: 0.1248Epoch 25/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 37ms/step - accuracy: 0.8219 - loss: 0.123372\n",
      "\u001b[1m13603/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - accuracy: 0.8189 - loss: 0.1254Epoch 17/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 35ms/step - accuracy: 0.8225 - loss: 0.12272\n",
      "\u001b[1m 7267/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:10\u001b[0m 34ms/step - accuracy: 0.8211 - loss: 0.1239Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 29ms/step - accuracy: 0.8199 - loss: 0.1246\n",
      "\u001b[1m 188/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 36ms/step - accuracy: 0.8176 - loss: 0.1268Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 28ms/step - accuracy: 0.8187 - loss: 0.1254\n",
      "\u001b[1m 2174/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:16\u001b[0m 35ms/step - accuracy: 0.8226 - loss: 0.1232Epoch 10/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8266 - loss: 0.1206523\n",
      "\u001b[1m3467/3677\u001b[0m \u001b[32m━━━━━━━━━━���━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.8243 - loss: 0.1216Epoch 27/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 31ms/step - accuracy: 0.8183 - loss: 0.1263\n",
      "Epoch 9/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 53ms/step - accuracy: 0.8243 - loss: 0.1216775m2:55\u001b[0m 28ms/step - accuracy: 0.8182 - \n",
      "\u001b[1m 1883/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:49\u001b[0m 32ms/step - accuracy: 0.8180 - loss: 0.1258Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 54ms/step - accuracy: 0.8222 - loss: 0.12305440m \u001b[1m4:50\u001b[0m 27ms/step - accuracy\n",
      "\u001b[1m3337/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 35ms/step - accuracy: 0.8214 - loss: 0.1239Epoch 25/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8218 - loss: 0.1229525\n",
      "Epoch 24/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 33ms/step - accuracy: 0.8223 - loss: 0.123035\n",
      "\u001b[1m24076/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2:30\u001b[0m 28ms/step - accuracy: 0.8187 - loss: 0.1256Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 56ms/step - accuracy: 0.8211 - loss: 0.123656\n",
      "Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 52ms/step - accuracy: 0.8237 - loss: 0.12176\n",
      "\u001b[1m 361/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 53ms/step - accuracy: 0.8239 - loss: 0.1226Epoch 26/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 36ms/step - accuracy: 0.8196 - loss: 0.1249355━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\n",
      "\u001b[1m4176/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 35ms/step - accuracy: 0.8215 - loss: 0.1238Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 52ms/step - accuracy: 0.8272 - loss: 0.12046\n",
      "Epoch 27/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.8264 - loss: 0.12116\n",
      "\u001b[1m 242/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 36ms/step - accuracy: 0.8174 - loss: 0.1259Epoch 30/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 39ms/step - accuracy: 0.8206 - loss: 0.12414\n",
      "\u001b[1m 907/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 53ms/step - accuracy: 0.8241 - loss: 0.1221Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 52ms/step - accuracy: 0.8262 - loss: 0.120752\n",
      "Epoch 27/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 44ms/step - accuracy: 0.8254 - loss: 0.1212343\n",
      "\u001b[1m10053/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 29ms/step - accuracy: 0.8193 - loss: 0.1245Epoch 26/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 46ms/step - accuracy: 0.8223 - loss: 0.123143\n",
      "\u001b[1m10304/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 29ms/step - accuracy: 0.8194 - loss: 0.1245Epoch 26/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 35ms/step - accuracy: 0.8232 - loss: 0.12253247939/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m\n",
      "Epoch 17/25\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m812s\u001b[0m 28ms/step - accuracy: 0.8186 - loss: 0.1256\n",
      "\u001b[1m 3373/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:08\u001b[0m 32ms/step - accuracy: 0.8191 - loss: 0.1261Epoch 6/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 35ms/step - accuracy: 0.8214 - loss: 0.12373\n",
      "\u001b[1m13843/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 34ms/step - accuracy: 0.8211 - loss: 0.1240Epoch 17/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 37ms/step - accuracy: 0.8234 - loss: 0.122032\n",
      "\u001b[1m27933/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.8170 - loss: 0.1269Epoch 18/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 27ms/step - accuracy: 0.8157 - loss: 0.1277\n",
      "Epoch 6/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 41ms/step - accuracy: 0.8216 - loss: 0.123445\n",
      "Epoch 17/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8237 - loss: 0.122225\n",
      "Epoch 24/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 53ms/step - accuracy: 0.8240 - loss: 0.121635\n",
      "Epoch 27/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 38ms/step - accuracy: 0.8205 - loss: 0.123825\n",
      "Epoch 18/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 52ms/step - accuracy: 0.8262 - loss: 0.120659\n",
      "Epoch 28/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 39ms/step - accuracy: 0.8278 - loss: 0.120423\n",
      "\u001b[1m 950/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:06\u001b[0m 39ms/step - accuracy: 0.8172 - loss: 0.1249Epoch 31/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 33ms/step - accuracy: 0.8224 - loss: 0.122655\n",
      "\u001b[1m 2951/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:43\u001b[0m 27ms/step - accuracy: 0.8188 - loss: 0.1264Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8232 - loss: 0.122468\n",
      "Epoch 25/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 29ms/step - accuracy: 0.8197 - loss: 0.1244\n",
      "\u001b[1m1442/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 52ms/step - accuracy: 0.8269 - loss: 0.1205Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8245 - loss: 0.122025\n",
      "\u001b[1m 673/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 56ms/step - accuracy: 0.8224 - loss: 0.1218Epoch 28/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8222 - loss: 0.123058\n",
      "Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 53ms/step - accuracy: 0.8216 - loss: 0.123054\n",
      "Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 45ms/step - accuracy: 0.8244 - loss: 0.1213582\n",
      "Epoch 27/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 27ms/step - accuracy: 0.8220 - loss: 0.1239\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 27ms/step - accuracy: 0.8216 - loss: 0.1238\n",
      "\u001b[1m14043/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.8202 - loss: 0.1242Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 52ms/step - accuracy: 0.8271 - loss: 0.120225\n",
      "\u001b[1m 510/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:44\u001b[0m 42ms/step - accuracy: 0.8274 - loss: 0.1205Epoch 28/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 35ms/step - accuracy: 0.8201 - loss: 0.124358\n",
      "Epoch 17/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 28ms/step - accuracy: 0.8199 - loss: 0.1247\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 27ms/step - accuracy: 0.8196 - loss: 0.1251\n",
      "\u001b[1m2446/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 53ms/step - accuracy: 0.8225 - loss: 0.1220Epoch 11/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 33ms/step - accuracy: 0.8214 - loss: 0.1236522\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 28ms/step - accuracy: 0.8181 - loss: 0.1258\n",
      "\u001b[1m 9619/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 33ms/step - accuracy: 0.8186 - loss: 0.1260Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8268 - loss: 0.12042\n",
      "Epoch 29/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 27ms/step - accuracy: 0.8183 - loss: 0.1256\n",
      "Epoch 11/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8256 - loss: 0.120955\n",
      "\u001b[1m 1359/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:33\u001b[0m 29ms/step - accuracy: 0.8185 - loss: 0.1251Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 39ms/step - accuracy: 0.8273 - loss: 0.1204225\n",
      "\u001b[1m1256/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 33ms/step - accuracy: 0.8231 - loss: 0.1229Epoch 32/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 39ms/step - accuracy: 0.8224 - loss: 0.1226656\n",
      "\u001b[1m6889/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.8210 - loss: 0.1236Epoch 17/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8225 - loss: 0.122636\n",
      "Epoch 27/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 36ms/step - accuracy: 0.8236 - loss: 0.122275\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 32ms/step - accuracy: 0.8183 - loss: 0.1256\n",
      "\u001b[1m 192/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:53\u001b[0m 41ms/step - accuracy: 0.8141 - loss: 0.1263Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 35ms/step - accuracy: 0.8220 - loss: 0.1233\n",
      "\u001b[1m3448/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8231 - loss: 0.1218Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 54ms/step - accuracy: 0.8230 - loss: 0.1221463\n",
      "Epoch 26/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 43ms/step - accuracy: 0.8235 - loss: 0.12194\n",
      "\u001b[1m1679/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 47ms/step - accuracy: 0.8236 - loss: 0.1228Epoch 17/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 36ms/step - accuracy: 0.8210 - loss: 0.123676\n",
      "Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8232 - loss: 0.1218751m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:52\u001b[0m 28ms/step - accuracy: 0.82\n",
      "\u001b[1m6650/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m27s\u001b[0m 38ms/step - accuracy: 0.8239 - loss: 0.1217Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 57ms/step - accuracy: 0.8230 - loss: 0.1222265\n",
      "\u001b[1m 8958/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:54\u001b[0m 26ms/step - accuracy: 0.8183 - loss: 0.1255Epoch 25/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 53ms/step - accuracy: 0.8220 - loss: 0.122744\n",
      "Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 47ms/step - accuracy: 0.8236 - loss: 0.12294636━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 55ms/step - accuracy: 0.8[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:41\u001b[0m 28\n",
      "\u001b[1m 7504/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 28ms/step - accuracy: 0.8229 - loss: 0.1230Epoch 28/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 39ms/step - accuracy: 0.8215 - loss: 0.123576\n",
      "\u001b[1m11770/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:39\u001b[0m 26ms/step - accuracy: 0.8186 - loss: 0.1255Epoch 19/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 53ms/step - accuracy: 0.8263 - loss: 0.120436\n",
      "\u001b[1m 859/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 54ms/step - accuracy: 0.8234 - loss: 0.1230Epoch 29/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 44ms/step - accuracy: 0.8202 - loss: 0.124556\n",
      "\u001b[1m 7128/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 28ms/step - accuracy: 0.8202 - loss: 0.1243Epoch 16/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 33ms/step - accuracy: 0.8231 - loss: 0.1227464\n",
      "\u001b[1m10924/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 31ms/step - accuracy: 0.8208 - loss: 0.1243Epoch 18/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 30ms/step - accuracy: 0.8209 - loss: 0.1243\n",
      "\u001b[1m 8881/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 32ms/step - accuracy: 0.8183 - loss: 0.1254Epoch 12/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 33ms/step - accuracy: 0.8185 - loss: 0.1260\n",
      "Epoch 10/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 44ms/step - accuracy: 0.8211 - loss: 0.124276\n",
      "Epoch 16/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 40ms/step - accuracy: 0.8215 - loss: 0.123236\n",
      "\u001b[1m 6452/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 27ms/step - accuracy: 0.8178 - loss: 0.1260Epoch 18/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 36ms/step - accuracy: 0.8203 - loss: 0.12444\n",
      "Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 52ms/step - accuracy: 0.8279 - loss: 0.1197564\n",
      "\u001b[1m14183/29412\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:32\u001b[0m 26ms/step - accuracy: 0.8187 - loss: 0.1254Epoch 30/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 51ms/step - accuracy: 0.8235 - loss: 0.12215\n",
      "\u001b[1m1289/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 45ms/step - accuracy: 0.8278 - loss: 0.1198Epoch 26/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 30ms/step - accuracy: 0.8208 - loss: 0.1242\n",
      "\u001b[1m 747/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 45ms/step - accuracy: 0.8250 - loss: 0.1222Epoch 10/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 39ms/step - accuracy: 0.8213 - loss: 0.12366\n",
      "\u001b[1m  84/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 45ms/step - accuracy: 0.8337 - loss: 0.1153Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 48ms/step - accuracy: 0.8276 - loss: 0.11977\n",
      "Epoch 30/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 41ms/step - accuracy: 0.8258 - loss: 0.12102\n",
      "Epoch 29/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 50ms/step - accuracy: 0.8237 - loss: 0.12254\n",
      "\u001b[1m3914/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 30ms/step - accuracy: 0.8247 - loss: 0.1218Epoch 27/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8221 - loss: 0.12296\n",
      "\u001b[1m1059/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 29ms/step - accuracy: 0.8203 - loss: 0.1244Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 34ms/step - accuracy: 0.8243 - loss: 0.12204\n",
      "\u001b[1m10560/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 31ms/step - accuracy: 0.8197 - loss: 0.1247Epoch 19/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 48ms/step - accuracy: 0.8228 - loss: 0.12245\n",
      "Epoch 29/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 25ms/step - accuracy: 0.8214 - loss: 0.1236\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 28ms/step - accuracy: 0.8224 - loss: 0.1231\n",
      "Epoch 12/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 36ms/step - accuracy: 0.8236 - loss: 0.12194\n",
      "Epoch 18/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 25ms/step - accuracy: 0.8224 - loss: 0.1232\n",
      "\u001b[1m20203/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 24ms/step - accuracy: 0.8164 - loss: 0.1274Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8268 - loss: 0.12024\n",
      "\u001b[1m4939/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 35ms/step - accuracy: 0.8230 - loss: 0.1230Epoch 30/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 30ms/step - accuracy: 0.8184 - loss: 0.1254\n",
      "\u001b[1m6917/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - accuracy: 0.8251 - loss: 0.1218Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 40ms/step - accuracy: 0.8232 - loss: 0.12285\n",
      "Epoch 29/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 37ms/step - accuracy: 0.8238 - loss: 0.12184\n",
      "\u001b[1m11953/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:24\u001b[0m 31ms/step - accuracy: 0.8197 - loss: 0.1248Epoch 18/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 25ms/step - accuracy: 0.8207 - loss: 0.1240\n",
      "Epoch 12/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 33ms/step - accuracy: 0.8250 - loss: 0.12182\n",
      "\u001b[1m1906/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 33ms/step - accuracy: 0.8253 - loss: 0.1212Epoch 19/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 34ms/step - accuracy: 0.8229 - loss: 0.12294\n",
      "\u001b[1m3528/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.8237 - loss: 0.1220Epoch 20/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 44ms/step - accuracy: 0.8237 - loss: 0.12206\n",
      "Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 38ms/step - accuracy: 0.8269 - loss: 0.12035\n",
      "Epoch 30/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 36ms/step - accuracy: 0.8203 - loss: 0.12446\n",
      "Epoch 17/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 44ms/step - accuracy: 0.8264 - loss: 0.12054\n",
      "Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 30ms/step - accuracy: 0.8226 - loss: 0.12333\n",
      "Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 45ms/step - accuracy: 0.8233 - loss: 0.12214\n",
      "\u001b[1m2592/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 30ms/step - accuracy: 0.8251 - loss: 0.1207Epoch 27/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 42ms/step - accuracy: 0.8257 - loss: 0.12117\n",
      "\u001b[1m 5576/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 21ms/step - accuracy: 0.8218 - loss: 0.1233Epoch 31/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 35ms/step - accuracy: 0.8218 - loss: 0.12303\n",
      "\u001b[1m 238/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 45ms/step - accuracy: 0.8241 - loss: 0.1205Epoch 19/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 36ms/step - accuracy: 0.8215 - loss: 0.12393\n",
      "\u001b[1m 187/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 47ms/step - accuracy: 0.8261 - loss: 0.1225Epoch 17/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 27ms/step - accuracy: 0.8196 - loss: 0.1251\n",
      "Epoch 11/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 43ms/step - accuracy: 0.8282 - loss: 0.11956\n",
      "Epoch 31/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 44ms/step - accuracy: 0.8226 - loss: 0.12283\n",
      "Epoch 31/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 28ms/step - accuracy: 0.8228 - loss: 0.1226440\u001b[0m 46ms/step - accuracy: 0.8251 -\n",
      "\u001b[1m1502/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 46ms/step - accuracy: 0.8251 - loss: 0.1213Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 44ms/step - accuracy: 0.8237 - loss: 0.1221226\n",
      "\u001b[1m 2750/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 24ms/step - accuracy: 0.8194 - loss: 0.1249Epoch 28/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 39ms/step - accuracy: 0.8248 - loss: 0.12214\n",
      "\u001b[1m 2896/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:45\u001b[0m 24ms/step - accuracy: 0.8193 - loss: 0.1249Epoch 30/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 29ms/step - accuracy: 0.8215 - loss: 0.12366\n",
      "\u001b[1m 7198/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 23ms/step - accuracy: 0.8214 - loss: 0.1235Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 25ms/step - accuracy: 0.8208 - loss: 0.1244\n",
      "Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8280 - loss: 0.119455\n",
      "Epoch 32/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8247 - loss: 0.1217343ep - accuracy: ━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 55ms/step - accurac�━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 36ms/step - accuracy: 0.8229 - \n",
      "\u001b[1m27674/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m46s\u001b[0m 27ms/step - accuracy: 0.8188 - loss: 0.1256Epoch 30/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 42ms/step - accuracy: 0.8252 - loss: 0.121244\n",
      "\u001b[1m6697/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8250 - loss: 0.1212Epoch 31/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 28ms/step - accuracy: 0.8194 - loss: 0.1255\n",
      "\u001b[1m 142/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 57ms/step - accuracy: 0.8226 - loss: 0.1247Epoch 11/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 51ms/step - accuracy: 0.8249 - loss: 0.1212483\n",
      "\u001b[1m2048/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 41ms/step - accuracy: 0.8297 - loss: 0.1188Epoch 29/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 33ms/step - accuracy: 0.8250 - loss: 0.1212624\n",
      "Epoch 20/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 47ms/step - accuracy: 0.8272 - loss: 0.12075628━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 32\n",
      "\u001b[1m11727/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 25ms/step - accuracy: 0.8218 - loss: 0.1232Epoch 32/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 51ms/step - accuracy: 0.8259 - loss: 0.12066\n",
      "\u001b[1m3259/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 38ms/step - accuracy: 0.8240 - loss: 0.1222Epoch 31/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 36ms/step - accuracy: 0.8237 - loss: 0.121528\n",
      "\u001b[1m1756/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 54ms/step - accuracy: 0.8281 - loss: 0.1196Epoch 21/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 52ms/step - accuracy: 0.8277 - loss: 0.11992858\n",
      "\u001b[1m 3919/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:50\u001b[0m 33ms/step - accuracy: 0.8191 - loss: 0.1258Epoch 30/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 41ms/step - accuracy: 0.8251 - loss: 0.121536\n",
      "Epoch 31/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 25ms/step - accuracy: 0.8215 - loss: 0.1234\n",
      "Epoch 13/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 41ms/step - accuracy: 0.8239 - loss: 0.121927\n",
      "\u001b[1m1574/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 47ms/step - accuracy: 0.8262 - loss: 0.1210Epoch 19/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 25ms/step - accuracy: 0.8219 - loss: 0.12322\n",
      "\u001b[1m12746/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.8198 - loss: 0.1246Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 35ms/step - accuracy: 0.8228 - loss: 0.123136\n",
      "\u001b[1m1668/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 40ms/step - accuracy: 0.8226 - loss: 0.1217Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 53ms/step - accuracy: 0.8285 - loss: 0.11944\n",
      "\u001b[1m 4723/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 32ms/step - accuracy: 0.8220 - loss: 0.1231Epoch 32/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 36ms/step - accuracy: 0.8234 - loss: 0.121835\n",
      "\u001b[1m 3172/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:53\u001b[0m 36ms/step - accuracy: 0.8202 - loss: 0.1249Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 55ms/step - accuracy: 0.8241 - loss: 0.12205\n",
      "\u001b[1m1232/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 55ms/step - accuracy: 0.8269 - loss: 0.1196Epoch 32/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 25ms/step - accuracy: 0.8220 - loss: 0.1236\n",
      "\u001b[1m2367/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 53ms/step - accuracy: 0.8293 - loss: 0.1192Epoch 13/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 53ms/step - accuracy: 0.8244 - loss: 0.121626\n",
      "\u001b[1m7121/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.8233 - loss: 0.1225Epoch 29/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 31ms/step - accuracy: 0.8227 - loss: 0.123046\n",
      "\u001b[1m3195/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.8241 - loss: 0.1217Epoch 22/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━���━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 45ms/step - accuracy: 0.8233 - loss: 0.1226\n",
      "\u001b[1m 2688/29412\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:57\u001b[0m 31ms/step - accuracy: 0.8178 - loss: 0.1262Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8283 - loss: 0.119666\n",
      "\u001b[1m 205/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 41ms/step - accuracy: 0.8255 - loss: 0.1213Epoch 32/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 25ms/step - accuracy: 0.8199 - loss: 0.1246\n",
      "\u001b[1m3623/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8240 - loss: 0.1217Epoch 13/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 56ms/step - accuracy: 0.8240 - loss: 0.1217463\n",
      "Epoch 31/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 41ms/step - accuracy: 0.8222 - loss: 0.12273\n",
      "\u001b[1m 1832/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 23ms/step - accuracy: 0.8234 - loss: 0.1230Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 25ms/step - accuracy: 0.8191 - loss: 0.1254\n",
      "Epoch 13/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 27ms/step - accuracy: 0.8175 - loss: 0.1267\n",
      "Epoch 7/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 28ms/step - accuracy: 0.8227 - loss: 0.1228\n",
      "\u001b[1m6386/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m41s\u001b[0m 43ms/step - accuracy: 0.8204 - loss: 0.1243Epoch 13/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 29ms/step - accuracy: 0.8179 - loss: 0.1259\n",
      "Epoch 12/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 29ms/step - accuracy: 0.8216 - loss: 0.1234\n",
      "Epoch 11/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 44ms/step - accuracy: 0.8218 - loss: 0.123665\n",
      "\u001b[1m 243/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:24\u001b[0m 37ms/step - accuracy: 0.8233 - loss: 0.1228Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 55ms/step - accuracy: 0.8263 - loss: 0.120225\n",
      "Epoch 32/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 55ms/step - accuracy: 0.8268 - loss: 0.11993126\n",
      "\u001b[1m1133/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 54ms/step - accuracy: 0.8310 - loss: 0.1175Epoch 31/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.8244 - loss: 0.121426\n",
      "\u001b[1m3446/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 39ms/step - accuracy: 0.8239 - loss: 0.1215Epoch 29/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 32ms/step - accuracy: 0.8240 - loss: 0.121646\n",
      "Epoch 21/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 45ms/step - accuracy: 0.8311 - loss: 0.1184554\n",
      "Epoch 37/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 33ms/step - accuracy: 0.8203 - loss: 0.124455m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:09\u001b[0m 32ms/step - accuracy:\n",
      "\u001b[1m15646/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:30\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.1266Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8298 - loss: 0.118735\n",
      "\u001b[1m14329/29412\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:02\u001b[0m 24ms/step - accuracy: 0.8167 - loss: 0.1264Epoch 33/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 47ms/step - accuracy: 0.8280 - loss: 0.12034\n",
      "Epoch 34/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 56ms/step - accuracy: 0.8232 - loss: 0.12262\n",
      "Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 31ms/step - accuracy: 0.8238 - loss: 0.1223462\n",
      "Epoch 23/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8253 - loss: 0.121436\n",
      "Epoch 32/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 54ms/step - accuracy: 0.8299 - loss: 0.11832\n",
      "Epoch 34/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 37ms/step - accuracy: 0.8247 - loss: 0.12132630 7230/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 26ms/step - accuracy: 0.8193 - \n",
      "\u001b[1m14609/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8231 - loss: 0.1227Epoch 20/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 41ms/step - accuracy: 0.8251 - loss: 0.121736\n",
      "\u001b[1m1533/3677\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 53ms/step - accuracy: 0.8303 - loss: 0.1187Epoch 33/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 31ms/step - accuracy: 0.8241 - loss: 0.1219623\n",
      "Epoch 21/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 35ms/step - accuracy: 0.8231 - loss: 0.1227\n",
      "\u001b[1m11229/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 35ms/step - accuracy: 0.8197 - loss: 0.1252Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8287 - loss: 0.119436\n",
      "\u001b[1m14695/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8194 - loss: 0.1254Epoch 33/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 33ms/step - accuracy: 0.8194 - loss: 0.1254\n",
      "\u001b[1m11054/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 25ms/step - accuracy: 0.8223 - loss: 0.1228Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 31ms/step - accuracy: 0.8221 - loss: 0.1234\n",
      "Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 38ms/step - accuracy: 0.8241 - loss: 0.122356\n",
      "\u001b[1m 592/3677\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 53ms/step - accuracy: 0.8300 - loss: 0.1180Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 45ms/step - accuracy: 0.8320 - loss: 0.118336\n",
      "Epoch 38/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 56ms/step - accuracy: 0.8257 - loss: 0.120656\n",
      "Epoch 31/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 33ms/step - accuracy: 0.8259 - loss: 0.120956\n",
      "Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 52ms/step - accuracy: 0.8300 - loss: 0.118826\n",
      "Epoch 34/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 55ms/step - accuracy: 0.8273 - loss: 0.12004\n",
      "Epoch 32/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 39ms/step - accuracy: 0.8228 - loss: 0.12276\n",
      "\u001b[1m 2742/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:22\u001b[0m 37ms/step - accuracy: 0.8232 - loss: 0.1231Epoch 21/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 35ms/step - accuracy: 0.8196 - loss: 0.1252\n",
      "Epoch 12/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 54ms/step - accuracy: 0.8267 - loss: 0.120524\n",
      "Epoch 31/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 25ms/step - accuracy: 0.8214 - loss: 0.1236\n",
      "\u001b[1m 1262/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:44\u001b[0m 30ms/step - accuracy: 0.8252 - loss: 0.1216Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 54ms/step - accuracy: 0.8296 - loss: 0.119164\n",
      "\u001b[1m5188/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 30ms/step - accuracy: 0.8232 - loss: 0.1223Epoch 34/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 44ms/step - accuracy: 0.8211 - loss: 0.12382\n",
      "Epoch 19/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 47ms/step - accuracy: 0.8273 - loss: 0.12012\n",
      "Epoch 35/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 26ms/step - accuracy: 0.8201 - loss: 0.1247\n",
      "\u001b[1m1958/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 55ms/step - accuracy: 0.8243 - loss: 0.1217Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.8243 - loss: 0.1215434━━━━━━━━━━━━\u001b[0m \u001b[1m6:43\u001b[0m \n",
      "Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 44ms/step - accuracy: 0.8234 - loss: 0.122952\n",
      "\u001b[1m  93/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 56ms/step - accuracy: 0.8226 - loss: 0.1218Epoch 19/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 40ms/step - accuracy: 0.8254 - loss: 0.12123\n",
      "\u001b[1m5971/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m44s\u001b[0m 32ms/step - accuracy: 0.8248 - loss: 0.1214Epoch 21/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 32ms/step - accuracy: 0.8215 - loss: 0.1230\n",
      "\u001b[1m2363/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 52ms/step - accuracy: 0.8320 - loss: 0.1178Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 55ms/step - accuracy: 0.8242 - loss: 0.12192\n",
      "Epoch 34/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m714s\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.1267\n",
      "\u001b[1m3806/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 41ms/step - accuracy: 0.8252 - loss: 0.1222Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8273 - loss: 0.1196322\n",
      "Epoch 34/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m713s\u001b[0m 24ms/step - accuracy: 0.8201 - loss: 0.1249\n",
      "\u001b[1m2907/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m42s\u001b[0m 56ms/step - accuracy: 0.8266 - loss: 0.1201Epoch 8/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 56ms/step - accuracy: 0.8256 - loss: 0.12104\n",
      "Epoch 31/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 32ms/step - accuracy: 0.8243 - loss: 0.12142\n",
      "Epoch 22/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 34ms/step - accuracy: 0.8188 - loss: 0.1255\n",
      "\u001b[1m1842/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 45ms/step - accuracy: 0.8336 - loss: 0.1174Epoch 13/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 32ms/step - accuracy: 0.8250 - loss: 0.121352\n",
      "Epoch 21/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 34ms/step - accuracy: 0.8216 - loss: 0.1234\n",
      "\u001b[1m 3653/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━���━━━━━━━━━━━━\u001b[0m \u001b[1m5:01\u001b[0m 27ms/step - accuracy: 0.8210 - loss: 0.1240Epoch 12/25\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 25ms/step - accuracy: 0.8171 - loss: 0.1263\n",
      "\u001b[1m3485/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 39ms/step - accuracy: 0.8247 - loss: 0.1217Epoch 8/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 38ms/step - accuracy: 0.8246 - loss: 0.12203\n",
      "Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8264 - loss: 0.120147\n",
      "\u001b[1m 7176/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 28ms/step - accuracy: 0.8235 - loss: 0.1225Epoch 32/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 52ms/step - accuracy: 0.8317 - loss: 0.118046\n",
      "Epoch 35/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 46ms/step - accuracy: 0.8282 - loss: 0.119735\n",
      "\u001b[1m 4136/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:22\u001b[0m 36ms/step - accuracy: 0.8209 - loss: 0.1244Epoch 36/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8248 - loss: 0.121536\n",
      "\u001b[1m 567/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:09\u001b[0m 37ms/step - accuracy: 0.8298 - loss: 0.1192Epoch 32/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 56ms/step - accuracy: 0.8278 - loss: 0.119545\n",
      "Epoch 33/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8260 - loss: 0.12114\n",
      "Epoch 34/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 55ms/step - accuracy: 0.8299 - loss: 0.118545\n",
      "\u001b[1m 6171/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 37ms/step - accuracy: 0.8204 - loss: 0.1246Epoch 36/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 42ms/step - accuracy: 0.8255 - loss: 0.122045\n",
      "\u001b[1m 3736/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:53\u001b[0m 28ms/step - accuracy: 0.8172 - loss: 0.1257Epoch 23/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 44ms/step - accuracy: 0.8233 - loss: 0.122454\n",
      "\u001b[1m5785/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 49ms/step - accuracy: 0.8230 - loss: 0.1227Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8297 - loss: 0.118925\n",
      "\u001b[1m10827/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 28ms/step - accuracy: 0.8240 - loss: 0.1223Epoch 35/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 43ms/step - accuracy: 0.8261 - loss: 0.120755\n",
      "Epoch 35/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 36ms/step - accuracy: 0.8209 - loss: 0.1241\n",
      "\u001b[1m 9951/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 29ms/step - accuracy: 0.8194 - loss: 0.1248Epoch 13/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 39ms/step - accuracy: 0.8242 - loss: 0.12194565━━━━━━━━\u001b[0m\u001b[37m\n",
      "\u001b[1m 5413/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:15\u001b[0m 28ms/step - accuracy: 0.8174 - loss: 0.1256Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8246 - loss: 0.1219256\n",
      "Epoch 35/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 53ms/step - accuracy: 0.8316 - loss: 0.1177436��━━━━━━━━━━━━\u001b[0m \u001b[1m5:37\u001b[0m 38ms/step - accuracy: 0.823\n",
      "\u001b[1m 8584/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:47\u001b[0m 28ms/step - accuracy: 0.8183 - loss: 0.1260Epoch 36/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 29ms/step - accuracy: 0.8238 - loss: 0.1224\n",
      "\u001b[1m2524/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 56ms/step - accuracy: 0.8287 - loss: 0.1190Epoch 15/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 34ms/step - accuracy: 0.8256 - loss: 0.12085\n",
      "\u001b[1m11662/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 29ms/step - accuracy: 0.8202 - loss: 0.1243Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 55ms/step - accuracy: 0.8268 - loss: 0.12085\n",
      "Epoch 33/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 29ms/step - accuracy: 0.8231 - loss: 0.1227\n",
      "Epoch 15/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 40ms/step - accuracy: 0.8206 - loss: 0.1237\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 29ms/step - accuracy: 0.8223 - loss: 0.12313\n",
      "\u001b[1m5565/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 36ms/step - accuracy: 0.8258 - loss: 0.1205Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 49ms/step - accuracy: 0.8234 - loss: 0.12292\n",
      "\u001b[1m5569/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 36ms/step - accuracy: 0.8258 - loss: 0.1205Epoch 20/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 34ms/step - accuracy: 0.8258 - loss: 0.12126\n",
      "Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8336 - loss: 0.11724\n",
      "Epoch 41/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8291 - loss: 0.11925\n",
      "Epoch 36/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 38ms/step - accuracy: 0.8231 - loss: 0.1224\n",
      "\u001b[1m2878/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - accuracy: 0.8260 - loss: 0.1211Epoch 14/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 43ms/step - accuracy: 0.8262 - loss: 0.12082\n",
      "\u001b[1m2619/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 56ms/step - accuracy: 0.8280 - loss: 0.1195Epoch 22/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━��━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 28ms/step - accuracy: 0.8207 - loss: 0.1240\n",
      "\u001b[1m   54/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:49\u001b[0m 32ms/step - accuracy: 0.8181 - loss: 0.1298Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 42ms/step - accuracy: 0.8283 - loss: 0.12005\n",
      "Epoch 36/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 43ms/step - accuracy: 0.8253 - loss: 0.12114\n",
      "\u001b[1m 9749/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:06\u001b[0m 28ms/step - accuracy: 0.8174 - loss: 0.1257Epoch 24/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 37ms/step - accuracy: 0.8201 - loss: 0.1246\n",
      "\u001b[1m 9811/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:04\u001b[0m 28ms/step - accuracy: 0.8174 - loss: 0.1257Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 29ms/step - accuracy: 0.8195 - loss: 0.1248\n",
      "Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━���━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 57ms/step - accuracy: 0.8266 - loss: 0.1203\n",
      "\u001b[1m 137/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:38\u001b[0m 47ms/step - accuracy: 0.8323 - loss: 0.1168Epoch 33/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8258 - loss: 0.12114\n",
      "Epoch 35/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 35ms/step - accuracy: 0.8222 - loss: 0.1236\n",
      "Epoch 15/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 56ms/step - accuracy: 0.8285 - loss: 0.119062\n",
      "\u001b[1m  929/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 36ms/step - accuracy: 0.8184 - loss: 0.1238Epoch 34/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 36ms/step - accuracy: 0.8259 - loss: 0.1205424\n",
      "Epoch 24/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 40ms/step - accuracy: 0.8258 - loss: 0.1213543��━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 38ms/step - accur\n",
      "\u001b[1m 174/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 35ms/step - accuracy: 0.8228 - loss: 0.1209Epoch 24/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 47ms/step - accuracy: 0.8285 - loss: 0.12022\n",
      "Epoch 38/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8275 - loss: 0.1202324\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 33ms/step - accuracy: 0\n",
      "Epoch 33/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8343 - loss: 0.1170625\n",
      "\u001b[1m3494/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 45ms/step - accuracy: 0.8272 - loss: 0.1203Epoch 42/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 52ms/step - accuracy: 0.8316 - loss: 0.117536\n",
      "Epoch 37/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 42ms/step - accuracy: 0.8271 - loss: 0.120427\n",
      "Epoch 37/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 38ms/step - accuracy: 0.8199 - loss: 0.1249\n",
      "\u001b[1m27722/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m57s\u001b[0m 34ms/step - accuracy: 0.8172 - loss: 0.1266Epoch 13/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8264 - loss: 0.120437\n",
      "Epoch 34/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 33ms/step - accuracy: 0.8251 - loss: 0.12179127\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 57ms/step - accuracy: 0.8259 - loss: 0.12053\n",
      "Epoch 36/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 57ms/step - accuracy: 0.8293 - loss: 0.118853\n",
      "\u001b[1m2081/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 51ms/step - accuracy: 0.8304 - loss: 0.1181Epoch 37/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 55ms/step - accuracy: 0.8287 - loss: 0.1190364m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 36ms/step - accurac\n",
      "Epoch 35/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 38ms/step - accuracy: 0.8203 - loss: 0.1242\n",
      "Epoch 14/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8246 - loss: 0.121734\n",
      "\u001b[1m 7380/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4:43\u001b[0m 39ms/step - accuracy: 0.8205 - loss: 0.1243Epoch 37/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 49ms/step - accuracy: 0.8213 - loss: 0.123616\n",
      "\u001b[1m6516/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.8238 - loss: 0.1231Epoch 21/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 36ms/step - accuracy: 0.8271 - loss: 0.120046\n",
      "\u001b[1m 979/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 56ms/step - accuracy: 0.8315 - loss: 0.1186Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 38ms/step - accuracy: 0.8233 - loss: 0.1225\n",
      "Epoch 13/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 51ms/step - accuracy: 0.8224 - loss: 0.122446\n",
      "Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8273 - loss: 0.119635\n",
      "Epoch 37/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 46ms/step - accuracy: 0.8300 - loss: 0.119135\n",
      "\u001b[1m11158/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 28ms/step - accuracy: 0.8231 - loss: 0.1231Epoch 39/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 43ms/step - accuracy: 0.8269 - loss: 0.120325\n",
      "\u001b[1m6913/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 36ms/step - accuracy: 0.8266 - loss: 0.1207Epoch 25/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 28ms/step - accuracy: 0.8233 - loss: 0.1225\n",
      "\u001b[1m 6199/14706\u001b[0m \u001b[32m━━━━━━━���\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 32ms/step - accuracy: 0.8234 - loss: 0.1224Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 28ms/step - accuracy: 0.8230 - loss: 0.12315\n",
      "Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 55ms/step - accuracy: 0.8276 - loss: 0.12012565━━━━━━━━━━━━━\u001b[m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07\u001b[0m 39ms/step - accuracy: \n",
      "\u001b[1m 4116/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:47\u001b[0m 33ms/step - accuracy: 0.8225 - loss: 0.1230Epoch 37/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 56ms/step - accuracy: 0.8279 - loss: 0.119735\n",
      "Epoch 35/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 28ms/step - accuracy: 0.8220 - loss: 0.1235\n",
      "Epoch 16/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 36ms/step - accuracy: 0.8205 - loss: 0.1243\n",
      "\u001b[1m2672/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 55ms/step - accuracy: 0.8273 - loss: 0.1205Epoch 14/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 55ms/step - accuracy: 0.8316 - loss: 0.118135\n",
      "\u001b[1m10943/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 41ms/step - accuracy: 0.8218 - loss: 0.1236Epoch 39/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 55ms/step - accuracy: 0.8308 - loss: 0.118046\n",
      "\u001b[1m 2666/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:40\u001b[0m 33ms/step - accuracy: 0.8217 - loss: 0.1235Epoch 38/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 32ms/step - accuracy: 0.8275 - loss: 0.120326\n",
      "Epoch 24/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 32ms/step - accuracy: 0.8263 - loss: 0.120536\n",
      "\u001b[1m3005/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 42ms/step - accuracy: 0.8273 - loss: 0.1201Epoch 25/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 29ms/step - accuracy: 0.8209 - loss: 0.1243\n",
      "\u001b[1m12797/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:04\u001b[0m 34ms/step - accuracy: 0.8222 - loss: 0.1233Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 57ms/step - accuracy: 0.8277 - loss: 0.119936\n",
      "Epoch 37/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 27ms/step - accuracy: 0.8207 - loss: 0.1243\n",
      "Epoch 16/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 35ms/step - accuracy: 0.8232 - loss: 0.122846\n",
      "\u001b[1m10987/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10:21\u001b[0m 34ms/step - accuracy: 0.8181 - loss: 0.1254Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 56ms/step - accuracy: 0.8285 - loss: 0.119235\n",
      "Epoch 38/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 53ms/step - accuracy: 0.8284 - loss: 0.118732\n",
      "\u001b[1m 1745/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:59\u001b[0m 28ms/step - accuracy: 0.8231 - loss: 0.1228Epoch 38/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 41ms/step - accuracy: 0.8300 - loss: 0.1189222\n",
      "\u001b[1m 990/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 50ms/step - accuracy: 0.8253 - loss: 0.1208Epoch 39/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 53ms/step - accuracy: 0.8288 - loss: 0.11954\n",
      "Epoch 36/75\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/steptep - accuracy: 0.8230 - loss: 0.122\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 39ms/step - accuracy: 0.8216 - loss: 0.1236\n",
      "\u001b[1m 212/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 56ms/step - accuracy: 0.8299 - loss: 0.1183Epoch 15/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 33ms/step - accuracy: 0.8281 - loss: 0.11984\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 39ms/step - accuracy: 0.8272 - loss: 0.1205633m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m26s\u001b[0m 44ms/step - accuracy��━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 53ms\n",
      "\u001b[1m6972/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.8270 - loss: 0.1203Epoch 26/100\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/stepp - accuracy: 0.8283 - loss: 0.12022\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 36ms/step - accuracy: 0.8260 - loss: 0.1211223\n",
      "Epoch 26/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8270 - loss: 0.1202\n",
      "\u001b[1m16214/29412\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m7:05\u001b[0m 32ms/step - accuracy: 0.8188 - loss: 0.1251Epoch 38/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 40ms/step - accuracy: 0.8270 - loss: 0.12033\n",
      "Epoch 24/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 44ms/step - accuracy: 0.8223 - loss: 0.123074\n",
      "\u001b[1m2946/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 44ms/step - accuracy: 0.8353 - loss: 0.1165Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8282 - loss: 0.11962\n",
      "Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 51ms/step - accuracy: 0.8333 - loss: 0.11713\n",
      "Epoch 40/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 53ms/step - accuracy: 0.8296 - loss: 0.11932\n",
      "\u001b[1m11492/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 25ms/step - accuracy: 0.8234 - loss: 0.1227Epoch 36/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 51ms/step - accuracy: 0.8333 - loss: 0.1170222\n",
      "Epoch 40/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 36ms/step - accuracy: 0.8256 - loss: 0.12113\n",
      "\u001b[1m 6666/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:13\u001b[0m 31ms/step - accuracy: 0.8197 - loss: 0.1248Epoch 25/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 54ms/step - accuracy: 0.8293 - loss: 0.11853\n",
      "\u001b[1m3278/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 39ms/step - accuracy: 0.8284 - loss: 0.1201Epoch 37/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 25ms/step - accuracy: 0.8233 - loss: 0.1224\n",
      "\u001b[1m12639/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:05\u001b[0m 32ms/step - accuracy: 0.8229 - loss: 0.1228Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 54ms/step - accuracy: 0.8287 - loss: 0.11893\n",
      "\u001b[1m5127/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 38ms/step - accuracy: 0.8283 - loss: 0.1203Epoch 39/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8282 - loss: 0.11963\n",
      "\u001b[1m14053/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8243 - loss: 0.1221Epoch 37/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 32ms/step - accuracy: 0.8207 - loss: 0.1240\n",
      "Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 40ms/step - accuracy: 0.8296 - loss: 0.1195926━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:00\u001b[0m 32ms/step - accuracy: 0.8229 - loss: 0.1\n",
      "\u001b[1m  194/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:12\u001b[0m 26ms/step - accuracy: 0.8297 - loss: 0.1183Epoch 40/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 25ms/step - accuracy: 0.8248 - loss: 0.1218\n",
      "\u001b[1m21225/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 32ms/step - accuracy: 0.8189 - loss: 0.1251Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 25ms/step - accuracy: 0.8242 - loss: 0.12214━━━━━━━━━━━━\u001b[0m \u001b[1m5:05\u001b[0m 29ms/step - acc\n",
      "Epoch 17/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 38ms/step - accuracy: 0.8276 - loss: 0.1200226�━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 29ms/st\n",
      "Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 53ms/step - accuracy: 0.8270 - loss: 0.12035\n",
      "\u001b[1m 3048/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:02\u001b[0m 31ms/step - accuracy: 0.8190 - loss: 0.1256Epoch 40/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8329 - loss: 0.11686\n",
      "Epoch 40/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 30ms/step - accuracy: 0.8271 - loss: 0.12025\n",
      "Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8271 - loss: 0.12053\n",
      "Epoch 39/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 39ms/step - accuracy: 0.8281 - loss: 0.1200495━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 39\n",
      "\u001b[1m22811/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 30ms/step - accuracy: 0.8171 - loss: 0.1261Epoch 25/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 41ms/step - accuracy: 0.8288 - loss: 0.11972\n",
      "\u001b[1m6264/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 32ms/step - accuracy: 0.8248 - loss: 0.1218Epoch 41/50\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/stepp - accuracy: 0.8324 - loss: 0.11724\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 53ms/step - accuracy: 0.8295 - loss: 0.11892\n",
      "\u001b[1m3110/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - accuracy: 0.8294 - loss: 0.1184Epoch 37/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 30ms/step - accuracy: 0.8267 - loss: 0.12041\n",
      "Epoch 26/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 30ms/step - accuracy: 0.8245 - loss: 0.1218\n",
      "Epoch 16/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 35ms/step - accuracy: 0.8256 - loss: 0.12106\n",
      "Epoch 26/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m907s\u001b[0m 31ms/step - accuracy: 0.8191 - loss: 0.1250\n",
      "\u001b[1m 720/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:42\u001b[0m 43ms/step - accuracy: 0.8249 - loss: 0.1216Epoch 9/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 52ms/step - accuracy: 0.8288 - loss: 0.11944\n",
      "Epoch 40/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 50ms/step - accuracy: 0.8327 - loss: 0.11732\n",
      "\u001b[1m2968/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 37ms/step - accuracy: 0.8293 - loss: 0.1191Epoch 42/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 52ms/step - accuracy: 0.8296 - loss: 0.11894\n",
      "\u001b[1m2377/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 34ms/step - accuracy: 0.8284 - loss: 0.1200Epoch 38/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 51ms/step - accuracy: 0.8318 - loss: 0.11793\n",
      "\u001b[1m 444/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 54ms/step - accuracy: 0.8264 - loss: 0.1210Epoch 41/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 33ms/step - accuracy: 0.8240 - loss: 0.1223\n",
      "Epoch 16/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 39ms/step - accuracy: 0.8300 - loss: 0.1193124━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 55ms/step - accuractep - accuracy: 0.8196\n",
      "\u001b[1m4122/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 29ms/step - accuracy: 0.8297 - loss: 0.1188Epoch 42/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 28ms/step - accuracy: 0.8241 - loss: 0.1220\n",
      "\u001b[1m1736/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 35ms/step - accuracy: 0.8268 - loss: 0.1205Epoch 17/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 23ms/step - accuracy: 0.8204 - loss: 0.1240\n",
      "\u001b[1m 301/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 52ms/step - accuracy: 0.8300 - loss: 0.1180Epoch 10/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 24ms/step - accuracy: 0.8226 - loss: 0.1231\n",
      "\u001b[1m2408/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 52ms/step - accuracy: 0.8320 - loss: 0.1171Epoch 18/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 22ms/step - accuracy: 0.8221 - loss: 0.123727\n",
      "\u001b[1m 4293/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:04\u001b[0m 29ms/step - accuracy: 0.8232 - loss: 0.1224Epoch 18/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 31ms/step - accuracy: 0.8248 - loss: 0.121927\n",
      "Epoch 28/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 29ms/step - accuracy: 0.8287 - loss: 0.119127\n",
      "Epoch 27/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 37ms/step - accuracy: 0.8285 - loss: 0.119517\n",
      "Epoch 26/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 23ms/step - accuracy: 0.8173 - loss: 0.1265\n",
      "\u001b[1m3126/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29s\u001b[0m 53ms/step - accuracy: 0.8287 - loss: 0.1191Epoch 10/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 35ms/step - accuracy: 0.8277 - loss: 0.120325\n",
      "Epoch 28/50\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.8284 - loss: 0.1191205\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 37ms/step - accuracy: 0.8289 - loss: 0.119127\n",
      "\u001b[1m 2852/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:32\u001b[0m 28ms/step - accuracy: 0.8203 - loss: 0.1248Epoch 28/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 23ms/step - accuracy: 0.8195 - loss: 0.1252\n",
      "Epoch 10/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 24ms/step - accuracy: 0.8214 - loss: 0.1237\n",
      "\u001b[1m3505/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.8289 - loss: 0.1190Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 52ms/step - accuracy: 0.8284 - loss: 0.119437\n",
      "Epoch 41/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 52ms/step - accuracy: 0.8289 - loss: 0.119027\n",
      "Epoch 39/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 51ms/step - accuracy: 0.8353 - loss: 0.116035\n",
      "\u001b[1m 941/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 42ms/step - accuracy: 0.8359 - loss: 0.1158Epoch 43/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 25ms/step - accuracy: 0.8232 - loss: 0.1229\n",
      "Epoch 16/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 51ms/step - accuracy: 0.8306 - loss: 0.11853\n",
      "Epoch 39/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8296 - loss: 0.119019403247/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m \n",
      "Epoch 40/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 41ms/step - accuracy: 0.8258 - loss: 0.12094\n",
      "Epoch 26/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8308 - loss: 0.117843\n",
      "Epoch 40/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8304 - loss: 0.1181122\n",
      "\u001b[1m5411/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 29ms/step - accuracy: 0.8301 - loss: 0.1190Epoch 42/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 42ms/step - accuracy: 0.8372 - loss: 0.115331\n",
      "Epoch 49/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 28ms/step - accuracy: 0.8237 - loss: 0.1229\n",
      "Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 51ms/step - accuracy: 0.8336 - loss: 0.11722\n",
      "\u001b[1m6677/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.8303 - loss: 0.1186Epoch 43/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 33ms/step - accuracy: 0.8281 - loss: 0.12002\n",
      "Epoch 29/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8344 - loss: 0.11623\n",
      "\u001b[1m5388/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 36ms/step - accuracy: 0.8296 - loss: 0.1186Epoch 43/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 43ms/step - accuracy: 0.8328 - loss: 0.11762\n",
      "\u001b[1m 9526/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:02\u001b[0m 24ms/step - accuracy: 0.8188 - loss: 0.1252Epoch 46/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8287 - loss: 0.11995\n",
      "\u001b[1m 6818/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:39\u001b[0m 28ms/step - accuracy: 0.8231 - loss: 0.1224Epoch 43/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8296 - loss: 0.11914\n",
      "\u001b[1m13604/29412\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:58\u001b[0m 27ms/step - accuracy: 0.8176 - loss: 0.1265Epoch 42/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 33ms/step - accuracy: 0.8267 - loss: 0.12124\n",
      "\u001b[1m1176/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 48ms/step - accuracy: 0.8317 - loss: 0.1177Epoch 29/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 38ms/step - accuracy: 0.8302 - loss: 0.11872\n",
      "Epoch 27/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 29ms/step - accuracy: 0.8226 - loss: 0.1227\n",
      "\u001b[1m1133/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 47ms/step - accuracy: 0.8351 - loss: 0.1159Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 27ms/step - accuracy: 0.8251 - loss: 0.1213\n",
      "Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8309 - loss: 0.11842\n",
      "\u001b[1m 789/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 48ms/step - accuracy: 0.8292 - loss: 0.1189Epoch 40/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 47ms/step - accuracy: 0.8362 - loss: 0.11542\n",
      "Epoch 44/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 49ms/step - accuracy: 0.8300 - loss: 0.11896\n",
      "\u001b[1m14180/29412\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 23ms/step - accuracy: 0.8208 - loss: 0.1243Epoch 41/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 43ms/step - accuracy: 0.8393 - loss: 0.11442\n",
      "\u001b[1m13339/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - accuracy: 0.8215 - loss: 0.1241Epoch 50/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 25ms/step - accuracy: 0.8230 - loss: 0.1228\n",
      "\u001b[1m 1230/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:04\u001b[0m 27ms/step - accuracy: 0.8242 - loss: 0.1217Epoch 19/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 33ms/step - accuracy: 0.8269 - loss: 0.12034\n",
      "\u001b[1m7169/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.8295 - loss: 0.1187Epoch 28/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 25ms/step - accuracy: 0.8250 - loss: 0.1216\n",
      "\u001b[1m 246/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 46ms/step - accuracy: 0.8298 - loss: 0.1192Epoch 19/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 26ms/step - accuracy: 0.8212 - loss: 0.1237\n",
      "\u001b[1m15242/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:46\u001b[0m 24ms/step - accuracy: 0.8187 - loss: 0.1253Epoch 19/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 25ms/step - accuracy: 0.8228 - loss: 0.1229\n",
      "\u001b[1m15280/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:45\u001b[0m 24ms/step - accuracy: 0.8187 - loss: 0.1253Epoch 17/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 24ms/step - accuracy: 0.8207 - loss: 0.1241\n",
      "Epoch 19/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8356 - loss: 0.11576\n",
      "\u001b[1m3041/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.8311 - loss: 0.1183Epoch 45/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 31ms/step - accuracy: 0.8289 - loss: 0.11890\n",
      "\u001b[1m10816/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 28ms/step - accuracy: 0.8228 - loss: 0.1231Epoch 30/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 43ms/step - accuracy: 0.8325 - loss: 0.11809\n",
      "Epoch 47/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 41ms/step - accuracy: 0.8310 - loss: 0.11842\n",
      "Epoch 45/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 46ms/step - accuracy: 0.8352 - loss: 0.11590\n",
      "\u001b[1m1732/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 47ms/step - accuracy: 0.8329 - loss: 0.1169Epoch 44/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8334 - loss: 0.11712\n",
      "\u001b[1m1997/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 38ms/step - accuracy: 0.8259 - loss: 0.1219Epoch 44/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 47ms/step - accuracy: 0.8283 - loss: 0.11972\n",
      "Epoch 44/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 40ms/step - accuracy: 0.8274 - loss: 0.12051\n",
      "\u001b[1m 7061/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 26ms/step - accuracy: 0.8275 - loss: 0.1199Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8294 - loss: 0.1188422\n",
      "Epoch 43/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 27ms/step - accuracy: 0.8234 - loss: 0.1223\n",
      "\u001b[1m21675/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 26ms/step - accuracy: 0.8181 - loss: 0.1263Epoch 16/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 42ms/step - accuracy: 0.8396 - loss: 0.11423\n",
      "Epoch 51/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 30ms/step - accuracy: 0.8294 - loss: 0.11923\n",
      "Epoch 29/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 42ms/step - accuracy: 0.8329 - loss: 0.11794\n",
      "Epoch 48/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 35ms/step - accuracy: 0.8292 - loss: 0.11914\n",
      "\u001b[1m3077/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - accuracy: 0.8301 - loss: 0.1190Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 36ms/step - accuracy: 0.8293 - loss: 0.11894\n",
      "\u001b[1m 800/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 47ms/step - accuracy: 0.8303 - loss: 0.1178Epoch 28/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 47ms/step - accuracy: 0.8317 - loss: 0.11773\n",
      "Epoch 42/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 47ms/step - accuracy: 0.8351 - loss: 0.11594\n",
      "Epoch 45/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 47ms/step - accuracy: 0.8368 - loss: 0.11523\n",
      "Epoch 46/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 48ms/step - accuracy: 0.8335 - loss: 0.11681\n",
      "\u001b[1m2239/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 49ms/step - accuracy: 0.8340 - loss: 0.1168Epoch 45/75\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m787s\u001b[0m 26ms/step - accuracy: 0.8199 - loss: 0.1248\n",
      "Epoch 10/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8299 - loss: 0.11914\n",
      "\u001b[1m14495/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.8217 - loss: 0.1237Epoch 45/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 27ms/step - accuracy: 0.8217 - loss: 0.1237\n",
      "Epoch 17/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8312 - loss: 0.11823\n",
      "Epoch 44/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 42ms/step - accuracy: 0.8400 - loss: 0.11423\n",
      "\u001b[1m 8443/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 26ms/step - accuracy: 0.8219 - loss: 0.1236Epoch 52/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 43ms/step - accuracy: 0.8323 - loss: 0.11792\n",
      "Epoch 46/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 39ms/step - accuracy: 0.8253 - loss: 0.12182\n",
      "\u001b[1m28454/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - accuracy: 0.8183 - loss: 0.1262Epoch 26/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 26ms/step - accuracy: 0.8264 - loss: 0.1205\n",
      "\u001b[1m3275/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.8329 - loss: 0.1175Epoch 18/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 24ms/step - accuracy: 0.8189 - loss: 0.1253\n",
      "Epoch 11/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 24ms/step - accuracy: 0.8208 - loss: 0.1238\n",
      "\u001b[1m2987/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m27s\u001b[0m 40ms/step - accuracy: 0.8326 - loss: 0.1176Epoch 20/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 33ms/step - accuracy: 0.8267 - loss: 0.121213\n",
      "\u001b[1m 4193/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:49\u001b[0m 28ms/step - accuracy: 0.8254 - loss: 0.1208Epoch 31/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 33ms/step - accuracy: 0.8288 - loss: 0.119716\n",
      "\u001b[1m 156/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 52ms/step - accuracy: 0.8385 - loss: 0.1140Epoch 31/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 25ms/step - accuracy: 0.8241 - loss: 0.1221\n",
      "\u001b[1m11484/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 26ms/step - accuracy: 0.8234 - loss: 0.1222Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 49ms/step - accuracy: 0.8304 - loss: 0.118414\n",
      "Epoch 45/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 50ms/step - accuracy: 0.8315 - loss: 0.117706\n",
      "\u001b[1m6292/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - accuracy: 0.8290 - loss: 0.1192Epoch 43/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 25ms/step - accuracy: 0.8220 - loss: 0.1236\n",
      "\u001b[1m2549/7353\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 29ms/step - accuracy: 0.8315 - loss: 0.1181Epoch 20/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 29ms/step - accuracy: 0.8226 - loss: 0.1232\n",
      "Epoch 17/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 40ms/step - accuracy: 0.8325 - loss: 0.117796\n",
      "Epoch 47/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 25ms/step - accuracy: 0.8244 - loss: 0.1224\n",
      "Epoch 18/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8369 - loss: 0.114826\n",
      "Epoch 47/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8348 - loss: 0.11651123\n",
      "\u001b[1m3601/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8292 - loss: 0.1196Epoch 46/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8292 - loss: 0.119656\n",
      "Epoch 46/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 48ms/step - accuracy: 0.8314 - loss: 0.118243\n",
      "\u001b[1m5984/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m48s\u001b[0m 35ms/step - accuracy: 0.8291 - loss: 0.1190Epoch 45/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 33ms/step - accuracy: 0.8289 - loss: 0.119325\n",
      "Epoch 30/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 48ms/step - accuracy: 0.8344 - loss: 0.11645\n",
      "\u001b[1m 9991/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 26ms/step - accuracy: 0.8242 - loss: 0.1221Epoch 46/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8328 - loss: 0.11681\n",
      "Epoch 44/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 30ms/step - accuracy: 0.8313 - loss: 0.11830\n",
      "\u001b[1m 8761/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 24ms/step - accuracy: 0.8273 - loss: 0.1199Epoch 31/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 38ms/step - accuracy: 0.8253 - loss: 0.12155\n",
      "\u001b[1m 6024/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 25ms/step - accuracy: 0.8252 - loss: 0.1218Epoch 27/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 48ms/step - accuracy: 0.8317 - loss: 0.11721\n",
      "Epoch 46/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 28ms/step - accuracy: 0.8212 - loss: 0.1235\n",
      "\u001b[1m10927/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 24ms/step - accuracy: 0.8251 - loss: 0.1216Epoch 18/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 30ms/step - accuracy: 0.8299 - loss: 0.11872\n",
      "\u001b[1m 286/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:54\u001b[0m 42ms/step - accuracy: 0.8341 - loss: 0.1186Epoch 32/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 26ms/step - accuracy: 0.8242 - loss: 0.1222\n",
      "Epoch 20/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 39ms/step - accuracy: 0.8271 - loss: 0.12061\n",
      "\u001b[1m10298/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 25ms/step - accuracy: 0.8248 - loss: 0.1216Epoch 27/100\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/steptep - accuracy: 0.8318 - loss: 0.11825\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 49ms/step - accuracy: 0.8317 - loss: 0.11773\n",
      "\u001b[1m6166/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - accuracy: 0.8309 - loss: 0.1182Epoch 44/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 25ms/step - accuracy: 0.8247 - loss: 0.1217\n",
      "\u001b[1m11738/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 25ms/step - accuracy: 0.8253 - loss: 0.1216Epoch 21/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 24ms/step - accuracy: 0.8271 - loss: 0.1201\n",
      "\u001b[1m1282/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10\u001b[0m 41ms/step - accuracy: 0.8299 - loss: 0.1190Epoch 21/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 33ms/step - accuracy: 0.8281 - loss: 0.12015\n",
      "\u001b[1m 2095/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:54\u001b[0m 23ms/step - accuracy: 0.8254 - loss: 0.1220Epoch 31/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 25ms/step - accuracy: 0.8255 - loss: 0.12153\n",
      "Epoch 21/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 47ms/step - accuracy: 0.8380 - loss: 0.11453\n",
      "Epoch 48/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 49ms/step - accuracy: 0.8340 - loss: 0.11625\n",
      "\u001b[1m 5936/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:50\u001b[0m 26ms/step - accuracy: 0.8250 - loss: 0.1215Epoch 45/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 35ms/step - accuracy: 0.8318 - loss: 0.1178532━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.8252 - loss:\n",
      "\u001b[1m3443/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.8324 - loss: 0.1171Epoch 30/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 35ms/step - accuracy: 0.8308 - loss: 0.11822\n",
      "\u001b[1m13500/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - accuracy: 0.8252 - loss: 0.1216Epoch 32/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8323 - loss: 0.11719\n",
      "Epoch 47/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 26ms/step - accuracy: 0.8261 - loss: 0.1208\n",
      "Epoch 20/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 48ms/step - accuracy: 0.8306 - loss: 0.11894\n",
      "Epoch 48/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 29ms/step - accuracy: 0.8227 - loss: 0.12325━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 35ms/step - accuracy: 0\n",
      "\u001b[1m 335/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 48ms/step - accuracy: 0.8390 - loss: 0.1122Epoch 18/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 39ms/step - accuracy: 0.8262 - loss: 0.12132\n",
      "Epoch 28/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 32ms/step - accuracy: 0.8262 - loss: 0.12111\n",
      "\u001b[1m 4401/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 22ms/step - accuracy: 0.8198 - loss: 0.1239Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 38ms/step - accuracy: 0.8276 - loss: 0.12070\n",
      "\u001b[1m 1023/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:35\u001b[0m 29ms/step - accuracy: 0.8214 - loss: 0.1234Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 49ms/step - accuracy: 0.8354 - loss: 0.11664\n",
      "Epoch 45/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 34ms/step - accuracy: 0.8309 - loss: 0.1185522\n",
      "\u001b[1m1445/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 38ms/step - accuracy: 0.8336 - loss: 0.1173Epoch 33/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8390 - loss: 0.11401\n",
      "\u001b[1m 404/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 33ms/step - accuracy: 0.8290 - loss: 0.1189Epoch 49/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 50ms/step - accuracy: 0.8314 - loss: 0.118320\n",
      "\u001b[1m  817/29412\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:56\u001b[0m 23ms/step - accuracy: 0.8182 - loss: 0.1229Epoch 49/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 28ms/step - accuracy: 0.8229 - loss: 0.1228\n",
      "\u001b[1m1173/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:55\u001b[0m 38ms/step - accuracy: 0.8293 - loss: 0.1187Epoch 19/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 49ms/step - accuracy: 0.8335 - loss: 0.11695\n",
      "Epoch 46/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 23ms/step - accuracy: 0.8186 - loss: 0.1255\n",
      "\u001b[1m26772/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:07\u001b[0m 25ms/step - accuracy: 0.8183 - loss: 0.1259Epoch 12/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 23ms/step - accuracy: 0.8287 - loss: 0.1199\n",
      "\u001b[1m 884/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 45ms/step - accuracy: 0.8357 - loss: 0.1157Epoch 22/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 29ms/step - accuracy: 0.8308 - loss: 0.1181231��━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:16\u001b[0m 23ms/step \n",
      "Epoch 34/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 26ms/step - accuracy: 0.8209 - loss: 0.1241\n",
      "\u001b[1m  414/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 22ms/step - accuracy: 0.8299 - loss: 0.1207Epoch 11/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 49ms/step - accuracy: 0.8344 - loss: 0.11653\n",
      "\u001b[1m14538/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8267 - loss: 0.1205Epoch 46/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 24ms/step - accuracy: 0.8259 - loss: 0.1212\n",
      "\u001b[1m5299/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 32ms/step - accuracy: 0.8279 - loss: 0.1203Epoch 22/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 27ms/step - accuracy: 0.8267 - loss: 0.1205\n",
      "Epoch 20/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8395 - loss: 0.11422\n",
      "Epoch 50/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 42ms/step - accuracy: 0.8427 - loss: 0.11265\n",
      "\u001b[1m11550/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 24ms/step - accuracy: 0.8233 - loss: 0.1231Epoch 57/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 24ms/step - accuracy: 0.8262 - loss: 0.1209\n",
      "\u001b[1m13232/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.8244 - loss: 0.1218Epoch 22/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 23ms/step - accuracy: 0.8198 - loss: 0.1250\n",
      "\u001b[1m 2338/29412\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:44\u001b[0m 22ms/step - accuracy: 0.8193 - loss: 0.1247Epoch 12/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 25ms/step - accuracy: 0.8184 - loss: 0.1259\n",
      "\u001b[1m1930/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 46ms/step - accuracy: 0.8393 - loss: 0.1138Epoch 11/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 27ms/step - accuracy: 0.8238 - loss: 0.1221\n",
      "\u001b[1m  519/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:28\u001b[0m 23ms/step - accuracy: 0.8342 - loss: 0.1134Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.1234\n",
      "Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 47ms/step - accuracy: 0.8320 - loss: 0.11710\n",
      "\u001b[1m2666/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - accuracy: 0.8378 - loss: 0.1147Epoch 49/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 46ms/step - accuracy: 0.8317 - loss: 0.118376\n",
      "\u001b[1m 4272/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:20\u001b[0m 25ms/step - accuracy: 0.8249 - loss: 0.1218Epoch 50/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 32ms/step - accuracy: 0.8294 - loss: 0.119456\n",
      "\u001b[1m 187/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 45ms/step - accuracy: 0.8321 - loss: 0.1166Epoch 33/50\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step/step - accuracy: 0.8257 - loss: 0.1205\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 44ms/step - accuracy: 0.8394 - loss: 0.11381\n",
      "Epoch 51/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8346 - loss: 0.11633\n",
      "Epoch 47/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 41ms/step - accuracy: 0.8427 - loss: 0.11280\n",
      "Epoch 58/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 34ms/step - accuracy: 0.8312 - loss: 0.11805\n",
      "\u001b[1m11238/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:34\u001b[0m 22ms/step - accuracy: 0.8199 - loss: 0.1238Epoch 32/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 37ms/step - accuracy: 0.8289 - loss: 0.11925\n",
      "Epoch 31/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 28ms/step - accuracy: 0.8235 - loss: 0.1230\n",
      "Epoch 19/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 34ms/step - accuracy: 0.8312 - loss: 0.11771\n",
      "\u001b[1m 7625/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 22ms/step - accuracy: 0.8302 - loss: 0.1179Epoch 34/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 45ms/step - accuracy: 0.8331 - loss: 0.11704\n",
      "Epoch 50/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 45ms/step - accuracy: 0.8351 - loss: 0.11602\n",
      "Epoch 48/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 44ms/step - accuracy: 0.8311 - loss: 0.11862\n",
      "\u001b[1m5923/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m50s\u001b[0m 35ms/step - accuracy: 0.8254 - loss: 0.1215Epoch 51/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 22ms/step - accuracy: 0.8252 - loss: 0.1216\n",
      "Epoch 21/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 31ms/step - accuracy: 0.8316 - loss: 0.11821\n",
      "Epoch 35/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 43ms/step - accuracy: 0.8412 - loss: 0.11312\n",
      "Epoch 52/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 31ms/step - accuracy: 0.8292 - loss: 0.11970\n",
      "\u001b[1m13026/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8275 - loss: 0.1202Epoch 35/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 46ms/step - accuracy: 0.8367 - loss: 0.11574\n",
      "\u001b[1m 2919/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:03\u001b[0m 26ms/step - accuracy: 0.8279 - loss: 0.1199Epoch 48/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 23ms/step - accuracy: 0.8254 - loss: 0.1208\n",
      "\u001b[1m14605/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8294 - loss: 0.1186Epoch 23/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 29ms/step - accuracy: 0.8321 - loss: 0.11782\n",
      "Epoch 35/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 22ms/step - accuracy: 0.8294 - loss: 0.1186\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8231 - loss: 0.1228\n",
      "\u001b[1m2081/3677\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 44ms/step - accuracy: 0.8333 - loss: 0.1172Epoch 23/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 36ms/step - accuracy: 0.8285 - loss: 0.11973\n",
      "Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 35ms/step - accuracy: 0.8256 - loss: 0.12143\n",
      "Epoch 30/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 23ms/step - accuracy: 0.8258 - loss: 0.1210\n",
      "\u001b[1m12882/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8246 - loss: 0.1221Epoch 23/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 26ms/step - accuracy: 0.8222 - loss: 0.1235\n",
      "\u001b[1m13000/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8246 - loss: 0.1221Epoch 20/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 36ms/step - accuracy: 0.8300 - loss: 0.11880\n",
      "\u001b[1m1926/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 28ms/step - accuracy: 0.8351 - loss: 0.1167Epoch 32/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 28ms/step - accuracy: 0.8312 - loss: 0.11833\n",
      "Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 47ms/step - accuracy: 0.8347 - loss: 0.11646\n",
      "Epoch 49/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 23ms/step - accuracy: 0.8230 - loss: 0.1229\n",
      "Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 46ms/step - accuracy: 0.8347 - loss: 0.11660\n",
      "\u001b[1m25578/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:20\u001b[0m 21ms/step - accuracy: 0.8205 - loss: 0.1238Epoch 51/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8327 - loss: 0.11802\n",
      "Epoch 52/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 46ms/step - accuracy: 0.8353 - loss: 0.11600\n",
      "Epoch 49/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 41ms/step - accuracy: 0.8435 - loss: 0.11200\n",
      "\u001b[1m4539/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 37ms/step - accuracy: 0.8292 - loss: 0.1195Epoch 60/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 38ms/step - accuracy: 0.8286 - loss: 0.11975\n",
      "Epoch 31/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8371 - loss: 0.11513\n",
      "\u001b[1m29222/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8200 - loss: 0.1248Epoch 50/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 21ms/step - accuracy: 0.8200 - loss: 0.1248\n",
      "Epoch 13/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 26ms/step - accuracy: 0.8271 - loss: 0.1210\n",
      "Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8322 - loss: 0.11781\n",
      "Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8297 - loss: 0.1186\n",
      "Epoch 24/25\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 35ms/step - accuracy: 0.8312 - loss: 0.118295\n",
      "\u001b[1m2069/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 32ms/step - accuracy: 0.8347 - loss: 0.1162Epoch 35/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 22ms/step - accuracy: 0.8236 - loss: 0.12242\n",
      "\u001b[1m5669/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 39ms/step - accuracy: 0.8305 - loss: 0.1185Epoch 24/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 42ms/step - accuracy: 0.8431 - loss: 0.1122922\n",
      "\u001b[1m2253/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 47ms/step - accuracy: 0.8409 - loss: 0.1133Epoch 61/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 49ms/step - accuracy: 0.8330 - loss: 0.117124\n",
      "Epoch 52/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8369 - loss: 0.1152125\n",
      "Epoch 50/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 36ms/step - accuracy: 0.8344 - loss: 0.116804\n",
      "\u001b[1m 7358/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 25ms/step - accuracy: 0.8227 - loss: 0.1236Epoch 34/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 37ms/step - accuracy: 0.8320 - loss: 0.11752454[0m 24ms\n",
      "Epoch 36/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 30ms/step - accuracy: 0.8246 - loss: 0.1219\n",
      "\u001b[1m 7014/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 26ms/step - accuracy: 0.8262 - loss: 0.1208Epoch 21/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 29ms/step - accuracy: 0.8268 - loss: 0.1204\n",
      "\u001b[1m 6261/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 31ms/step - accuracy: 0.8268 - loss: 0.1199Epoch 22/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 35ms/step - accuracy: 0.8341 - loss: 0.11690\n",
      "\u001b[1m10561/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7:42\u001b[0m 25ms/step - accuracy: 0.8229 - loss: 0.1225Epoch 37/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 29ms/step - accuracy: 0.8233 - loss: 0.1224\n",
      "\u001b[1m 2493/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:06\u001b[0m 25ms/step - accuracy: 0.8276 - loss: 0.1201Epoch 21/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 49ms/step - accuracy: 0.8321 - loss: 0.118103\n",
      "Epoch 54/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 28ms/step - accuracy: 0.8292 - loss: 0.1194\n",
      "Epoch 23/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 32ms/step - accuracy: 0.8343 - loss: 0.11669\n",
      "\u001b[1m 747/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:22\u001b[0m 31ms/step - accuracy: 0.8397 - loss: 0.1146Epoch 37/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 43ms/step - accuracy: 0.8440 - loss: 0.111623\n",
      "Epoch 62/75\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 25ms/step - accuracy: 0.8184 - loss: 0.1258\n",
      "\u001b[1m 8601/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 26ms/step - accuracy: 0.8263 - loss: 0.1208Epoch 12/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 49ms/step - accuracy: 0.8368 - loss: 0.11482\n",
      "Epoch 51/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 25ms/step - accuracy: 0.8272 - loss: 0.1208\n",
      "Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 48ms/step - accuracy: 0.8340 - loss: 0.116903\n",
      "\u001b[1m5304/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 36ms/step - accuracy: 0.8308 - loss: 0.1184Epoch 53/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 48ms/step - accuracy: 0.8376 - loss: 0.115223\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 33ms/step - accuracy: 0.8285 - loss: 0.119503\n",
      "Epoch 37/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 25ms/step - accuracy: 0.8233 - loss: 0.1232\n",
      "\u001b[1m895/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepEpoch 24/100\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step/step - accuracy: 0.8272 - loss: 0.120\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 23ms/step - accuracy: 0.8296 - loss: 0.1187\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 29ms/step - accuracy: 0.8241 - loss: 0.1223\n",
      "Epoch 21/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 23ms/step - accuracy: 0.8245 - loss: 0.1220\n",
      "\u001b[1m3625/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8359 - loss: 0.1155Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 45ms/step - accuracy: 0.8359 - loss: 0.11558\n",
      "\u001b[1m  465/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:22\u001b[0m 27ms/step - accuracy: 0.8265 - loss: 0.1209Epoch 52/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 27ms/step - accuracy: 0.8264 - loss: 0.1203\n",
      "\u001b[1m6720/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.8308 - loss: 0.1186Epoch 21/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 46ms/step - accuracy: 0.8338 - loss: 0.11738\n",
      "\u001b[1m 7582/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 26ms/step - accuracy: 0.8242 - loss: 0.1218Epoch 55/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 41ms/step - accuracy: 0.8442 - loss: 0.11190\n",
      "Epoch 63/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 36ms/step - accuracy: 0.8308 - loss: 0.11853\n",
      "Epoch 34/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 32ms/step - accuracy: 0.8347 - loss: 0.11684\n",
      "\u001b[1m3712/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 28ms/step - accuracy: 0.8318 - loss: 0.1175Epoch 38/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 45ms/step - accuracy: 0.8335 - loss: 0.117035\n",
      "\u001b[1m 8694/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 25ms/step - accuracy: 0.8273 - loss: 0.1203Epoch 54/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 46ms/step - accuracy: 0.8344 - loss: 0.11619\n",
      "Epoch 55/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 32ms/step - accuracy: 0.8322 - loss: 0.11798\n",
      "\u001b[1m3876/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 27ms/step - accuracy: 0.8341 - loss: 0.1166Epoch 37/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 45ms/step - accuracy: 0.8377 - loss: 0.11490\n",
      "Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 22ms/step - accuracy: 0.8257 - loss: 0.1210\n",
      "Epoch 23/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 41ms/step - accuracy: 0.8444 - loss: 0.11170\n",
      "Epoch 64/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 35ms/step - accuracy: 0.8282 - loss: 0.11980\n",
      "\u001b[1m4355/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 27ms/step - accuracy: 0.8341 - loss: 0.1166Epoch 33/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 26ms/step - accuracy: 0.8245 - loss: 0.1217\n",
      "Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 44ms/step - accuracy: 0.8332 - loss: 0.11729\n",
      "Epoch 56/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 36ms/step - accuracy: 0.8305 - loss: 0.11924\n",
      "\u001b[1m 6990/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 21ms/step - accuracy: 0.8309 - loss: 0.1179Epoch 33/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 22ms/step - accuracy: 0.8225 - loss: 0.1231\n",
      "\u001b[1m10754/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 21ms/step - accuracy: 0.8282 - loss: 0.1196Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 24ms/step - accuracy: 0.8275 - loss: 0.1201\n",
      "\u001b[1m17049/29412\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 24ms/step - accuracy: 0.8210 - loss: 0.1241Epoch 24/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 21ms/step - accuracy: 0.8192 - loss: 0.1254\n",
      "Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 25ms/step - accuracy: 0.8276 - loss: 0.1197\n",
      "\u001b[1m3291/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 27ms/step - accuracy: 0.8302 - loss: 0.1190Epoch 23/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 33ms/step - accuracy: 0.8334 - loss: 0.11670\n",
      "Epoch 36/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 25ms/step - accuracy: 0.8244 - loss: 0.1217\n",
      "\u001b[1m4838/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 31ms/step - accuracy: 0.8359 - loss: 0.1160Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 43ms/step - accuracy: 0.8343 - loss: 0.11649\n",
      "\u001b[1m 2848/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 22ms/step - accuracy: 0.8292 - loss: 0.1197Epoch 55/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 33ms/step - accuracy: 0.8343 - loss: 0.11640\n",
      "Epoch 38/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 23ms/step - accuracy: 0.8255 - loss: 0.1217\n",
      "\u001b[1m 1205/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 22ms/step - accuracy: 0.8308 - loss: 0.1202Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 41ms/step - accuracy: 0.8341 - loss: 0.11601\n",
      "\u001b[1m1429/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 40ms/step - accuracy: 0.8369 - loss: 0.1153Epoch 56/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 23ms/step - accuracy: 0.8271 - loss: 0.1202\n",
      "\u001b[1m 939/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 39ms/step - accuracy: 0.8438 - loss: 0.1112Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 21ms/step - accuracy: 0.8310 - loss: 0.1181\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 25ms/step - accuracy: 0.8257 - loss: 0.1216\n",
      "\u001b[1m5420/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 29ms/step - accuracy: 0.8337 - loss: 0.1164Epoch 22/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 41ms/step - accuracy: 0.8386 - loss: 0.11411\n",
      "\u001b[1m 7203/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 23ms/step - accuracy: 0.8249 - loss: 0.1215Epoch 54/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 9ms/stepep - accuracy: 0.8375 - loss: 0.11120\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 41ms/step - accuracy: 0.8342 - loss: 0.11721\n",
      "Epoch 57/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 39ms/step - accuracy: 0.8347 - loss: 0.11630\n",
      "Epoch 56/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/stepstep - accuracy: 0.8180 - loss: 0.123\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 22ms/step - accuracy: 0.8275 - loss: 0.1204\n",
      "\u001b[1m2835/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 31ms/step - accuracy: 0.8281 - loss: 0.1194Epoch 24/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.8286 - loss: 0.1195\n",
      "Epoch 25/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 22ms/step - accuracy: 0.8291 - loss: 0.1197\n",
      "\u001b[1m11206/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 21ms/step - accuracy: 0.8280 - loss: 0.1200Epoch 24/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 23ms/step - accuracy: 0.8255 - loss: 0.1216\n",
      "Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 39ms/step - accuracy: 0.8351 - loss: 0.11620\n",
      "\u001b[1m2751/7353\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 29ms/step - accuracy: 0.8342 - loss: 0.1166Epoch 58/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 28ms/step - accuracy: 0.8354 - loss: 0.11610\n",
      "\u001b[1m5073/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 30ms/step - accuracy: 0.8299 - loss: 0.1193Epoch 40/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 22ms/step - accuracy: 0.8252 - loss: 0.1216\n",
      "\u001b[1m3624/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 31ms/step - accuracy: 0.8283 - loss: 0.1193Epoch 23/25\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 22ms/step - accuracy: 0.8198 - loss: 0.1251\n",
      "\u001b[1m16204/29412\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:34\u001b[0m 21ms/step - accuracy: 0.8221 - loss: 0.1231Epoch 13/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 38ms/step - accuracy: 0.8346 - loss: 0.11671\n",
      "Epoch 57/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 32ms/step - accuracy: 0.8326 - loss: 0.11780\n",
      "\u001b[1m 1179/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:41\u001b[0m 21ms/step - accuracy: 0.8317 - loss: 0.1175Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 39ms/step - accuracy: 0.8347 - loss: 0.11570\n",
      "Epoch 57/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 23ms/step - accuracy: 0.8252 - loss: 0.1218\n",
      "Epoch 26/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 39ms/step - accuracy: 0.8390 - loss: 0.11390\n",
      "\u001b[1m 3756/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:58\u001b[0m 22ms/step - accuracy: 0.8257 - loss: 0.1212Epoch 55/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.8379 - loss: 0.11419\n",
      "Epoch 56/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 38ms/step - accuracy: 0.8369 - loss: 0.11541\n",
      "Epoch 57/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 39ms/step - accuracy: 0.8351 - loss: 0.11555\n",
      "Epoch 58/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 23ms/step - accuracy: 0.8263 - loss: 0.1217\n",
      "Epoch 23/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 21ms/step - accuracy: 0.8270 - loss: 0.1205\n",
      "\u001b[1m 799/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 38ms/step - accuracy: 0.8365 - loss: 0.1151Epoch 23/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 38ms/step - accuracy: 0.8370 - loss: 0.11544\n",
      "\u001b[1m 5717/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 20ms/step - accuracy: 0.8286 - loss: 0.1199Epoch 58/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 39ms/step - accuracy: 0.8349 - loss: 0.11640\n",
      "Epoch 59/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 36ms/step - accuracy: 0.8448 - loss: 0.11133\n",
      "\u001b[1m2266/3677\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 39ms/step - accuracy: 0.8415 - loss: 0.1125Epoch 68/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 22ms/step - accuracy: 0.8265 - loss: 0.1205\n",
      "\u001b[1m 111/3677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 40ms/step - accuracy: 0.8393 - loss: 0.1126Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 40ms/step - accuracy: 0.8378 - loss: 0.11504\n",
      "\u001b[1m 9681/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 21ms/step - accuracy: 0.8297 - loss: 0.1190Epoch 59/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 27ms/step - accuracy: 0.8351 - loss: 0.11599\n",
      "Epoch 41/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 38ms/step - accuracy: 0.8439 - loss: 0.11180\n",
      "\u001b[1m20838/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 20ms/step - accuracy: 0.8202 - loss: 0.1246Epoch 60/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 40ms/step - accuracy: 0.8376 - loss: 0.11469\n",
      "\u001b[1m15015/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4:42\u001b[0m 20ms/step - accuracy: 0.8213 - loss: 0.1236Epoch 56/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 40ms/step - accuracy: 0.8380 - loss: 0.11425\n",
      "Epoch 57/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 31ms/step - accuracy: 0.8328 - loss: 0.11744\n",
      "\u001b[1m13269/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 22ms/step - accuracy: 0.8270 - loss: 0.1205Epoch 37/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 41ms/step - accuracy: 0.8369 - loss: 0.11560\n",
      "Epoch 60/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 32ms/step - accuracy: 0.8293 - loss: 0.11919\n",
      "Epoch 36/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 22ms/step - accuracy: 0.8259 - loss: 0.1215\n",
      "Epoch 27/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 39ms/step - accuracy: 0.8436 - loss: 0.11191\n",
      "Epoch 61/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 31ms/step - accuracy: 0.8325 - loss: 0.11859\n",
      "\u001b[1m3516/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 29ms/step - accuracy: 0.8357 - loss: 0.1159Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 40ms/step - accuracy: 0.8357 - loss: 0.11569\n",
      "\u001b[1m 4464/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:41\u001b[0m 21ms/step - accuracy: 0.8240 - loss: 0.1223Epoch 59/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 29ms/step - accuracy: 0.8342 - loss: 0.11699\n",
      "\u001b[1m 4538/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:40\u001b[0m 21ms/step - accuracy: 0.8240 - loss: 0.1223Epoch 40/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 21ms/step - accuracy: 0.8292 - loss: 0.1194\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 20ms/step - accuracy: 0.8205 - loss: 0.1244\n",
      "\u001b[1m3386/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 33ms/step - accuracy: 0.8342 - loss: 0.1169Epoch 15/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 40ms/step - accuracy: 0.8388 - loss: 0.11429\n",
      "\u001b[1m22481/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 20ms/step - accuracy: 0.8213 - loss: 0.1237Epoch 57/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 30ms/step - accuracy: 0.8356 - loss: 0.11599\n",
      "\u001b[1m 7516/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 24ms/step - accuracy: 0.8271 - loss: 0.1209Epoch 41/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 41ms/step - accuracy: 0.8420 - loss: 0.11279\n",
      "\u001b[1m1364/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 41ms/step - accuracy: 0.8383 - loss: 0.1150Epoch 61/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 28ms/step - accuracy: 0.8350 - loss: 0.11639\n",
      "Epoch 42/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 28ms/step - accuracy: 0.8343 - loss: 0.11630\n",
      "\u001b[1m11082/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 22ms/step - accuracy: 0.8305 - loss: 0.1189Epoch 43/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 20ms/step - accuracy: 0.8212 - loss: 0.1237\n",
      "Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 22ms/step - accuracy: 0.8285 - loss: 0.1199\n",
      "Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 38ms/step - accuracy: 0.8420 - loss: 0.11253\n",
      "Epoch 62/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 23ms/step - accuracy: 0.8268 - loss: 0.1210\n",
      "Epoch 24/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 30ms/step - accuracy: 0.8359 - loss: 0.11582\n",
      "\u001b[1m10551/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 22ms/step - accuracy: 0.8270 - loss: 0.1208Epoch 40/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 28ms/step - accuracy: 0.8353 - loss: 0.11643\n",
      "Epoch 41/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 22ms/step - accuracy: 0.8275 - loss: 0.1201\n",
      "\u001b[1m6108/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - accuracy: 0.8366 - loss: 0.1155Epoch 28/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 31ms/step - accuracy: 0.8309 - loss: 0.11850\n",
      "Epoch 37/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 38ms/step - accuracy: 0.8401 - loss: 0.11352\n",
      "Epoch 58/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 38ms/step - accuracy: 0.8399 - loss: 0.11330\n",
      "\u001b[1m 476/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 29ms/step - accuracy: 0.8291 - loss: 0.1193Epoch 59/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 20ms/step - accuracy: 0.8195 - loss: 0.1252\n",
      "Epoch 14/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 21ms/step - accuracy: 0.8302 - loss: 0.1191\n",
      "Epoch 27/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 31ms/step - accuracy: 0.8330 - loss: 0.11793\n",
      "Epoch 37/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 34ms/step - accuracy: 0.8458 - loss: 0.11084\n",
      "Epoch 71/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 40ms/step - accuracy: 0.8377 - loss: 0.11471\n",
      "Epoch 61/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 28ms/step - accuracy: 0.8361 - loss: 0.11592\n",
      "\u001b[1m5889/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.8358 - loss: 0.1156Epoch 43/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 36ms/step - accuracy: 0.8467 - loss: 0.11029\n",
      "\u001b[1m10886/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 21ms/step - accuracy: 0.8281 - loss: 0.1197Epoch 72/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 40ms/step - accuracy: 0.8389 - loss: 0.1137\n",
      "Epoch 59/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 40ms/step - accuracy: 0.8398 - loss: 0.11321\n",
      "\u001b[1m 6057/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 21ms/step - accuracy: 0.8315 - loss: 0.1178Epoch 60/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 31ms/step - accuracy: 0.8345 - loss: 0.11674\n",
      "Epoch 39/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 29ms/step - accuracy: 0.8304 - loss: 0.11881\n",
      "Epoch 43/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 39ms/step - accuracy: 0.8389 - loss: 0.11422\n",
      "Epoch 62/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 28ms/step - accuracy: 0.8357 - loss: 0.11569\n",
      "Epoch 44/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 38ms/step - accuracy: 0.8376 - loss: 0.11499\n",
      "\u001b[1m1071/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 39ms/step - accuracy: 0.8405 - loss: 0.1129Epoch 62/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 39ms/step - accuracy: 0.8363 - loss: 0.11598\n",
      "\u001b[1m 7381/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 21ms/step - accuracy: 0.8292 - loss: 0.1194Epoch 63/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 30ms/step - accuracy: 0.8362 - loss: 0.11518\n",
      "Epoch 41/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 23ms/step - accuracy: 0.8271 - loss: 0.1211\n",
      "\u001b[1m12160/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.8306 - loss: 0.1183Epoch 25/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 21ms/step - accuracy: 0.8282 - loss: 0.1199\n",
      "Epoch 29/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 38ms/step - accuracy: 0.8390 - loss: 0.11421\n",
      "Epoch 63/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.8296 - loss: 0.1195\n",
      "\u001b[1m1234/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 36ms/step - accuracy: 0.8511 - loss: 0.1084Epoch 28/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 21ms/step - accuracy: 0.8305 - loss: 0.1183\n",
      "Epoch 28/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 21ms/step - accuracy: 0.8286 - loss: 0.1195\n",
      "\u001b[1m1883/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 39ms/step - accuracy: 0.8378 - loss: 0.1153Epoch 29/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 37ms/step - accuracy: 0.8370 - loss: 0.11500\n",
      "Epoch 63/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 38ms/step - accuracy: 0.8446 - loss: 0.11111\n",
      "Epoch 65/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 39ms/step - accuracy: 0.8396 - loss: 0.11308\n",
      "Epoch 61/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 21ms/step - accuracy: 0.8288 - loss: 0.1196\n",
      "\u001b[1m  462/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:25\u001b[0m 23ms/step - accuracy: 0.8299 - loss: 0.1219Epoch 27/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 28ms/step - accuracy: 0.8364 - loss: 0.11570\n",
      "\u001b[1m4546/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 27ms/step - accuracy: 0.8377 - loss: 0.1147Epoch 44/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 21ms/step - accuracy: 0.8306 - loss: 0.1183\n",
      "\u001b[1m4121/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 28ms/step - accuracy: 0.8359 - loss: 0.1163Epoch 27/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 19ms/step - accuracy: 0.8222 - loss: 0.1234\n",
      "\u001b[1m5747/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - accuracy: 0.8360 - loss: 0.1152Epoch 16/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/stepep - accuracy: 0.8390 - loss: 0.11110\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 37ms/step - accuracy: 0.8408 - loss: 0.11244\n",
      "Epoch 62/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 19ms/step - accuracy: 0.8209 - loss: 0.1238\n",
      "\u001b[1m1165/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 30ms/step - accuracy: 0.8338 - loss: 0.1170Epoch 15/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 29ms/step - accuracy: 0.8361 - loss: 0.11548\n",
      "Epoch 44/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 36ms/step - accuracy: 0.8384 - loss: 0.11459\n",
      "Epoch 65/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 21ms/step - accuracy: 0.8287 - loss: 0.1191\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 37ms/step - accuracy: 0.8436 - loss: 0.11160\n",
      "\u001b[1m3878/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 27ms/step - accuracy: 0.8367 - loss: 0.1153Epoch 66/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 34ms/step - accuracy: 0.8484 - loss: 0.10989\n",
      "Epoch 75/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 21ms/step - accuracy: 0.8307 - loss: 0.1190\n",
      "\u001b[1m12766/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.8311 - loss: 0.1183Epoch 29/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 22ms/step - accuracy: 0.8282 - loss: 0.1201\n",
      "\u001b[1m4379/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 28ms/step - accuracy: 0.8367 - loss: 0.1153Epoch 26/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 30ms/step - accuracy: 0.8357 - loss: 0.11600\n",
      "Epoch 41/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 20ms/step - accuracy: 0.8313 - loss: 0.1183\n",
      "Epoch 29/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 21ms/step - accuracy: 0.8297 - loss: 0.1190\n",
      "\u001b[1m1222/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 34ms/step - accuracy: 0.8390 - loss: 0.1140Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 26ms/step - accuracy: 0.8359 - loss: 0.11562\n",
      "\u001b[1m1280/3677\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 34ms/step - accuracy: 0.8389 - loss: 0.1141Epoch 46/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 20ms/step - accuracy: 0.8291 - loss: 0.1200\n",
      "Epoch 28/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 34ms/step - accuracy: 0.8387 - loss: 0.11428\n",
      "Epoch 66/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 36ms/step - accuracy: 0.8436 - loss: 0.11170\n",
      "Epoch 67/75\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 21ms/step - accuracy: 0.8311 - loss: 0.1183\n",
      "Epoch 28/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 29ms/step - accuracy: 0.8369 - loss: 0.11493\n",
      "\u001b[1m21045/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 18ms/step - accuracy: 0.8199 - loss: 0.1246Epoch 43/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 29ms/step - accuracy: 0.8328 - loss: 0.11772\n",
      "Epoch 40/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 30ms/step - accuracy: 0.8336 - loss: 0.11763\n",
      "\u001b[1m3532/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8474 - loss: 0.1096Epoch 40/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 33ms/step - accuracy: 0.8474 - loss: 0.10963\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step/step - accuracy: 0.8300 - loss: 0.119\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 36ms/step - accuracy: 0.8437 - loss: 0.11197\n",
      "\u001b[1m6494/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.8378 - loss: 0.1149Epoch 68/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 36ms/step - accuracy: 0.8387 - loss: 0.11433\n",
      "Epoch 67/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 26ms/step - accuracy: 0.8384 - loss: 0.11478\n",
      "Epoch 46/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 26ms/step - accuracy: 0.8378 - loss: 0.11497\n",
      "\u001b[1m 5315/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 21ms/step - accuracy: 0.8304 - loss: 0.1187Epoch 47/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 18ms/step - accuracy: 0.8200 - loss: 0.1246\n",
      "Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 36ms/step - accuracy: 0.8404 - loss: 0.11317\n",
      "Epoch 64/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 27ms/step - accuracy: 0.8369 - loss: 0.11518\n",
      "Epoch 47/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 18ms/step - accuracy: 0.8241 - loss: 0.1222\n",
      "Epoch 17/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 36ms/step - accuracy: 0.8409 - loss: 0.11348\n",
      "\u001b[1m3056/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.8447 - loss: 0.1108Epoch 67/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 28ms/step - accuracy: 0.8313 - loss: 0.11853\n",
      "Epoch 46/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 36ms/step - accuracy: 0.8375 - loss: 0.11543\n",
      "Epoch 67/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 35ms/step - accuracy: 0.8396 - loss: 0.11375\n",
      "Epoch 67/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 20ms/step - accuracy: 0.8301 - loss: 0.1190\n",
      "\u001b[1m1748/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 36ms/step - accuracy: 0.8401 - loss: 0.1132Epoch 31/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 35ms/step - accuracy: 0.8448 - loss: 0.11084\n",
      "\u001b[1m10674/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 20ms/step - accuracy: 0.8317 - loss: 0.1180Epoch 69/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.8389 - loss: 0.11439\n",
      "Epoch 68/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 34ms/step - accuracy: 0.8382 - loss: 0.11516\n",
      "\u001b[1m 8568/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:04\u001b[0m 18ms/step - accuracy: 0.8227 - loss: 0.1228Epoch 68/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 26ms/step - accuracy: 0.8391 - loss: 0.11469\n",
      "Epoch 47/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 18ms/step - accuracy: 0.8221 - loss: 0.1231\n",
      "\u001b[1m13152/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.8279 - loss: 0.1204Epoch 16/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 26ms/step - accuracy: 0.8387 - loss: 0.11458\n",
      "Epoch 48/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 20ms/step - accuracy: 0.8290 - loss: 0.1196\n",
      "Epoch 28/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 33ms/step - accuracy: 0.8464 - loss: 0.11007\n",
      "\u001b[1m3382/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.8423 - loss: 0.1119Epoch 70/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 34ms/step - accuracy: 0.8380 - loss: 0.11429\n",
      "\u001b[1m  74/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 24ms/step - accuracy: 0.8469 - loss: 0.1095Epoch 67/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.8422 - loss: 0.11199\n",
      "Epoch 66/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 20ms/step - accuracy: 0.8279 - loss: 0.1204\n",
      "Epoch 31/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 26ms/step - accuracy: 0.8374 - loss: 0.11489\n",
      "\u001b[1m 785/3677\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 30ms/step - accuracy: 0.8413 - loss: 0.1131Epoch 48/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 27ms/step - accuracy: 0.8318 - loss: 0.11782\n",
      "Epoch 42/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 34ms/step - accuracy: 0.8391 - loss: 0.11438\n",
      "Epoch 69/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 34ms/step - accuracy: 0.8374 - loss: 0.11519\n",
      "Epoch 69/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 28ms/step - accuracy: 0.8368 - loss: 0.11569\n",
      "Epoch 43/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 35ms/step - accuracy: 0.8472 - loss: 0.10994\n",
      "\u001b[1m1865/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 34ms/step - accuracy: 0.8385 - loss: 0.1142Epoch 71/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 36ms/step - accuracy: 0.8389 - loss: 0.11378\n",
      "\u001b[1m3477/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.8424 - loss: 0.1116Epoch 68/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 35ms/step - accuracy: 0.8423 - loss: 0.11163\n",
      "Epoch 67/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 20ms/step - accuracy: 0.8301 - loss: 0.1190\n",
      "Epoch 32/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 35ms/step - accuracy: 0.8443 - loss: 0.11135\n",
      "\u001b[1m7347/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8376 - loss: 0.1149Epoch 71/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 25ms/step - accuracy: 0.8376 - loss: 0.11495\n",
      "Epoch 49/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 26ms/step - accuracy: 0.8388 - loss: 0.11489\n",
      "\u001b[1m21536/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 17ms/step - accuracy: 0.8202 - loss: 0.1246Epoch 48/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 19ms/step - accuracy: 0.8315 - loss: 0.1184\n",
      "\u001b[1m3445/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8392 - loss: 0.1140Epoch 31/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 20ms/step - accuracy: 0.8284 - loss: 0.1194\n",
      "\u001b[1m3875/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 26ms/step - accuracy: 0.8373 - loss: 0.1150Epoch 32/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 33ms/step - accuracy: 0.8393 - loss: 0.11404\n",
      "Epoch 70/75\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 17ms/step - accuracy: 0.8204 - loss: 0.1245\n",
      "\u001b[1m4939/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 25ms/step - accuracy: 0.8397 - loss: 0.1139Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 33ms/step - accuracy: 0.8400 - loss: 0.11352\n",
      "Epoch 71/75\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 17ms/step - accuracy: 0.8230 - loss: 0.1226\n",
      "\u001b[1m1539/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 26ms/step - accuracy: 0.8398 - loss: 0.1144Epoch 18/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 34ms/step - accuracy: 0.8412 - loss: 0.11313\n",
      "Epoch 71/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 28ms/step - accuracy: 0.8374 - loss: 0.11509\n",
      "\u001b[1m12481/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 17ms/step - accuracy: 0.8183 - loss: 0.1250Epoch 44/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 35ms/step - accuracy: 0.8430 - loss: 0.11218\n",
      "\u001b[1m1958/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 34ms/step - accuracy: 0.8367 - loss: 0.1155Epoch 68/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 27ms/step - accuracy: 0.8327 - loss: 0.11782\n",
      "\u001b[1m 547/3677\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 36ms/step - accuracy: 0.8422 - loss: 0.1118Epoch 48/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 26ms/step - accuracy: 0.8401 - loss: 0.11408\n",
      "\u001b[1m3250/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m14s\u001b[0m 34ms/step - accuracy: 0.8395 - loss: 0.1140Epoch 49/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 25ms/step - accuracy: 0.8394 - loss: 0.11416\n",
      "Epoch 50/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 34ms/step - accuracy: 0.8394 - loss: 0.11410\n",
      "\u001b[1m3544/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 26ms/step - accuracy: 0.8391 - loss: 0.1145Epoch 71/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 25ms/step - accuracy: 0.8374 - loss: 0.11506\n",
      "\u001b[1m 2651/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:56\u001b[0m 20ms/step - accuracy: 0.8292 - loss: 0.1198Epoch 50/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 34ms/step - accuracy: 0.8399 - loss: 0.11382\n",
      "Epoch 72/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 34ms/step - accuracy: 0.8399 - loss: 0.11430\n",
      "Epoch 72/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 19ms/step - accuracy: 0.8330 - loss: 0.1173\n",
      "\u001b[1m23620/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:42\u001b[0m 18ms/step - accuracy: 0.8191 - loss: 0.1248Epoch 32/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 20ms/step - accuracy: 0.8330 - loss: 0.1173\n",
      "Epoch 31/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 17ms/step - accuracy: 0.8220 - loss: 0.1233\n",
      "Epoch 17/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 19ms/step - accuracy: 0.8308 - loss: 0.1180\n",
      "Epoch 33/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 20ms/step - accuracy: 0.8300 - loss: 0.1197\n",
      "\u001b[1m 902/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 27ms/step - accuracy: 0.8316 - loss: 0.1179Epoch 29/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 28ms/step - accuracy: 0.8378 - loss: 0.11519\n",
      "\u001b[1m3553/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8474 - loss: 0.1096Epoch 45/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 26ms/step - accuracy: 0.8340 - loss: 0.11732\n",
      "Epoch 49/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 34ms/step - accuracy: 0.8474 - loss: 0.10960\n",
      "Epoch 74/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 35ms/step - accuracy: 0.8390 - loss: 0.11392\n",
      "Epoch 71/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 24ms/step - accuracy: 0.8390 - loss: 0.11439\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 35ms/step - accuracy: 0.8456 - loss: 0.11078\n",
      "Epoch 74/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 25ms/step - accuracy: 0.8366 - loss: 0.11528\n",
      "\u001b[1m15362/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 17ms/step - accuracy: 0.8213 - loss: 0.1236Epoch 51/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 26ms/step - accuracy: 0.8387 - loss: 0.11478\n",
      "Epoch 50/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 35ms/step - accuracy: 0.8431 - loss: 0.11158\n",
      "Epoch 70/100\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/stepp - accuracy: 0.8349 - loss: 0.11618\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 32ms/step - accuracy: 0.8419 - loss: 0.11327\n",
      "Epoch 73/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 33ms/step - accuracy: 0.8478 - loss: 0.10967\n",
      "Epoch 75/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 27ms/step - accuracy: 0.8355 - loss: 0.11672\n",
      "Epoch 45/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 26ms/step - accuracy: 0.8383 - loss: 0.11446\n",
      "\u001b[1m 8951/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 18ms/step - accuracy: 0.8320 - loss: 0.1181Epoch 50/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.8457 - loss: 0.11052\n",
      "Epoch 75/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 33ms/step - accuracy: 0.8402 - loss: 0.11318\n",
      "\u001b[1m6576/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8334 - loss: 0.1170Epoch 72/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 31ms/step - accuracy: 0.8424 - loss: 0.11287\n",
      "Epoch 74/75\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.8445 - loss: 0.11085\n",
      "Epoch 71/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 26ms/step - accuracy: 0.8334 - loss: 0.11707\n",
      "Epoch 45/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.8425 - loss: 0.11287\n",
      "\u001b[1m6249/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - accuracy: 0.8327 - loss: 0.1176Epoch 74/75\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 25ms/step - accuracy: 0.8326 - loss: 0.11762\n",
      "\u001b[1m1901/7353\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 28ms/step - accuracy: 0.8349 - loss: 0.1166Epoch 50/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 27ms/step - accuracy: 0.8380 - loss: 0.11479\n",
      "Epoch 46/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 34ms/step - accuracy: 0.8401 - loss: 0.11310\n",
      "Epoch 73/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 34ms/step - accuracy: 0.8432 - loss: 0.11220\n",
      "\u001b[1m 185/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 25ms/step - accuracy: 0.8405 - loss: 0.1131Epoch 75/75\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/stepep - accuracy: 0.8443 - loss: 0.111110\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 19ms/step - accuracy: 0.8340 - loss: 0.1170\n",
      "\u001b[1m1451/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 29ms/step - accuracy: 0.8411 - loss: 0.1127Epoch 33/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 26ms/step - accuracy: 0.8381 - loss: 0.11487\n",
      "Epoch 50/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.8440 - loss: 0.11146\n",
      "\u001b[1m2767/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.8407 - loss: 0.1134Epoch 72/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 27ms/step - accuracy: 0.8360 - loss: 0.11629\n",
      "Epoch 46/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 27ms/step - accuracy: 0.8401 - loss: 0.11378\n",
      "\u001b[1m 5735/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.1180Epoch 51/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 27ms/step - accuracy: 0.8337 - loss: 0.11679\n",
      "Epoch 46/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.8406 - loss: 0.11343\n",
      "\u001b[1m14107/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.8300 - loss: 0.1193Epoch 75/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 29ms/step - accuracy: 0.8399 - loss: 0.11399\n",
      "Epoch 76/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 16ms/step - accuracy: 0.8213 - loss: 0.1231\n",
      "Epoch 18/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 18ms/step - accuracy: 0.8327 - loss: 0.1180\n",
      "Epoch 34/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 28ms/step - accuracy: 0.8400 - loss: 0.11418\n",
      "\u001b[1m14956/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 15ms/step - accuracy: 0.8229 - loss: 0.1232Epoch 76/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.1182\n",
      "Epoch 33/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 23ms/step - accuracy: 0.8383 - loss: 0.11494\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 17ms/step - accuracy: 0.8303 - loss: 0.1191\n",
      "\u001b[1m 5196/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:36\u001b[0m 14ms/step - accuracy: 0.8224 - loss: 0.1227Epoch 35/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 29ms/step - accuracy: 0.8440 - loss: 0.11089\n",
      "Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 17ms/step - accuracy: 0.8315 - loss: 0.1182\n",
      "\u001b[1m6605/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.8381 - loss: 0.1141Epoch 35/100\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/stepstep - accuracy: 0.8228 - loss: 0.129\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 24ms/step - accuracy: 0.8367 - loss: 0.11579\n",
      "\u001b[1m 1515/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 16ms/step - accuracy: 0.8346 - loss: 0.1175Epoch 47/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 23ms/step - accuracy: 0.8394 - loss: 0.11399\n",
      "Epoch 52/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 21ms/step - accuracy: 0.8382 - loss: 0.11422\n",
      "Epoch 54/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 21ms/step - accuracy: 0.8336 - loss: 0.11742\n",
      "Epoch 52/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 17ms/step - accuracy: 0.8286 - loss: 0.1190\n",
      "Epoch 35/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 23ms/step - accuracy: 0.8333 - loss: 0.11685\n",
      "Epoch 47/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━���━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 18ms/step - accuracy: 0.8335 - loss: 0.1171\n",
      "\u001b[1m3622/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8397 - loss: 0.1133Epoch 33/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 28ms/step - accuracy: 0.8397 - loss: 0.11337\n",
      "Epoch 75/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 18ms/step - accuracy: 0.8301 - loss: 0.1194\n",
      "Epoch 31/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 17ms/step - accuracy: 0.8320 - loss: 0.1177\n",
      "Epoch 34/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 15ms/step - accuracy: 0.8291 - loss: 0.1196\n",
      "\u001b[1m27677/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8224 - loss: 0.1234Epoch 35/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 20ms/step - accuracy: 0.8386 - loss: 0.11427\n",
      "Epoch 55/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 21ms/step - accuracy: 0.8368 - loss: 0.11572\n",
      "Epoch 48/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 26ms/step - accuracy: 0.8444 - loss: 0.111123\n",
      "Epoch 75/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 20ms/step - accuracy: 0.8335 - loss: 0.11746\n",
      "\u001b[1m 163/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 19ms/step - accuracy: 0.8442 - loss: 0.1118Epoch 53/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 14ms/step - accuracy: 0.8223 - loss: 0.1234\n",
      "Epoch 20/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 14ms/step - accuracy: 0.8239 - loss: 0.1222\n",
      "Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 25ms/step - accuracy: 0.8454 - loss: 0.110217\n",
      "Epoch 76/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 20ms/step - accuracy: 0.8407 - loss: 0.11329\n",
      "Epoch 53/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 20ms/step - accuracy: 0.8351 - loss: 0.11609\n",
      "\u001b[1m15842/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 14ms/step - accuracy: 0.8208 - loss: 0.1236Epoch 48/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 15ms/step - accuracy: 0.8329 - loss: 0.1180\n",
      "Epoch 34/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.8402 - loss: 0.11408\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.1186\n",
      "Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 23ms/step - accuracy: 0.8406 - loss: 0.11329\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 15ms/step - accuracy: 0.8315 - loss: 0.1181\n",
      "\u001b[1m13273/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.8353 - loss: 0.1163Epoch 36/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 20ms/step - accuracy: 0.8383 - loss: 0.11434\n",
      "\u001b[1m3901/7353\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 19ms/step - accuracy: 0.8392 - loss: 0.1141Epoch 49/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 20ms/step - accuracy: 0.8351 - loss: 0.11597\n",
      "Epoch 49/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.8293 - loss: 0.1196\n",
      "\u001b[1m5787/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.8386 - loss: 0.1146Epoch 33/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 24ms/step - accuracy: 0.8410 - loss: 0.11368\n",
      "\u001b[1m 9111/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.1185Epoch 79/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 20ms/step - accuracy: 0.8342 - loss: 0.11698\n",
      "Epoch 54/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 25ms/step - accuracy: 0.8450 - loss: 0.110138\n",
      "Epoch 78/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 13ms/step - accuracy: 0.8212 - loss: 0.1235\n",
      "\u001b[1m 1476/29412\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:22\u001b[0m 14ms/step - accuracy: 0.8250 - loss: 0.1207Epoch 19/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 20ms/step - accuracy: 0.8386 - loss: 0.11457\n",
      "Epoch 50/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 20ms/step - accuracy: 0.8399 - loss: 0.11370\n",
      "Epoch 54/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 26ms/step - accuracy: 0.8461 - loss: 0.110418\n",
      "Epoch 77/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 26ms/step - accuracy: 0.8395 - loss: 0.11341\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 15ms/step - accuracy: 0.8297 - loss: 0.1192\n",
      "\u001b[1m4541/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 22ms/step - accuracy: 0.8368 - loss: 0.1161Epoch 36/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 25ms/step - accuracy: 0.8414 - loss: 0.113219\n",
      "\u001b[1m 859/7353\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 21ms/step - accuracy: 0.8434 - loss: 0.1116Epoch 80/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 19ms/step - accuracy: 0.8404 - loss: 0.11379\n",
      "\u001b[1m11138/29412\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:58\u001b[0m 13ms/step - accuracy: 0.8205 - loss: 0.1241Epoch 51/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 16ms/step - accuracy: 0.8298 - loss: 0.1195\n",
      "Epoch 33/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 15ms/step - accuracy: 0.8333 - loss: 0.1167\n",
      "Epoch 36/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 19ms/step - accuracy: 0.8410 - loss: 0.11288\n",
      "Epoch 55/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.8400 - loss: 0.114030\n",
      "\u001b[1m 3788/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 14ms/step - accuracy: 0.8362 - loss: 0.1156Epoch 81/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 23ms/step - accuracy: 0.8423 - loss: 0.11277\n",
      "\u001b[1m 4460/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 14ms/step - accuracy: 0.8361 - loss: 0.1157Epoch 81/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 13ms/step - accuracy: 0.8213 - loss: 0.1237\n",
      "Epoch 21/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 19ms/step - accuracy: 0.8349 - loss: 0.11679\n",
      "Epoch 55/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.8405 - loss: 0.113019\n",
      "\u001b[1m 1235/29412\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:13\u001b[0m 13ms/step - accuracy: 0.8253 - loss: 0.1222Epoch 80/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.8312 - loss: 0.1187\n",
      "\u001b[1m1484/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 21ms/step - accuracy: 0.8356 - loss: 0.1161Epoch 34/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 19ms/step - accuracy: 0.8390 - loss: 0.11389\n",
      "\u001b[1m  253/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 16ms/step - accuracy: 0.8316 - loss: 0.1212Epoch 58/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 13ms/step - accuracy: 0.8239 - loss: 0.1220\n",
      "Epoch 21/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.8462 - loss: 0.10995\n",
      "Epoch 80/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 20ms/step - accuracy: 0.8377 - loss: 0.11537\n",
      "\u001b[1m 1668/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 16ms/step - accuracy: 0.8330 - loss: 0.1194Epoch 51/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.8422 - loss: 0.11197\n",
      "\u001b[1m5640/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.8397 - loss: 0.1146Epoch 81/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 19ms/step - accuracy: 0.8396 - loss: 0.1138\n",
      "Epoch 59/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 13ms/step - accuracy: 0.8240 - loss: 0.1224\n",
      "Epoch 21/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 15ms/step - accuracy: 0.8335 - loss: 0.1169\n",
      "Epoch 37/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 20ms/step - accuracy: 0.8394 - loss: 0.11488\n",
      "\u001b[1m  579/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 16ms/step - accuracy: 0.8370 - loss: 0.1144Epoch 52/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 23ms/step - accuracy: 0.8426 - loss: 0.11297\n",
      "\u001b[1m 1418/29412\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:12\u001b[0m 13ms/step - accuracy: 0.8246 - loss: 0.1230Epoch 83/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 24ms/step - accuracy: 0.8463 - loss: 0.11062\n",
      "Epoch 80/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 0.1235\n",
      "Epoch 20/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.8425 - loss: 0.112386\n",
      "Epoch 83/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 15ms/step - accuracy: 0.8325 - loss: 0.1181\n",
      "\u001b[1m 4391/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 14ms/step - accuracy: 0.8292 - loss: 0.1197Epoch 37/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 15ms/step - accuracy: 0.8312 - loss: 0.1187\n",
      "Epoch 34/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 20ms/step - accuracy: 0.8384 - loss: 0.11502\n",
      "\u001b[1m10560/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 15ms/step - accuracy: 0.8317 - loss: 0.1182Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.8334 - loss: 0.1174\n",
      "Epoch 37/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 25ms/step - accuracy: 0.8414 - loss: 0.11322\n",
      "\u001b[1m13149/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.8322 - loss: 0.1178Epoch 84/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 19ms/step - accuracy: 0.8362 - loss: 0.11637\n",
      "Epoch 57/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 25ms/step - accuracy: 0.8425 - loss: 0.11267\n",
      "Epoch 84/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 14ms/step - accuracy: 0.8297 - loss: 0.1194\n",
      "Epoch 38/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 25ms/step - accuracy: 0.8462 - loss: 0.109758\n",
      "Epoch 83/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 15ms/step - accuracy: 0.8323 - loss: 0.1177\n",
      "\u001b[1m5458/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 20ms/step - accuracy: 0.8408 - loss: 0.1134Epoch 39/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 14ms/step - accuracy: 0.8230 - loss: 0.1230\n",
      "Epoch 20/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 13ms/step - accuracy: 0.8230 - loss: 0.1229\n",
      "Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 24ms/step - accuracy: 0.8429 - loss: 0.111718\n",
      "Epoch 83/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 24ms/step - accuracy: 0.8470 - loss: 0.109818\n",
      "\u001b[1m10569/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 15ms/step - accuracy: 0.8318 - loss: 0.1187Epoch 82/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.1182\n",
      "\u001b[1m1672/3677\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8408 - loss: 0.1135Epoch 39/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 14ms/step - accuracy: 0.8295 - loss: 0.1188\n",
      "Epoch 39/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 15ms/step - accuracy: 0.8363 - loss: 0.1159\n",
      "\u001b[1m17172/29412\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 13ms/step - accuracy: 0.8244 - loss: 0.1221Epoch 37/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 19ms/step - accuracy: 0.8406 - loss: 0.11352\n",
      "Epoch 54/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.8351 - loss: 0.1160\n",
      "Epoch 38/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 12ms/step - accuracy: 0.8241 - loss: 0.1221\n",
      "Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 24ms/step - accuracy: 0.8418 - loss: 0.112820\n",
      "Epoch 86/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 24ms/step - accuracy: 0.8454 - loss: 0.11047\n",
      "Epoch 83/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 19ms/step - accuracy: 0.8417 - loss: 0.11320\n",
      "\u001b[1m25333/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m53s\u001b[0m 13ms/step - accuracy: 0.8238 - loss: 0.1226Epoch 55/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 12ms/step - accuracy: 0.8246 - loss: 0.1220\n",
      "Epoch 22/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 24ms/step - accuracy: 0.8411 - loss: 0.112717\n",
      "Epoch 85/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 18ms/step - accuracy: 0.8394 - loss: 0.11383\n",
      "\u001b[1m 8538/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 15ms/step - accuracy: 0.8328 - loss: 0.1174Epoch 62/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 23ms/step - accuracy: 0.8470 - loss: 0.109429\n",
      "Epoch 86/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 22ms/step - accuracy: 0.8430 - loss: 0.11239\n",
      "\u001b[1m 5487/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 13ms/step - accuracy: 0.8289 - loss: 0.1193Epoch 86/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 18ms/step - accuracy: 0.8390 - loss: 0.11359\n",
      "Epoch 63/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.8462 - loss: 0.110223\n",
      "\u001b[1m1419/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 19ms/step - accuracy: 0.8380 - loss: 0.1152Epoch 85/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.8410 - loss: 0.113115\n",
      "Epoch 87/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 15ms/step - accuracy: 0.8316 - loss: 0.1182\n",
      "Epoch 36/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 15ms/step - accuracy: 0.8337 - loss: 0.1176\n",
      "\u001b[1m 938/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 23ms/step - accuracy: 0.8444 - loss: 0.1107Epoch 37/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 12ms/step - accuracy: 0.8233 - loss: 0.1228\n",
      "Epoch 23/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 24ms/step - accuracy: 0.8486 - loss: 0.10929\n",
      "\u001b[1m 244/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 18ms/step - accuracy: 0.8423 - loss: 0.1126Epoch 86/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 14ms/step - accuracy: 0.8346 - loss: 0.1174\n",
      "\u001b[1m10884/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.8329 - loss: 0.1172Epoch 39/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.8426 - loss: 0.112023\n",
      "Epoch 88/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.8359 - loss: 0.1156\n",
      "Epoch 40/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 14ms/step - accuracy: 0.8334 - loss: 0.1171\n",
      "Epoch 41/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.8426 - loss: 0.112424\n",
      "Epoch 89/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 18ms/step - accuracy: 0.8367 - loss: 0.11575\n",
      "Epoch 61/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 23ms/step - accuracy: 0.8478 - loss: 0.10927\n",
      "Epoch 88/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 15ms/step - accuracy: 0.8330 - loss: 0.1174\n",
      "Epoch 40/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.8328 - loss: 0.1174\n",
      "Epoch 41/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 12ms/step - accuracy: 0.8264 - loss: 0.1213\n",
      "Epoch 23/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 15ms/step - accuracy: 0.8325 - loss: 0.1184\n",
      "Epoch 37/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 21ms/step - accuracy: 0.8432 - loss: 0.112618\n",
      "Epoch 91/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8334 - loss: 0.1174\n",
      "Epoch 40/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 21ms/step - accuracy: 0.8427 - loss: 0.11273\n",
      "Epoch 90/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 18ms/step - accuracy: 0.8411 - loss: 0.11313\n",
      "\u001b[1m3471/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8427 - loss: 0.1120Epoch 62/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 21ms/step - accuracy: 0.8427 - loss: 0.11207\n",
      "\u001b[1m14569/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8359 - loss: 0.1158Epoch 90/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.8358 - loss: 0.1158\n",
      "Epoch 41/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8372 - loss: 0.1154\n",
      "Epoch 40/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 12ms/step - accuracy: 0.8221 - loss: 0.1230\n",
      "Epoch 24/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8348 - loss: 0.1162\n",
      "Epoch 42/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 17ms/step - accuracy: 0.8408 - loss: 0.11348\n",
      "Epoch 66/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8337 - loss: 0.1173\n",
      "Epoch 42/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 19ms/step - accuracy: 0.8433 - loss: 0.11179\n",
      "\u001b[1m14363/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.1183Epoch 63/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.1183\n",
      "Epoch 39/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 13ms/step - accuracy: 0.8224 - loss: 0.1234\n",
      "Epoch 22/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 18ms/step - accuracy: 0.8414 - loss: 0.11273\n",
      "\u001b[1m 6891/29412\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 13ms/step - accuracy: 0.8284 - loss: 0.1200Epoch 67/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.112015\n",
      "Epoch 92/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.1183\n",
      "\u001b[1m1154/7353\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 17ms/step - accuracy: 0.8391 - loss: 0.1138Epoch 43/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 12ms/step - accuracy: 0.8256 - loss: 0.1215\n",
      "\u001b[1m2509/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - accuracy: 0.8469 - loss: 0.1095Epoch 24/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8315 - loss: 0.1185\n",
      "Epoch 42/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.8442 - loss: 0.11180\n",
      "Epoch 93/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 24ms/step - accuracy: 0.8471 - loss: 0.10942\n",
      "Epoch 92/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 19ms/step - accuracy: 0.8383 - loss: 0.11512\n",
      "\u001b[1m13578/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.8336 - loss: 0.1175Epoch 64/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 18ms/step - accuracy: 0.8369 - loss: 0.11562\n",
      "Epoch 65/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.8478 - loss: 0.109917\n",
      "\u001b[1m 2766/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 15ms/step - accuracy: 0.8338 - loss: 0.1155Epoch 91/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 12ms/step - accuracy: 0.8236 - loss: 0.1225\n",
      "Epoch 25/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 24ms/step - accuracy: 0.8418 - loss: 0.11335\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8303 - loss: 0.1187\n",
      "Epoch 44/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 24ms/step - accuracy: 0.8468 - loss: 0.109615\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 15ms/step - accuracy: 0.8324 - loss: 0.1180\n",
      "Epoch 40/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 19ms/step - accuracy: 0.8421 - loss: 0.11265\n",
      "\u001b[1m1956/3677\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8439 - loss: 0.1114Epoch 61/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 19ms/step - accuracy: 0.8408 - loss: 0.11382\n",
      "Epoch 60/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 19ms/step - accuracy: 0.8430 - loss: 0.11213\n",
      "Epoch 65/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 19ms/step - accuracy: 0.8419 - loss: 0.11247\n",
      "Epoch 62/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 12ms/step - accuracy: 0.8269 - loss: 0.1211\n",
      "Epoch 25/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 19ms/step - accuracy: 0.8415 - loss: 0.11377\n",
      "Epoch 61/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 19ms/step - accuracy: 0.8433 - loss: 0.11215\n",
      "Epoch 66/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.8491 - loss: 0.108183\n",
      "\u001b[1m4092/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 18ms/step - accuracy: 0.8374 - loss: 0.1155Epoch 96/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 19ms/step - accuracy: 0.8420 - loss: 0.11255\n",
      "\u001b[1m 331/3677\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 28ms/step - accuracy: 0.8470 - loss: 0.1084Epoch 70/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8297 - loss: 0.1187\n",
      "Epoch 45/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 24ms/step - accuracy: 0.8431 - loss: 0.11186\n",
      "Epoch 95/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.1227\n",
      "Epoch 23/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 19ms/step - accuracy: 0.8438 - loss: 0.11180\n",
      "Epoch 67/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 18ms/step - accuracy: 0.8416 - loss: 0.11298\n",
      "Epoch 71/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.1177\n",
      "\u001b[1m11615/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 15ms/step - accuracy: 0.8370 - loss: 0.1157Epoch 44/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 12ms/step - accuracy: 0.8241 - loss: 0.1223\n",
      "Epoch 26/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 23ms/step - accuracy: 0.8435 - loss: 0.11216\n",
      "\u001b[1m14127/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8381 - loss: 0.1148Epoch 96/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8355 - loss: 0.1159\n",
      "\u001b[1m 7571/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:40\u001b[0m 13ms/step - accuracy: 0.8229 - loss: 0.1223Epoch 45/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 23ms/step - accuracy: 0.8442 - loss: 0.111802\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 15ms/step - accuracy: 0.8381 - loss: 0.1148\n",
      "Epoch 43/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 24ms/step - accuracy: 0.8489 - loss: 0.108321\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 15ms/step - accuracy: 0.8344 - loss: 0.1173\n",
      "\u001b[1m 8679/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:23\u001b[0m 13ms/step - accuracy: 0.8228 - loss: 0.1223Epoch 41/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 18ms/step - accuracy: 0.8375 - loss: 0.11476\n",
      "Epoch 68/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 15ms/step - accuracy: 0.8368 - loss: 0.1158\n",
      "Epoch 44/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.8441 - loss: 0.112017\n",
      "Epoch 98/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 23ms/step - accuracy: 0.8488 - loss: 0.10882\n",
      "Epoch 94/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 12ms/step - accuracy: 0.8265 - loss: 0.1208\n",
      "\u001b[1m 2766/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 14ms/step - accuracy: 0.8332 - loss: 0.1176Epoch 26/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 17ms/step - accuracy: 0.8378 - loss: 0.11531\n",
      "\u001b[1m 4840/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.1176Epoch 69/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 12ms/step - accuracy: 0.8279 - loss: 0.1207\n",
      "Epoch 26/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 13ms/step - accuracy: 0.8339 - loss: 0.1167\n",
      "Epoch 46/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 23ms/step - accuracy: 0.8491 - loss: 0.10881\n",
      "Epoch 95/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 14ms/step - accuracy: 0.8360 - loss: 0.1157\n",
      "\u001b[1m6430/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.8425 - loss: 0.1124Epoch 45/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8381 - loss: 0.1151\n",
      "Epoch 44/50\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 22ms/step - accuracy: 0.8442 - loss: 0.111024\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.8331 - loss: 0.1177\n",
      "Epoch 42/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 12ms/step - accuracy: 0.8322 - loss: 0.1180\n",
      "Epoch 45/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 18ms/step - accuracy: 0.8425 - loss: 0.11236\n",
      "\u001b[1m25726/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - accuracy: 0.8223 - loss: 0.1225Epoch 65/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 16ms/step - accuracy: 0.8425 - loss: 0.11235\n",
      "\u001b[1m4207/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 15ms/step - accuracy: 0.8405 - loss: 0.1138Epoch 73/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 22ms/step - accuracy: 0.8491 - loss: 0.10846\n",
      "Epoch 100/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 18ms/step - accuracy: 0.8417 - loss: 0.11366\n",
      "\u001b[1m 5083/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 11ms/step - accuracy: 0.8255 - loss: 0.1209Epoch 64/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 18ms/step - accuracy: 0.8441 - loss: 0.111364\n",
      "Epoch 69/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.8447 - loss: 0.111617\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step accuracy: 0.8388 - loss: 0.11: 0.1151\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 18ms/step - accuracy: 0.8446 - loss: 0.11151\n",
      "Epoch 66/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 22ms/step - accuracy: 0.8459 - loss: 0.110716\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/steps/step - accuracy: 0.8340 - loss: 0.1118\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 18ms/step - accuracy: 0.8428 - loss: 0.11295\n",
      "Epoch 65/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 18ms/step - accuracy: 0.8445 - loss: 0.1115\n",
      "Epoch 70/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 16ms/step - accuracy: 0.8433 - loss: 0.11190\n",
      "\u001b[1m 203/7353\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 16ms/step - accuracy: 0.8425 - loss: 0.1137Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 12ms/step - accuracy: 0.8366 - loss: 0.1152\n",
      "Epoch 47/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 22ms/step - accuracy: 0.8502 - loss: 0.107506\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 22ms/step - accuracy: 0.8443 - loss: 0.111011\n",
      "Epoch 100/100\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/steptep - accuracy: 0.8375 - loss: 0.1111276\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 15ms/step - accuracy: 0.8375 - loss: 0.11555\n",
      "Epoch 71/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 11ms/step - accuracy: 0.8271 - loss: 0.1206\n",
      "Epoch 27/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 13ms/step - accuracy: 0.8330 - loss: 0.1178\n",
      "Epoch 43/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8340 - loss: 0.1173\n",
      "Epoch 43/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 12ms/step - accuracy: 0.8322 - loss: 0.1180\n",
      "Epoch 46/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.1157\n",
      "Epoch 48/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 21ms/step - accuracy: 0.8484 - loss: 0.108916\n",
      "\u001b[1m23227/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 12ms/step - accuracy: 0.8207 - loss: 0.1235Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.1173\n",
      "Epoch 44/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 12ms/step - accuracy: 0.8327 - loss: 0.1178\n",
      "Epoch 47/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 15ms/step - accuracy: 0.8427 - loss: 0.1123\n",
      "Epoch 76/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 15ms/step - accuracy: 0.8380 - loss: 0.11482\n",
      "\u001b[1m28450/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8209 - loss: 0.1235Epoch 73/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8342 - loss: 0.1171\n",
      "Epoch 44/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 16ms/step - accuracy: 0.8445 - loss: 0.11155\n",
      "Epoch 68/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 16ms/step - accuracy: 0.8454 - loss: 0.11065\n",
      "Epoch 72/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 12ms/step - accuracy: 0.8209 - loss: 0.1234\n",
      "Epoch 26/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 16ms/step - accuracy: 0.8449 - loss: 0.11122\n",
      "\u001b[1m 9537/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 11ms/step - accuracy: 0.8327 - loss: 0.1177Epoch 69/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 16ms/step - accuracy: 0.8444 - loss: 0.11135\n",
      "\u001b[1m 8141/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 13ms/step - accuracy: 0.8393 - loss: 0.1140Epoch 73/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 12ms/step - accuracy: 0.8345 - loss: 0.1169\n",
      "Epoch 45/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 16ms/step - accuracy: 0.8419 - loss: 0.11324\n",
      "Epoch 68/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 11ms/step - accuracy: 0.8328 - loss: 0.1177\n",
      "Epoch 48/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 21ms/step - accuracy: 0.8490 - loss: 0.108722\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step/step - accuracy: 0.8445 - loss: 0.1115\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.1202\n",
      "\u001b[1m 1575/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 13ms/step - accuracy: 0.8326 - loss: 0.1180Epoch 28/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 11ms/step - accuracy: 0.8364 - loss: 0.1161\n",
      "Epoch 48/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8349 - loss: 0.1170\n",
      "Epoch 45/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.1177\n",
      "Epoch 50/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 14ms/step - accuracy: 0.8375 - loss: 0.11549\n",
      "Epoch 75/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 12ms/step - accuracy: 0.8368 - loss: 0.1157\n",
      "Epoch 48/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 15ms/step - accuracy: 0.8443 - loss: 0.11136\n",
      "Epoch 79/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.1175\n",
      "Epoch 49/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 14ms/step - accuracy: 0.8394 - loss: 0.11435\n",
      "Epoch 76/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 15ms/step - accuracy: 0.8440 - loss: 0.11188\n",
      "\u001b[1m4233/7353\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - accuracy: 0.8447 - loss: 0.1112Epoch 71/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.1171\n",
      "Epoch 46/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 10ms/step - accuracy: 0.8241 - loss: 0.1224\n",
      "Epoch 29/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.8368 - loss: 0.1159\n",
      "Epoch 49/50\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 11ms/step - accuracy: 0.8209 - loss: 0.1240\n",
      "\u001b[1m 9506/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 11ms/step - accuracy: 0.8382 - loss: 0.1143Epoch 27/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 12ms/step - accuracy: 0.8242 - loss: 0.1223\n",
      "Epoch 26/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.1178\n",
      "Epoch 51/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.1163\n",
      "Epoch 46/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 16ms/step - accuracy: 0.8427 - loss: 0.11265\n",
      "\u001b[1m13724/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8409 - loss: 0.1136Epoch 70/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 10ms/step - accuracy: 0.8283 - loss: 0.1197\n",
      "Epoch 29/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 15ms/step - accuracy: 0.8445 - loss: 0.11125\n",
      "Epoch 75/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 15ms/step - accuracy: 0.8426 - loss: 0.11316\n",
      "\u001b[1m 5546/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 12ms/step - accuracy: 0.8365 - loss: 0.1161Epoch 71/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.8366 - loss: 0.1157\n",
      "Epoch 50/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.1163\n",
      "Epoch 47/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 15ms/step - accuracy: 0.8437 - loss: 0.11182\n",
      "Epoch 81/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 15ms/step - accuracy: 0.8454 - loss: 0.11126\n",
      "Epoch 76/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 12ms/step - accuracy: 0.8323 - loss: 0.1179\n",
      "Epoch 52/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 14ms/step - accuracy: 0.8395 - loss: 0.11439\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.1164\n",
      "\u001b[1m3372/7353\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 16ms/step - accuracy: 0.8453 - loss: 0.1109Epoch 47/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 11ms/step - accuracy: 0.8369 - loss: 0.1154\n",
      "\u001b[1m12611/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.1144Epoch 52/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/stepstep - accuracy: 0.8407 - loss: 0.114\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 12ms/step - accuracy: 0.8323 - loss: 0.1175\n",
      "Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 12ms/step - accuracy: 0.8363 - loss: 0.1164\n",
      "\u001b[1m 8991/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 9ms/step - accuracy: 0.8252 - loss: 0.1215Epoch 48/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 11ms/step - accuracy: 0.8236 - loss: 0.1230\n",
      "\u001b[1m11606/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.1162Epoch 27/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.1149\n",
      "Epoch 53/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 15ms/step - accuracy: 0.8446 - loss: 0.1114\n",
      "Epoch 83/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 12ms/step - accuracy: 0.8341 - loss: 0.1171\n",
      "\u001b[1m 4966/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 12ms/step - accuracy: 0.8373 - loss: 0.1154Epoch 48/50\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 14ms/step - accuracy: 0.8394 - loss: 0.11426\n",
      "Epoch 80/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 15ms/step - accuracy: 0.8432 - loss: 0.11266\n",
      "Epoch 73/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 15ms/step - accuracy: 0.8457 - loss: 0.11115\n",
      "Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11ms/step - accuracy: 0.8355 - loss: 0.1162\n",
      "\u001b[1m 1948/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 12ms/step - accuracy: 0.8366 - loss: 0.1157Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12ms/step - accuracy: 0.8404 - loss: 0.1141\n",
      "Epoch 50/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 0.1147\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 15ms/step - accuracy: 0.8418 - loss: 0.11343\n",
      "Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11ms/step - accuracy: 0.8368 - loss: 0.1153\n",
      "Epoch 54/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 15ms/step - accuracy: 0.8461 - loss: 0.1102\n",
      "Epoch 79/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 9ms/step - accuracy: 0.8250 - loss: 0.1218\n",
      "\u001b[1m 499/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 15ms/step - accuracy: 0.8502 - loss: 0.1089Epoch 31/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.1163\n",
      "Epoch 49/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.1164\n",
      "Epoch 49/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.8363 - loss: 0.1160\n",
      "Epoch 54/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.1143\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 14ms/step - accuracy: 0.8401 - loss: 0.11418\n",
      "Epoch 82/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/stepstep - accuracy: 0.8388 - loss: 0.116\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 15ms/step - accuracy: 0.8446 - loss: 0.1112\n",
      "Epoch 85/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 14ms/step - accuracy: 0.8445 - loss: 0.11114\n",
      "\u001b[1m4568/7353\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.8462 - loss: 0.1104Epoch 86/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.1199\n",
      "Epoch 31/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.1168\n",
      "Epoch 55/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 11ms/step - accuracy: 0.8353 - loss: 0.1168\n",
      "\u001b[1m 587/7353\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 14ms/step - accuracy: 0.8410 - loss: 0.1121Epoch 50/50\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11ms/step - accuracy: 0.8365 - loss: 0.1157\n",
      "Epoch 50/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 11ms/step - accuracy: 0.8374 - loss: 0.1154\n",
      "Epoch 55/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 13ms/step - accuracy: 0.8448 - loss: 0.110891\n",
      "Epoch 81/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.110514\n",
      "Epoch 77/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 13ms/step - accuracy: 0.8451 - loss: 0.11194\n",
      "Epoch 76/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 11ms/step - accuracy: 0.8375 - loss: 0.1152\n",
      "\u001b[1m20957/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 10ms/step - accuracy: 0.8251 - loss: 0.1220Epoch 56/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.1193\n",
      "Epoch 32/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 9ms/step - accuracy: 0.8218 - loss: 0.1229\n",
      "\u001b[1m 8463/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 9ms/step - accuracy: 0.8238 - loss: 0.1221Epoch 30/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 14ms/step - accuracy: 0.8450 - loss: 0.111159\n",
      "Epoch 88/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10ms/step - accuracy: 0.8362 - loss: 0.1163\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/steptep - accuracy: 0.8242 - loss: 0.1240\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13ms/step - accuracy: 0.8413 - loss: 0.11367\n",
      "\u001b[1m 2154/29412\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 10ms/step - accuracy: 0.8274 - loss: 0.1204Epoch 85/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 13ms/step - accuracy: 0.8460 - loss: 0.110606\n",
      "\u001b[1m 8216/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 10ms/step - accuracy: 0.8360 - loss: 0.1161Epoch 79/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.110546\n",
      "Epoch 83/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 13ms/step - accuracy: 0.8438 - loss: 0.112317\n",
      "Epoch 78/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 10ms/step - accuracy: 0.8251 - loss: 0.1220\n",
      "Epoch 29/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 11ms/step - accuracy: 0.8326 - loss: 0.1175\n",
      "\u001b[1m18952/29412\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 9ms/step - accuracy: 0.8294 - loss: 0.1195Epoch 57/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13ms/step - accuracy: 0.8458 - loss: 0.11066\n",
      "Epoch 84/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 9ms/step - accuracy: 0.8249 - loss: 0.1218\n",
      "Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 14ms/step - accuracy: 0.8449 - loss: 0.11105\n",
      "Epoch 90/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8469 - loss: 0.110135\n",
      "Epoch 81/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 13ms/step - accuracy: 0.8414 - loss: 0.113645\n",
      "Epoch 87/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 10ms/step - accuracy: 0.8382 - loss: 0.1143\n",
      "Epoch 58/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.1170\n",
      "\u001b[1m26063/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m30s\u001b[0m 9ms/step - accuracy: 0.8228 - loss: 0.1225Epoch 56/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8442 - loss: 0.11225\n",
      "Epoch 80/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 9ms/step - accuracy: 0.8297 - loss: 0.1200\n",
      "Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8476 - loss: 0.109915\n",
      "Epoch 86/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10ms/step - accuracy: 0.8396 - loss: 0.1139\n",
      "\u001b[1m12765/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 9ms/step - accuracy: 0.8291 - loss: 0.1197Epoch 59/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 10ms/step - accuracy: 0.8353 - loss: 0.1167\n",
      "Epoch 57/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 13ms/step - accuracy: 0.8465 - loss: 0.110215\n",
      "\u001b[1m3088/7353\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 13ms/step - accuracy: 0.8471 - loss: 0.1097Epoch 83/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.11041\n",
      "Epoch 92/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 13ms/step - accuracy: 0.8417 - loss: 0.113415\n",
      "Epoch 89/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8443 - loss: 0.111815\n",
      "\u001b[1m 3884/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 10ms/step - accuracy: 0.8370 - loss: 0.1162Epoch 82/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.8356 - loss: 0.1166\n",
      "Epoch 58/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 9ms/step - accuracy: 0.8204 - loss: 0.1237\n",
      "\u001b[1m1767/7353\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 13ms/step - accuracy: 0.8456 - loss: 0.1124Epoch 32/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8473 - loss: 0.109701\n",
      "Epoch 88/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 12ms/step - accuracy: 0.8466 - loss: 0.110194\n",
      "Epoch 85/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 13ms/step - accuracy: 0.8463 - loss: 0.110316\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.8363 - loss: 0.1161\n",
      "\u001b[1m 8232/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.1190Epoch 55/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 14ms/step - accuracy: 0.8402 - loss: 0.11436\n",
      "Epoch 91/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step - accuracy: 0.8448 - loss: 0.112313\n",
      "Epoch 84/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 9ms/step - accuracy: 0.8266 - loss: 0.1213\n",
      "Epoch 31/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.1201\n",
      "Epoch 34/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8468 - loss: 0.110206\n",
      "Epoch 90/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 10ms/step - accuracy: 0.8373 - loss: 0.1156\n",
      "Epoch 56/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 14ms/step - accuracy: 0.8412 - loss: 0.11376\n",
      "Epoch 92/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step - accuracy: 0.8478 - loss: 0.109766\n",
      "Epoch 87/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 9ms/step - accuracy: 0.8260 - loss: 0.1217\n",
      "Epoch 35/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.8341 - loss: 0.1167\n",
      "Epoch 61/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8449 - loss: 0.111115\n",
      "\u001b[1m13736/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8382 - loss: 0.1151Epoch 96/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 12ms/step - accuracy: 0.8445 - loss: 0.111705\n",
      "Epoch 86/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 9ms/step - accuracy: 0.8298 - loss: 0.1191\n",
      "Epoch 35/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8382 - loss: 0.1151\n",
      "Epoch 61/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.8342 - loss: 0.1165\n",
      "Epoch 62/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8472 - loss: 0.10992\n",
      "Epoch 89/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.8374 - loss: 0.1155\n",
      "Epoch 62/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 14ms/step - accuracy: 0.8415 - loss: 0.11355\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.8394 - loss: 0.1139\n",
      "Epoch 63/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step - accuracy: 0.8479 - loss: 0.109796\n",
      "Epoch 92/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 10ms/step - accuracy: 0.8351 - loss: 0.1162\n",
      "Epoch 61/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8453 - loss: 0.11131\n",
      "Epoch 88/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8464 - loss: 0.110316\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 10ms/step - accuracy: 0.8374 - loss: 0.1157\n",
      "Epoch 58/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.8378 - loss: 0.1152\n",
      "Epoch 63/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.8402 - loss: 0.1132\n",
      "Epoch 64/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 10ms/step - accuracy: 0.8358 - loss: 0.1162\n",
      "\u001b[1m 5550/29412\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 9ms/step - accuracy: 0.8306 - loss: 0.1183Epoch 62/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step - accuracy: 0.8477 - loss: 0.109616\n",
      "\u001b[1m 2351/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 10ms/step - accuracy: 0.8412 - loss: 0.1140Epoch 91/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 9ms/step - accuracy: 0.8216 - loss: 0.1235\n",
      "Epoch 34/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 9ms/step - accuracy: 0.8299 - loss: 0.1195\n",
      "Epoch 36/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 13ms/step - accuracy: 0.8487 - loss: 0.109324\n",
      "\u001b[1m 9743/29412\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 9ms/step - accuracy: 0.8301 - loss: 0.1185Epoch 94/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 13ms/step - accuracy: 0.8409 - loss: 0.113615\n",
      "Epoch 96/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 9ms/step - accuracy: 0.8269 - loss: 0.1212\n",
      "Epoch 33/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step - accuracy: 0.8465 - loss: 0.110982\n",
      "Epoch 90/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.110215\n",
      "Epoch 100/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 10ms/step - accuracy: 0.8395 - loss: 0.1142\n",
      "\u001b[1m19026/29412\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 9ms/step - accuracy: 0.8219 - loss: 0.1232Epoch 64/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8486 - loss: 0.109414\n",
      "Epoch 93/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 9ms/step - accuracy: 0.8245 - loss: 0.1221\n",
      "Epoch 37/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 9ms/step - accuracy: 0.8299 - loss: 0.1188\n",
      "Epoch 37/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8473 - loss: 0.109614\n",
      "Epoch 96/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8453 - loss: 0.111214\n",
      "Epoch 92/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 13ms/step - accuracy: 0.8415 - loss: 0.113304\n",
      "Epoch 98/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8484 - loss: 0.10921\n",
      "Epoch 95/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 12ms/step - accuracy: 0.8487 - loss: 0.109334\n",
      "\u001b[1m 6873/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.1168Epoch 98/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 12ms/step - accuracy: 0.8466 - loss: 0.110914\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - accuracy: 0.8378 - loss: 0.1155\n",
      "Epoch 61/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 10ms/step - accuracy: 0.8355 - loss: 0.1164\n",
      "\u001b[1m14981/29412\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 9ms/step - accuracy: 0.8331 - loss: 0.1181Epoch 65/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 13ms/step - accuracy: 0.8414 - loss: 0.113445\n",
      "Epoch 100/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - accuracy: 0.8386 - loss: 0.1150\n",
      "Epoch 62/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 10ms/step - accuracy: 0.8365 - loss: 0.1156\n",
      "Epoch 66/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 12ms/step - accuracy: 0.8472 - loss: 0.11001\n",
      "Epoch 100/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 9ms/step - accuracy: 0.8276 - loss: 0.1209\n",
      "Epoch 35/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 12ms/step - accuracy: 0.8462 - loss: 0.110954\n",
      "Epoch 96/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 9ms/step - accuracy: 0.8407 - loss: 0.1131\n",
      "\u001b[1m17825/29412\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.1213Epoch 68/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - accuracy: 0.8384 - loss: 0.1150\n",
      "Epoch 67/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 10ms/step - accuracy: 0.8338 - loss: 0.1166\n",
      "\u001b[1m 6863/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.1151Epoch 67/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 12ms/step - accuracy: 0.8488 - loss: 0.109214\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 9ms/step - accuracy: 0.8403 - loss: 0.1131\n",
      "\u001b[1m5964/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.8453 - loss: 0.1114Epoch 69/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.8401 - loss: 0.1143\n",
      "Epoch 68/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.8354 - loss: 0.1159\n",
      "\u001b[1m7071/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8453 - loss: 0.1114Epoch 68/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 11ms/step - accuracy: 0.8453 - loss: 0.11142\n",
      "Epoch 98/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 8ms/step - accuracy: 0.8214 - loss: 0.1234\n",
      "\u001b[1m22933/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.8282 - loss: 0.1206Epoch 37/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 8ms/step - accuracy: 0.8311 - loss: 0.1189\n",
      "\u001b[1m 3852/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 9ms/step - accuracy: 0.8391 - loss: 0.1142Epoch 39/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 11ms/step - accuracy: 0.8482 - loss: 0.10935\n",
      "Epoch 100/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.1156\n",
      "Epoch 64/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 11ms/step - accuracy: 0.8467 - loss: 0.11070\n",
      "Epoch 100/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.1211\n",
      "Epoch 40/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 8ms/step - accuracy: 0.8311 - loss: 0.1182\n",
      "Epoch 40/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8398 - loss: 0.1143\n",
      "Epoch 65/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 9ms/step - accuracy: 0.8378 - loss: 0.1154\n",
      "\u001b[1m 3220/29412\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 8ms/step - accuracy: 0.8282 - loss: 0.1205Epoch 69/100\n",
      "\u001b[1m7353/7353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 10ms/step - accuracy: 0.8454 - loss: 0.11145\n",
      "\u001b[1m1839/1839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/stepstep - accuracy: 0.8356 - loss: 0.11\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 9ms/step - accuracy: 0.8408 - loss: 0.1130\n",
      "Epoch 72/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.1140\n",
      "Epoch 71/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 0.1162\n",
      "\u001b[1m 8588/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.1149Epoch 71/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 8ms/step - accuracy: 0.8257 - loss: 0.1214\n",
      "Epoch 41/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 8ms/step - accuracy: 0.8303 - loss: 0.1189\n",
      "Epoch 41/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9ms/step - accuracy: 0.8412 - loss: 0.1133\n",
      "Epoch 73/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8349 - loss: 0.1165\n",
      "Epoch 72/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7ms/step - accuracy: 0.8284 - loss: 0.1206\n",
      "Epoch 38/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 8ms/step - accuracy: 0.8385 - loss: 0.1151\n",
      "Epoch 68/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - accuracy: 0.8387 - loss: 0.1149\n",
      "\u001b[1m 6604/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 9ms/step - accuracy: 0.8346 - loss: 0.1164Epoch 69/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 8ms/step - accuracy: 0.8329 - loss: 0.1180\n",
      "Epoch 42/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9ms/step - accuracy: 0.8378 - loss: 0.1154\n",
      "Epoch 73/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.1199\n",
      "Epoch 39/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.1136\n",
      "Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8349 - loss: 0.1164\n",
      "\u001b[1m13931/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8410 - loss: 0.1130Epoch 74/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9ms/step - accuracy: 0.8381 - loss: 0.1148\n",
      "Epoch 74/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 7ms/step - accuracy: 0.8213 - loss: 0.1238\n",
      "Epoch 41/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8409 - loss: 0.1137\n",
      "Epoch 75/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8361 - loss: 0.1156\n",
      "Epoch 75/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 9ms/step - accuracy: 0.8420 - loss: 0.1126\n",
      "\u001b[1m 7506/29412\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 8ms/step - accuracy: 0.8242 - loss: 0.1222Epoch 76/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.1146\n",
      "Epoch 71/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8322 - loss: 0.1182\n",
      "Epoch 43/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.1145\n",
      "Epoch 72/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 8ms/step - accuracy: 0.8245 - loss: 0.1220\n",
      "Epoch 44/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 0.1182\n",
      "\u001b[1m 6238/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 9ms/step - accuracy: 0.8426 - loss: 0.1127Epoch 44/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.1152\n",
      "Epoch 77/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8406 - loss: 0.1134\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8359 - loss: 0.1160\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8425 - loss: 0.1123\n",
      "Epoch 79/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8264 - loss: 0.1211\n",
      "Epoch 45/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 8ms/step - accuracy: 0.8306 - loss: 0.1194\n",
      "Epoch 42/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.1182\n",
      "Epoch 45/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8403 - loss: 0.1135\n",
      "Epoch 79/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8370 - loss: 0.1152\n",
      "Epoch 79/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8425 - loss: 0.1123\n",
      "Epoch 80/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.1145\n",
      "Epoch 75/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 7ms/step - accuracy: 0.8186 - loss: 0.1247\n",
      "\u001b[1m22421/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m53s\u001b[0m 8ms/step - accuracy: 0.8335 - loss: 0.1178Epoch 44/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 8ms/step - accuracy: 0.8297 - loss: 0.1198\n",
      "Epoch 43/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 8ms/step - accuracy: 0.8335 - loss: 0.1179\n",
      "Epoch 46/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8383 - loss: 0.1150\n",
      "Epoch 80/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.1214\n",
      "Epoch 47/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.1148\n",
      "Epoch 81/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 8ms/step - accuracy: 0.8319 - loss: 0.1182\n",
      "Epoch 47/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8416 - loss: 0.1134\n",
      "Epoch 82/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 7ms/step - accuracy: 0.8223 - loss: 0.1233\n",
      "Epoch 45/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8428 - loss: 0.1122\n",
      "Epoch 83/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8341 - loss: 0.1163\n",
      "\u001b[1m  586/29412\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 7ms/step - accuracy: 0.8265 - loss: 0.1212Epoch 82/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.1134\n",
      "Epoch 78/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8406 - loss: 0.1141\n",
      "\u001b[1m11783/29412\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 8ms/step - accuracy: 0.8325 - loss: 0.1183Epoch 79/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8283 - loss: 0.1202\n",
      "Epoch 48/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 7ms/step - accuracy: 0.8217 - loss: 0.1241\n",
      "Epoch 46/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 8ms/step - accuracy: 0.8329 - loss: 0.1176\n",
      "Epoch 48/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.1153\n",
      "Epoch 84/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.1122\n",
      "Epoch 86/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 9ms/step - accuracy: 0.8412 - loss: 0.1133\n",
      "Epoch 85/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.1141\n",
      "Epoch 81/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 9ms/step - accuracy: 0.8361 - loss: 0.1156\n",
      "\u001b[1m27418/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.1212Epoch 85/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 8ms/step - accuracy: 0.8304 - loss: 0.1194\n",
      "Epoch 46/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.1149\n",
      "Epoch 85/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8413 - loss: 0.1137\n",
      "Epoch 82/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.1129\n",
      "Epoch 86/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.1177\n",
      "Epoch 49/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 9ms/step - accuracy: 0.8367 - loss: 0.1152\n",
      "Epoch 86/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7ms/step - accuracy: 0.8298 - loss: 0.1197\n",
      "\u001b[1m 9816/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8423 - loss: 0.1130Epoch 47/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8424 - loss: 0.1126\n",
      "Epoch 89/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 8ms/step - accuracy: 0.8332 - loss: 0.1178\n",
      "Epoch 50/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 9ms/step - accuracy: 0.8396 - loss: 0.1143\n",
      "Epoch 87/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.1132\n",
      "Epoch 84/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.1131\n",
      "Epoch 85/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 9ms/step - accuracy: 0.8381 - loss: 0.1148\n",
      "Epoch 88/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8424 - loss: 0.1132\n",
      "Epoch 89/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.1173\n",
      "Epoch 51/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8360 - loss: 0.1158\n",
      "Epoch 89/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 7ms/step - accuracy: 0.8307 - loss: 0.1196\n",
      "Epoch 48/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.1205\n",
      "Epoch 52/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 7ms/step - accuracy: 0.8196 - loss: 0.1248\n",
      "Epoch 50/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.1117\n",
      "Epoch 92/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 8ms/step - accuracy: 0.8421 - loss: 0.1133\n",
      "Epoch 87/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8429 - loss: 0.1130\n",
      "\u001b[1m 2638/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 8ms/step - accuracy: 0.8490 - loss: 0.1097Epoch 88/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8389 - loss: 0.1146\n",
      "Epoch 91/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.1126\n",
      "Epoch 92/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 7ms/step - accuracy: 0.8200 - loss: 0.1245\n",
      "\u001b[1m 4735/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 8ms/step - accuracy: 0.8431 - loss: 0.1126Epoch 51/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 7ms/step - accuracy: 0.8283 - loss: 0.1201\n",
      "Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8382 - loss: 0.1142\n",
      "Epoch 92/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8365 - loss: 0.1152\n",
      "Epoch 93/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.1119\n",
      "Epoch 95/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.1135\n",
      "Epoch 90/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.1189\n",
      "Epoch 51/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 8ms/step - accuracy: 0.8329 - loss: 0.1177\n",
      "Epoch 54/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8410 - loss: 0.1135\n",
      "Epoch 91/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 8ms/step - accuracy: 0.8351 - loss: 0.1169\n",
      "Epoch 54/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8405 - loss: 0.1139\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.1132\n",
      "Epoch 95/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9ms/step - accuracy: 0.8367 - loss: 0.1152\n",
      "Epoch 95/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9ms/step - accuracy: 0.8411 - loss: 0.1135\n",
      "Epoch 96/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9ms/step - accuracy: 0.8366 - loss: 0.1151\n",
      "\u001b[1m 1995/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 9ms/step - accuracy: 0.8409 - loss: 0.1137Epoch 96/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7ms/step - accuracy: 0.8314 - loss: 0.1187\n",
      "\u001b[1m27284/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.1169Epoch 52/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.1170\n",
      "\u001b[1m28398/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 0.1169Epoch 55/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.1114\n",
      "Epoch 98/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 0.1169\n",
      "Epoch 55/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8421 - loss: 0.1132\n",
      "Epoch 93/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8431 - loss: 0.1127\n",
      "Epoch 94/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.1128\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8405 - loss: 0.1138\n",
      "Epoch 97/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 7ms/step - accuracy: 0.8307 - loss: 0.1191\n",
      "Epoch 53/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.1148\n",
      "Epoch 98/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.1129\n",
      "\u001b[1m14247/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8401 - loss: 0.1143Epoch 99/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - accuracy: 0.8401 - loss: 0.1143\n",
      "Epoch 98/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 7ms/step - accuracy: 0.8270 - loss: 0.1207\n",
      "Epoch 57/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8371 - loss: 0.1149\n",
      "Epoch 99/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8457 - loss: 0.1107\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8415 - loss: 0.112\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8421 - loss: 0.1127\n",
      "Epoch 96/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.1128\n",
      "Epoch 97/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.1243\n",
      "Epoch 56/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 7ms/step - accuracy: 0.8285 - loss: 0.1203\n",
      "Epoch 58/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 9ms/step - accuracy: 0.8437 - loss: 0.1121\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8ms/step - accuracy: 0.8396 - loss: 0.1142\n",
      "Epoch 100/100\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8352 - loss: 0.112\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 8ms/step - accuracy: 0.8337 - loss: 0.1170\n",
      "Epoch 58/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8413 - loss: 0.1138\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8317 - loss: 0.116\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 7ms/step - accuracy: 0.8211 - loss: 0.1235\n",
      "Epoch 57/100\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 8ms/step - accuracy: 0.8434 - loss: 0.1125\n",
      "Epoch 99/100\n",
      "\u001b[1m29412/29412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 0.1196\n",
      "Epoch 59/100\n",
      "\u001b[1m 6429/29412\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 7ms/step - accuracy: 0.8206 - loss: 0.1240"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape=(34, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))  # Regression output\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create Keras classifier\n",
    "model = KerasClassifier(model=create_rnn_model)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'epochs': [25, 50, 75, 100],\n",
    "    'batch_size': [16, 32, 64, 128]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs = -1)\n",
    "grid_result = grid_search.fit(X_train_rnn, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6756576f-5470-4bb4-a9a1-1775d4e91aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.812770 using {'epochs': 25, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4737cad2-493a-449e-be8a-d1abcd163ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 15:40:36.720378: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720390: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720377: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720385: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720383: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720378: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720375: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720373: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720389: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720371: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720375: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720386: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720384: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720371: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720386: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720373: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720392: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720398: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720390: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720428: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720518: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720516: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720534: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720536: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720535: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720537: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720543: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720544: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720546: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720542: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720543: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720539: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720548: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720544: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720590: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.720599: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.721626: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.722580: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722628: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722665: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722654: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722682: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722680: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722683: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722695: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722700: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722706: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722713: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722744: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722747: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722747: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722748: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722750: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722760: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722765: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722765: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722773: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722777: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722783: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722824: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722942: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722957: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722978: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722983: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.722995: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723003: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723004: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723010: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723028: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723029: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723029: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723039: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723041: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723044: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723048: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723049: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723050: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723051: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723053: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723053: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723055: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723055: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723058: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723056: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723060: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723084: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.723588: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 15:40:36.724698: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726544: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726546: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726548: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726552: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726553: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726555: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726557: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726559: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726561: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726564: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726566: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726567: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726568: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726567: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726569: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726570: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726571: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726573: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726575: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726576: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726576: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726577: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726579: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726582: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726958: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726958: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726959: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726956: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726964: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726971: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726973: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726979: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726979: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726982: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726983: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726982: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726982: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726983: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726984: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726986: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726986: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726991: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726992: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.726996: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.727007: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.729521: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 15:40:36.737849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737847: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737886: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737916: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.737938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738410: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.738456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.741599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 15:40:36.756660: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756660: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756672: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756661: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756661: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756690: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756693: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756753: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.756857: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757258: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757247: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757271: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757297: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757297: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757319: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757326: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.757888: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.760413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 15:40:36.761964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761965: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761967: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761971: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761986: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.761991: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762007: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762006: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762008: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762014: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762026: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762537: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762544: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762559: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762565: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762564: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762573: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762589: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762599: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762607: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762611: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762625: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.762637: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.763542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.765698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 15:40:36.775666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775670: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775671: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775671: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775670: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775674: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775692: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775692: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775693: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.775718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776300: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776311: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776328: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776330: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776401: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.776472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.778372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:36.780018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 15:40:39.749528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.749974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.750720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:39.756216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 15:40:48.921912: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:48.934512: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 15:40:49.188228: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.191388: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.191470: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.198105: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 15:40:49.271902: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 15:40:49.280233: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.281231: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.281915: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.283719: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.284374: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.286054: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.286162: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.289324: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.290856: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.291051: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.292478: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.293931: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.294408: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.310314: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.310815: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.311338: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.312824: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.315287: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.316100: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.317672: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.319783: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.320012: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.321701: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.324674: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.324706: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.330762: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 15:40:49.332155: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 15:40:49.334290: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.334642: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.336124: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.336842: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.336859: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.336879: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.337571: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.337682: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.337744: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.337991: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338133: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338152: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338341: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338382: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338404: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 15:40:49.338442: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 11ms/step - accuracy: 0.6026 - loss: 0.2621\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.6010 - loss: 0.3436\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.7079 - loss: 0.1910\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 15ms/step - accuracy: 0.7434 - loss: 0.1778\n",
      "\u001b[1m 8926/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 25ms/step - accuracy: 0.7367 - loss: 0.1809Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 15ms/step - accuracy: 0.7465 - loss: 0.1741\n",
      "\u001b[1m 9786/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 22ms/step - accuracy: 0.6735 - loss: 0.2132Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.7380 - loss: 0.1823\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 15ms/step - accuracy: 0.6252 - loss: 0.2644\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 15ms/step - accuracy: 0.7479 - loss: 0.1726\n",
      "\u001b[1m13713/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.7520 - loss: 0.1724Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 16ms/step - accuracy: 0.6028 - loss: 0.2681\n",
      "\u001b[1m  721/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 0.1375Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 16ms/step - accuracy: 0.7446 - loss: 0.1839\n",
      "\u001b[1m10345/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 22ms/step - accuracy: 0.6758 - loss: 0.2117Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 16ms/step - accuracy: 0.5985 - loss: 0.2614\n",
      "\u001b[1m14094/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7530 - loss: 0.1716Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 16ms/step - accuracy: 0.7633 - loss: 0.1626\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 16ms/step - accuracy: 0.6578 - loss: 0.2349\n",
      "\u001b[1m 3161/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 11ms/step - accuracy: 0.6604 - loss: 0.2243Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 16ms/step - accuracy: 0.7416 - loss: 0.2003\n",
      "\u001b[1m10568/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 23ms/step - accuracy: 0.7393 - loss: 0.1859Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 16ms/step - accuracy: 0.7522 - loss: 0.1710\n",
      "\u001b[1m 1563/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 14ms/step - accuracy: 0.8015 - loss: 0.1367Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 16ms/step - accuracy: 0.7307 - loss: 0.2267\n",
      "\u001b[1m 1623/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.8013 - loss: 0.1378Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 16ms/step - accuracy: 0.7546 - loss: 0.1705\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 17ms/step - accuracy: 0.6406 - loss: 0.2354\n",
      "\u001b[1m10237/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 25ms/step - accuracy: 0.7510 - loss: 0.1739Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.7585 - loss: 0.1654\n",
      "\u001b[1m 1730/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 13ms/step - accuracy: 0.8069 - loss: 0.1339Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 18ms/step - accuracy: 0.6543 - loss: 0.2178\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 18ms/step - accuracy: 0.7648 - loss: 0.1607\n",
      "\u001b[1m 1837/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 14ms/step - accuracy: 0.8072 - loss: 0.1330Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 18ms/step - accuracy: 0.7580 - loss: 0.1659\n",
      "\u001b[1m12448/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m48s\u001b[0m 22ms/step - accuracy: 0.7200 - loss: 0.2075Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 20ms/step - accuracy: 0.6507 - loss: 0.2995\n",
      "\u001b[1m 2517/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 15ms/step - accuracy: 0.8100 - loss: 0.1322Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 20ms/step - accuracy: 0.7190 - loss: 0.1884\n",
      "\u001b[1m 5194/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 13ms/step - accuracy: 0.7644 - loss: 0.1627Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 10ms/step - accuracy: 0.6584 - loss: 0.2249\n",
      "\u001b[1m 6372/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 14ms/step - accuracy: 0.8034 - loss: 0.1365Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 21ms/step - accuracy: 0.7058 - loss: 0.2055\n",
      "\u001b[1m 4538/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 15ms/step - accuracy: 0.8075 - loss: 0.1330Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.6603 - loss: 0.2139\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.6872 - loss: 0.2256\n",
      "\u001b[1m14071/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7507 - loss: 0.1771Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 22ms/step - accuracy: 0.6908 - loss: 0.2029\n",
      "\u001b[1m 3551/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 16ms/step - accuracy: 0.6617 - loss: 0.2239Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 22ms/step - accuracy: 0.7289 - loss: 0.1997\n",
      "\u001b[1m10781/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - accuracy: 0.6596 - loss: 0.2245Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 22ms/step - accuracy: 0.7453 - loss: 0.1739\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 22ms/step - accuracy: 0.7457 - loss: 0.1735\n",
      "\u001b[1m  622/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 19ms/step - accuracy: 0.7668 - loss: 0.1618Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.7523 - loss: 0.1759\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 22ms/step - accuracy: 0.7513 - loss: 0.1704\n",
      "\u001b[1m14041/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.7594 - loss: 0.1646Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 22ms/step - accuracy: 0.7457 - loss: 0.1768\n",
      "\u001b[1m 7348/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 13ms/step - accuracy: 0.7653 - loss: 0.1622Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 22ms/step - accuracy: 0.7548 - loss: 0.1738\n",
      "\u001b[1m13437/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - accuracy: 0.7605 - loss: 0.1671Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 23ms/step - accuracy: 0.7580 - loss: 0.1688\n",
      "\u001b[1m13488/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - accuracy: 0.7606 - loss: 0.1670Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 23ms/step - accuracy: 0.7566 - loss: 0.1782\n",
      "\u001b[1m 1124/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:26\u001b[0m 20ms/step - accuracy: 0.7661 - loss: 0.1625Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 23ms/step - accuracy: 0.7550 - loss: 0.1729\n",
      "\u001b[1m 9689/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 13ms/step - accuracy: 0.7827 - loss: 0.1517Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 23ms/step - accuracy: 0.7602 - loss: 0.1644\n",
      "\u001b[1m  440/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:57\u001b[0m 21ms/step - accuracy: 0.8149 - loss: 0.1317Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 23ms/step - accuracy: 0.7609 - loss: 0.1636\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 23ms/step - accuracy: 0.7635 - loss: 0.1638\n",
      "\u001b[1m  421/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 21ms/step - accuracy: 0.8049 - loss: 0.1328Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 24ms/step - accuracy: 0.7579 - loss: 0.1722\n",
      "\u001b[1m 8009/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 14ms/step - accuracy: 0.8097 - loss: 0.1322Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 24ms/step - accuracy: 0.7686 - loss: 0.1640\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 24ms/step - accuracy: 0.7273 - loss: 0.1897\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 24ms/step - accuracy: 0.7562 - loss: 0.1680\n",
      "\u001b[1m  319/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:42\u001b[0m 20ms/step - accuracy: 0.7909 - loss: 0.1426Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 24ms/step - accuracy: 0.7447 - loss: 0.1804\n",
      "\u001b[1m 1987/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:09\u001b[0m 20ms/step - accuracy: 0.8029 - loss: 0.1372Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 24ms/step - accuracy: 0.7635 - loss: 0.1650\n",
      "\u001b[1m 1156/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:40\u001b[0m 21ms/step - accuracy: 0.8094 - loss: 0.1312Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 25ms/step - accuracy: 0.7558 - loss: 0.1696\n",
      "\u001b[1m14632/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7557 - loss: 0.1727Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 11ms/step - accuracy: 0.6594 - loss: 0.2246\n",
      "\u001b[1m 6573/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 17ms/step - accuracy: 0.8126 - loss: 0.1304Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 25ms/step - accuracy: 0.7559 - loss: 0.1725\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 27ms/step - accuracy: 0.7525 - loss: 0.1851\n",
      "\u001b[1m 2090/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 20ms/step - accuracy: 0.8002 - loss: 0.1376Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7838 - loss: 0.1510\n",
      "\u001b[1m 4139/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 11ms/step - accuracy: 0.6601 - loss: 0.2243Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8045 - loss: 0.1357\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8048 - loss: 0.1352\n",
      "\u001b[1m11169/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m55s\u001b[0m 16ms/step - accuracy: 0.6586 - loss: 0.2249Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7672 - loss: 0.1611\n",
      "\u001b[1m 5785/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 19ms/step - accuracy: 0.7948 - loss: 0.1432Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.8110 - loss: 0.1315\n",
      "\u001b[1m 3090/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 22ms/step - accuracy: 0.8063 - loss: 0.1359Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 15ms/step - accuracy: 0.8118 - loss: 0.1314\n",
      "\u001b[1m 5247/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 22ms/step - accuracy: 0.8130 - loss: 0.1297Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 14ms/step - accuracy: 0.6914 - loss: 0.20448\n",
      "\u001b[1m 6437/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 21ms/step - accuracy: 0.8089 - loss: 0.1321Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 16ms/step - accuracy: 0.8094 - loss: 0.1319\n",
      "\u001b[1m12382/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.7536 - loss: 0.1685Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 14ms/step - accuracy: 0.8079 - loss: 0.1338\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 15ms/step - accuracy: 0.8111 - loss: 0.1314\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 15ms/step - accuracy: 0.6584 - loss: 0.2226\n",
      "\u001b[1m10645/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 11ms/step - accuracy: 0.6574 - loss: 0.2252Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 15ms/step - accuracy: 0.6601 - loss: 0.2244\n",
      "\u001b[1m 4665/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 21ms/step - accuracy: 0.8031 - loss: 0.1376Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.6587 - loss: 0.2248\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 15ms/step - accuracy: 0.8099 - loss: 0.1317\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 16ms/step - accuracy: 0.8132 - loss: 0.1299\n",
      "\u001b[1m 1031/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 0.1310Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 16ms/step - accuracy: 0.8116 - loss: 0.1310\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 17ms/step - accuracy: 0.8133 - loss: 0.1298\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 10ms/step - accuracy: 0.6590 - loss: 0.2247\n",
      "\u001b[1m13780/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6578 - loss: 0.2251Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.7548 - loss: 0.1679\n",
      "\u001b[1m 6251/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 21ms/step - accuracy: 0.8036 - loss: 0.1373Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11ms/step - accuracy: 0.6579 - loss: 0.2251\n",
      "\u001b[1m 1861/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 15ms/step - accuracy: 0.8142 - loss: 0.1290Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 18ms/step - accuracy: 0.8159 - loss: 0.1281\n",
      "\u001b[1m 8007/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 22ms/step - accuracy: 0.8103 - loss: 0.1315Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 18ms/step - accuracy: 0.8147 - loss: 0.1288\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 20ms/step - accuracy: 0.7967 - loss: 0.1426\n",
      "\u001b[1m13646/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.8069 - loss: 0.1345Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7914 - loss: 0.1460\n",
      "\u001b[1m 5247/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 16ms/step - accuracy: 0.8130 - loss: 0.1296Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.7750 - loss: 0.1577\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 20ms/step - accuracy: 0.7682 - loss: 0.1618\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 20ms/step - accuracy: 0.7969 - loss: 0.1423\n",
      "\u001b[1m12955/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.8087 - loss: 0.1331Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 20ms/step - accuracy: 0.7653 - loss: 0.1613\n",
      "\u001b[1m  915/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:32\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.1282Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 21ms/step - accuracy: 0.7974 - loss: 0.1413\n",
      "\u001b[1m11052/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 22ms/step - accuracy: 0.8076 - loss: 0.1345Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 21ms/step - accuracy: 0.8071 - loss: 0.1344\n",
      "\u001b[1m 9371/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 16ms/step - accuracy: 0.8126 - loss: 0.1298Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7752 - loss: 0.1568\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.8096 - loss: 0.1318\n",
      "\u001b[1m 7331/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 11ms/step - accuracy: 0.6598 - loss: 0.2244Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 22ms/step - accuracy: 0.8088 - loss: 0.1330\n",
      "\u001b[1m12049/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m58s\u001b[0m 22ms/step - accuracy: 0.8114 - loss: 0.1306Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 22ms/step - accuracy: 0.8099 - loss: 0.1311\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8118 - loss: 0.1301\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 22ms/step - accuracy: 0.8106 - loss: 0.1312\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.7910 - loss: 0.1465\n",
      "\u001b[1m 8454/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 27ms/step - accuracy: 0.8119 - loss: 0.1303Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 22ms/step - accuracy: 0.8058 - loss: 0.1344\n",
      "\u001b[1m13224/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m32s\u001b[0m 22ms/step - accuracy: 0.8115 - loss: 0.1305Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 23ms/step - accuracy: 0.8127 - loss: 0.1298\n",
      "\u001b[1m12848/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.8139 - loss: 0.1287Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 23ms/step - accuracy: 0.8109 - loss: 0.1309\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8116 - loss: 0.1307\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 23ms/step - accuracy: 0.8097 - loss: 0.1313\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 15ms/step - accuracy: 0.8108 - loss: 0.1318\n",
      "\u001b[1m 1541/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 22ms/step - accuracy: 0.8121 - loss: 0.1298Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 22ms/step - accuracy: 0.8080 - loss: 0.1341\n",
      "\u001b[1m  107/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 14ms/step - accuracy: 0.7931 - loss: 0.1399Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 22ms/step - accuracy: 0.8046 - loss: 0.1363\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 15ms/step - accuracy: 0.8112 - loss: 0.1313\n",
      "\u001b[1m 4742/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 20ms/step - accuracy: 0.7747 - loss: 0.1574Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 15ms/step - accuracy: 0.6586 - loss: 0.2225\n",
      "\u001b[1m 2504/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:26\u001b[0m 22ms/step - accuracy: 0.8085 - loss: 0.1317Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 22ms/step - accuracy: 0.8080 - loss: 0.1332\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 22ms/step - accuracy: 0.8086 - loss: 0.1321\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 15ms/step - accuracy: 0.8146 - loss: 0.1287\n",
      "\u001b[1m 4899/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 20ms/step - accuracy: 0.7804 - loss: 0.1541Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 22ms/step - accuracy: 0.8117 - loss: 0.1304\n",
      "\u001b[1m  611/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26\u001b[0m 15ms/step - accuracy: 0.8078 - loss: 0.1334Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 24ms/step - accuracy: 0.8121 - loss: 0.1304\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.6596 - loss: 0.2246\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 17ms/step - accuracy: 0.8130 - loss: 0.1295\n",
      "\u001b[1m 3484/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 22ms/step - accuracy: 0.8139 - loss: 0.1292Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 24ms/step - accuracy: 0.8100 - loss: 0.1311\n",
      "\u001b[1m  765/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:48\u001b[0m 21ms/step - accuracy: 0.8069 - loss: 0.1338Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 16ms/step - accuracy: 0.6585 - loss: 0.2249\n",
      "\u001b[1m 4373/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.1301Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.2246\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 15ms/step - accuracy: 0.8153 - loss: 0.1287\n",
      "\u001b[1m 5583/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 20ms/step - accuracy: 0.8058 - loss: 0.1371Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 23ms/step - accuracy: 0.8140 - loss: 0.1287\n",
      "\u001b[1m13896/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.8152 - loss: 0.1284Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 24ms/step - accuracy: 0.8147 - loss: 0.1290\n",
      "\u001b[1m 6613/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 14ms/step - accuracy: 0.7795 - loss: 0.1540Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 11ms/step - accuracy: 0.6584 - loss: 0.2250\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 24ms/step - accuracy: 0.8108 - loss: 0.1311\n",
      "\u001b[1m 5122/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 20ms/step - accuracy: 0.8037 - loss: 0.1380Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 16ms/step - accuracy: 0.8153 - loss: 0.1284\n",
      "\u001b[1m14457/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8128 - loss: 0.1295Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 16ms/step - accuracy: 0.8128 - loss: 0.1295\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 17ms/step - accuracy: 0.8174 - loss: 0.1274\n",
      "\u001b[1m 7750/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 19ms/step - accuracy: 0.8161 - loss: 0.1275Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 15ms/step - accuracy: 0.8124 - loss: 0.1307\n",
      "\u001b[1m 1772/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:38\u001b[0m 22ms/step - accuracy: 0.8137 - loss: 0.1296Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 16ms/step - accuracy: 0.8129 - loss: 0.1298\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 18ms/step - accuracy: 0.8164 - loss: 0.1274\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 18ms/step - accuracy: 0.7737 - loss: 0.1582\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.8183 - loss: 0.1261\n",
      "\u001b[1m 5322/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 23ms/step - accuracy: 0.8140 - loss: 0.1286Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.7966 - loss: 0.1428\n",
      "\u001b[1m 1901/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 16ms/step - accuracy: 0.8169 - loss: 0.1275Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 26ms/step - accuracy: 0.8119 - loss: 0.1302\n",
      "\u001b[1m 8128/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 22ms/step - accuracy: 0.8103 - loss: 0.1309Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.7810 - loss: 0.1531\n",
      "\u001b[1m 3455/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:27\u001b[0m 18ms/step - accuracy: 0.8166 - loss: 0.1277Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 19ms/step - accuracy: 0.8159 - loss: 0.1274\n",
      "\u001b[1m 8019/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 23ms/step - accuracy: 0.8136 - loss: 0.1298Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 11ms/step - accuracy: 0.6598 - loss: 0.2244\n",
      "\u001b[1m 7027/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 17ms/step - accuracy: 0.8144 - loss: 0.1285Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 11ms/step - accuracy: 0.6589 - loss: 0.2248\n",
      "\u001b[1m 5377/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 23ms/step - accuracy: 0.8148 - loss: 0.1288Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.7739 - loss: 0.1564\n",
      "\u001b[1m 8763/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 16ms/step - accuracy: 0.8168 - loss: 0.1269Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 20ms/step - accuracy: 0.7811 - loss: 0.1534\n",
      "\u001b[1m14574/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7770 - loss: 0.1559Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 20ms/step - accuracy: 0.7771 - loss: 0.1559\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 20ms/step - accuracy: 0.8058 - loss: 0.1367\n",
      "\u001b[1m 9658/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 23ms/step - accuracy: 0.8136 - loss: 0.1297Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.1305\n",
      "\u001b[1m 9032/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 22ms/step - accuracy: 0.8121 - loss: 0.1299Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.6586 - loss: 0.2249\n",
      "\u001b[1m10016/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 23ms/step - accuracy: 0.8132 - loss: 0.1290Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.8136 - loss: 0.1299\n",
      "\u001b[1m12078/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m58s\u001b[0m 22ms/step - accuracy: 0.8111 - loss: 0.1305Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 14ms/step - accuracy: 0.8032 - loss: 0.1391\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 15ms/step - accuracy: 0.8166 - loss: 0.1277\n",
      "\u001b[1m 9665/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 15ms/step - accuracy: 0.8159 - loss: 0.1286Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.6581 - loss: 0.2226\n",
      "\u001b[1m14596/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8040 - loss: 0.1379Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 20ms/step - accuracy: 0.8040 - loss: 0.1379\n",
      "\u001b[1m 8900/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 24ms/step - accuracy: 0.8128 - loss: 0.1296Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.6583 - loss: 0.2250\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8133 - loss: 0.1300\n",
      "\u001b[1m 1673/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 20ms/step - accuracy: 0.8091 - loss: 0.1339Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 21ms/step - accuracy: 0.8037 - loss: 0.1372\n",
      "\u001b[1m 1930/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.1294Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 22ms/step - accuracy: 0.8131 - loss: 0.1298\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 16ms/step - accuracy: 0.8148 - loss: 0.1280\n",
      "\u001b[1m 4976/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 10ms/step - accuracy: 0.6566 - loss: 0.2255Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 15ms/step - accuracy: 0.8170 - loss: 0.1277\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8114 - loss: 0.1303\n",
      "\u001b[1m12346/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m52s\u001b[0m 22ms/step - accuracy: 0.8115 - loss: 0.1305Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 15ms/step - accuracy: 0.8145 - loss: 0.1286\n",
      "\u001b[1m12792/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.8137 - loss: 0.1296Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 16ms/step - accuracy: 0.8171 - loss: 0.1269\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 16ms/step - accuracy: 0.8172 - loss: 0.1268\n",
      "\u001b[1m 2136/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:30\u001b[0m 22ms/step - accuracy: 0.8113 - loss: 0.1300Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 16ms/step - accuracy: 0.8148 - loss: 0.1284\n",
      "\u001b[1m10247/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 18ms/step - accuracy: 0.8199 - loss: 0.1250Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 23ms/step - accuracy: 0.8142 - loss: 0.1290\n",
      "\u001b[1m13869/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.8167 - loss: 0.1277Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 23ms/step - accuracy: 0.8156 - loss: 0.1279\n",
      "\u001b[1m13602/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.7988 - loss: 0.1417Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 15ms/step - accuracy: 0.8154 - loss: 0.1288\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7989 - loss: 0.1417\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 22ms/step - accuracy: 0.8168 - loss: 0.1277\n",
      "\u001b[1m14059/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.8120 - loss: 0.1312Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 23ms/step - accuracy: 0.8137 - loss: 0.1288\n",
      "\u001b[1m10442/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 10ms/step - accuracy: 0.6589 - loss: 0.2247Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 22ms/step - accuracy: 0.8110 - loss: 0.1312\n",
      "\u001b[1m 6107/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 20ms/step - accuracy: 0.7884 - loss: 0.1489Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8176 - loss: 0.1266\n",
      "\u001b[1m 6834/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 15ms/step - accuracy: 0.8169 - loss: 0.1274Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 22ms/step - accuracy: 0.8117 - loss: 0.1305\n",
      "\u001b[1m14632/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8120 - loss: 0.1311Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 23ms/step - accuracy: 0.8137 - loss: 0.1295\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 22ms/step - accuracy: 0.8120 - loss: 0.1311\n",
      "\u001b[1m 2850/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 22ms/step - accuracy: 0.8118 - loss: 0.1295Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 24ms/step - accuracy: 0.8143 - loss: 0.1286\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8124 - loss: 0.1298\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 18ms/step - accuracy: 0.7763 - loss: 0.1558\n",
      "\u001b[1m 1329/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:22\u001b[0m 15ms/step - accuracy: 0.8190 - loss: 0.1264Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 23ms/step - accuracy: 0.8147 - loss: 0.1285\n",
      "\u001b[1m 2651/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 21ms/step - accuracy: 0.8176 - loss: 0.1272Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 23ms/step - accuracy: 0.8133 - loss: 0.1297\n",
      "\u001b[1m 9185/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 15ms/step - accuracy: 0.8168 - loss: 0.1274Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 24ms/step - accuracy: 0.8128 - loss: 0.1295\n",
      "\u001b[1m 4702/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 21ms/step - accuracy: 0.8124 - loss: 0.1293Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.6589 - loss: 0.2247\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 23ms/step - accuracy: 0.8169 - loss: 0.1271\n",
      "\u001b[1m 2120/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05\u001b[0m 20ms/step - accuracy: 0.8140 - loss: 0.1300Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 24ms/step - accuracy: 0.8134 - loss: 0.1292\n",
      "\u001b[1m 2123/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05\u001b[0m 20ms/step - accuracy: 0.8140 - loss: 0.1300Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 24ms/step - accuracy: 0.8168 - loss: 0.1272\n",
      "\u001b[1m 9056/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 19ms/step - accuracy: 0.7809 - loss: 0.1527Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 10ms/step - accuracy: 0.6584 - loss: 0.2249\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 18ms/step - accuracy: 0.8197 - loss: 0.1251\n",
      "\u001b[1m 6178/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 20ms/step - accuracy: 0.8132 - loss: 0.1294Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 10ms/step - accuracy: 0.6608 - loss: 0.2242\n",
      "\u001b[1m 4500/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 15ms/step - accuracy: 0.8173 - loss: 0.1274Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 13ms/step - accuracy: 0.7892 - loss: 0.1476\n",
      "\u001b[1m 2891/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 20ms/step - accuracy: 0.8084 - loss: 0.1325Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 24ms/step - accuracy: 0.8141 - loss: 0.1293\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 22ms/step - accuracy: 0.8153 - loss: 0.1284\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1298\n",
      "\u001b[1m 4507/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 22ms/step - accuracy: 0.8145 - loss: 0.1284Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 18ms/step - accuracy: 0.8164 - loss: 0.1272\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.8169 - loss: 0.1273\n",
      "\u001b[1m10708/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 16ms/step - accuracy: 0.8150 - loss: 0.1279Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 15ms/step - accuracy: 0.6587 - loss: 0.2225\n",
      "\u001b[1m 3566/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 23ms/step - accuracy: 0.8141 - loss: 0.1285Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.6580 - loss: 0.2251\n",
      "\u001b[1m 1862/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 15ms/step - accuracy: 0.8165 - loss: 0.1279Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1296\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.7819 - loss: 0.1523\n",
      "\u001b[1m 4678/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:51\u001b[0m 23ms/step - accuracy: 0.8143 - loss: 0.1284Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 19ms/step - accuracy: 0.7889 - loss: 0.1484\n",
      "\u001b[1m 5063/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 23ms/step - accuracy: 0.8154 - loss: 0.1276Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.8059 - loss: 0.1365\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 24ms/step - accuracy: 0.8140 - loss: 0.1285\n",
      "\u001b[1m 7469/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 21ms/step - accuracy: 0.8106 - loss: 0.1311Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 0.1270\n",
      "\u001b[1m 5096/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 21ms/step - accuracy: 0.8179 - loss: 0.1279Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 18ms/step - accuracy: 0.7853 - loss: 0.1497\n",
      "\u001b[1m 4624/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 15ms/step - accuracy: 0.8154 - loss: 0.1286Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 20ms/step - accuracy: 0.8079 - loss: 0.1349\n",
      "\u001b[1m 3876/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 24ms/step - accuracy: 0.8187 - loss: 0.1266Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 16ms/step - accuracy: 0.8152 - loss: 0.1277\n",
      "\u001b[1m12537/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m44s\u001b[0m 21ms/step - accuracy: 0.8143 - loss: 0.1290Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 0.1396\n",
      "\u001b[1m12850/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.8143 - loss: 0.1290Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 21ms/step - accuracy: 0.8145 - loss: 0.1289\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 15ms/step - accuracy: 0.8156 - loss: 0.1284\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.2246\n",
      "\u001b[1m 9576/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 22ms/step - accuracy: 0.8176 - loss: 0.1269Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8187 - loss: 0.1253\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 22ms/step - accuracy: 0.8133 - loss: 0.1292\n",
      "\u001b[1m 1496/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 15ms/step - accuracy: 0.8170 - loss: 0.1284Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 11ms/step - accuracy: 0.6579 - loss: 0.2251\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.7922 - loss: 0.1450\n",
      "\u001b[1m 2135/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 15ms/step - accuracy: 0.8165 - loss: 0.1283Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 22ms/step - accuracy: 0.8133 - loss: 0.1292\n",
      "\u001b[1m 6522/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 19ms/step - accuracy: 0.7878 - loss: 0.1505Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 23ms/step - accuracy: 0.8169 - loss: 0.1271\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 11ms/step - accuracy: 0.6587 - loss: 0.2248\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 22ms/step - accuracy: 0.8142 - loss: 0.1291\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 16ms/step - accuracy: 0.6586 - loss: 0.2249\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 22ms/step - accuracy: 0.8176 - loss: 0.1269\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.8075 - loss: 0.1353\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 23ms/step - accuracy: 0.8158 - loss: 0.1274\n",
      "\u001b[1m11461/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 23ms/step - accuracy: 0.8163 - loss: 0.1275Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 22ms/step - accuracy: 0.8159 - loss: 0.1286\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 24ms/step - accuracy: 0.8180 - loss: 0.1259\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 24ms/step - accuracy: 0.8149 - loss: 0.1280\n",
      "\u001b[1m13031/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.8177 - loss: 0.1267Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 24ms/step - accuracy: 0.8153 - loss: 0.1278\n",
      "\u001b[1m12306/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8159 - loss: 0.1269Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 19ms/step - accuracy: 0.8175 - loss: 0.1259\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 15ms/step - accuracy: 0.6589 - loss: 0.2224\n",
      "\u001b[1m 6099/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 22ms/step - accuracy: 0.8149 - loss: 0.1287Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 24ms/step - accuracy: 0.8144 - loss: 0.1283\n",
      "\u001b[1m 3601/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 17ms/step - accuracy: 0.7858 - loss: 0.1515Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 14ms/step - accuracy: 0.8029 - loss: 0.1378\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 23ms/step - accuracy: 0.8144 - loss: 0.1283\n",
      "\u001b[1m13599/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.8159 - loss: 0.1269Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 11ms/step - accuracy: 0.6592 - loss: 0.2246\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 15ms/step - accuracy: 0.8153 - loss: 0.1288\n",
      "\u001b[1m12570/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 17ms/step - accuracy: 0.8198 - loss: 0.1252Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 20ms/step - accuracy: 0.8107 - loss: 0.1331\n",
      "\u001b[1m 8709/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 21ms/step - accuracy: 0.8138 - loss: 0.1302Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 20ms/step - accuracy: 0.8105 - loss: 0.1336\n",
      "\u001b[1m14052/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.8160 - loss: 0.1273Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 11ms/step - accuracy: 0.6585 - loss: 0.2249\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 18ms/step - accuracy: 0.8196 - loss: 0.1249\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 25ms/step - accuracy: 0.8160 - loss: 0.1273\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 15ms/step - accuracy: 0.8150 - loss: 0.1288\n",
      "\u001b[1m 4166/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:59\u001b[0m 23ms/step - accuracy: 0.8177 - loss: 0.1268Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 22ms/step - accuracy: 0.8164 - loss: 0.1279\n",
      "\u001b[1m 6443/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1288Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 21ms/step - accuracy: 0.8105 - loss: 0.1333\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8043 - loss: 0.1369\n",
      "\u001b[1m 4953/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 18ms/step - accuracy: 0.8188 - loss: 0.1254Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 22ms/step - accuracy: 0.8139 - loss: 0.1299\n",
      "\u001b[1m 6270/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 21ms/step - accuracy: 0.8087 - loss: 0.1340Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 23ms/step - accuracy: 0.8158 - loss: 0.1279\n",
      "\u001b[1m 9332/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 16ms/step - accuracy: 0.8197 - loss: 0.1253Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 15ms/step - accuracy: 0.6585 - loss: 0.2223\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 15ms/step - accuracy: 0.8196 - loss: 0.1256\n",
      "\u001b[1m10235/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.1271Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.8202 - loss: 0.1244\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.2246\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 16ms/step - accuracy: 0.8175 - loss: 0.1263\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 15ms/step - accuracy: 0.8158 - loss: 0.1286\n",
      "\u001b[1m  334/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 15ms/step - accuracy: 0.8205 - loss: 0.1246Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 21ms/step - accuracy: 0.8153 - loss: 0.1282\n",
      "\u001b[1m 1219/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 16ms/step - accuracy: 0.6620 - loss: 0.2210Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.8155 - loss: 0.1277\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 24ms/step - accuracy: 0.8159 - loss: 0.1274\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.8155 - loss: 0.1282\n",
      "\u001b[1m 3763/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1264Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 23ms/step - accuracy: 0.8167 - loss: 0.1269\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 23ms/step - accuracy: 0.8191 - loss: 0.1253\n",
      "\u001b[1m12908/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - accuracy: 0.8092 - loss: 0.1339Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 23ms/step - accuracy: 0.8167 - loss: 0.1272\n",
      "\u001b[1m 3680/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 18ms/step - accuracy: 0.7932 - loss: 0.1470Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.8198 - loss: 0.1249\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8134 - loss: 0.1320\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 23ms/step - accuracy: 0.8178 - loss: 0.1265\n",
      "\u001b[1m  550/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 22ms/step - accuracy: 0.8163 - loss: 0.1281Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 15ms/step - accuracy: 0.8185 - loss: 0.1261\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 23ms/step - accuracy: 0.8163 - loss: 0.1273\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.1325\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 20ms/step - accuracy: 0.8093 - loss: 0.1338\n",
      "\u001b[1m11421/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m59s\u001b[0m 18ms/step - accuracy: 0.8197 - loss: 0.1250Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8058 - loss: 0.1363\n",
      "\u001b[1m 5830/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 18ms/step - accuracy: 0.7931 - loss: 0.1473Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 11ms/step - accuracy: 0.6601 - loss: 0.2244\n",
      "\u001b[1m 4270/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 16ms/step - accuracy: 0.8106 - loss: 0.1334Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 15ms/step - accuracy: 0.8157 - loss: 0.1286\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.8197 - loss: 0.1256\n",
      "\u001b[1m 5336/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 17ms/step - accuracy: 0.8157 - loss: 0.1282Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 17ms/step - accuracy: 0.8183 - loss: 0.1262\n",
      "\u001b[1m 7759/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 20ms/step - accuracy: 0.8153 - loss: 0.1281Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 16ms/step - accuracy: 0.8166 - loss: 0.1272\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 21ms/step - accuracy: 0.8152 - loss: 0.1284\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.7975 - loss: 0.1417\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 21ms/step - accuracy: 0.8159 - loss: 0.1277\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 20ms/step - accuracy: 0.8203 - loss: 0.1246\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 16ms/step - accuracy: 0.8137 - loss: 0.1316\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.1273\n",
      "\u001b[1m11911/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m55s\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.1261Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 21ms/step - accuracy: 0.8176 - loss: 0.1263\n",
      "\u001b[1m13315/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - accuracy: 0.8185 - loss: 0.1261Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.6592 - loss: 0.2247\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 21ms/step - accuracy: 0.8192 - loss: 0.1255\n",
      "\u001b[1m13350/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - accuracy: 0.8186 - loss: 0.1255Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 19ms/step - accuracy: 0.8149 - loss: 0.1283\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 22ms/step - accuracy: 0.8201 - loss: 0.1242\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 16ms/step - accuracy: 0.8097 - loss: 0.1340\n",
      "\u001b[1m 5085/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 19ms/step - accuracy: 0.8179 - loss: 0.1272Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 19ms/step - accuracy: 0.8154 - loss: 0.1282\n",
      "\u001b[1m13823/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.1262Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12ms/step - accuracy: 0.6597 - loss: 0.2245\n",
      "\u001b[1m 7035/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 19ms/step - accuracy: 0.8185 - loss: 0.1258Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 12ms/step - accuracy: 0.6588 - loss: 0.2248\n",
      "\u001b[1m13539/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - accuracy: 0.8157 - loss: 0.1274Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.6594 - loss: 0.2220\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 20ms/step - accuracy: 0.8184 - loss: 0.1262\n",
      "\u001b[1m 6659/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 21ms/step - accuracy: 0.8216 - loss: 0.1234Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 17ms/step - accuracy: 0.8160 - loss: 0.1280\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.8111 - loss: 0.1330\n",
      "\u001b[1m   55/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 17ms/step - accuracy: 0.8005 - loss: 0.1373Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 20ms/step - accuracy: 0.8186 - loss: 0.1255\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 20ms/step - accuracy: 0.8214 - loss: 0.1238\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.1262\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 15ms/step - accuracy: 0.7260 - loss: 0.1847\n",
      "\u001b[1m 6228/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 20ms/step - accuracy: 0.8168 - loss: 0.1272Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 21ms/step - accuracy: 0.8163 - loss: 0.1271\n",
      "\u001b[1m  874/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 18ms/step - accuracy: 0.8192 - loss: 0.1240Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 22ms/step - accuracy: 0.8158 - loss: 0.1274\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 18ms/step - accuracy: 0.8139 - loss: 0.1313\n",
      "\u001b[1m 8880/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 23ms/step - accuracy: 0.8161 - loss: 0.1270Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 20ms/step - accuracy: 0.8160 - loss: 0.1271\n",
      "\u001b[1m 8751/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 19ms/step - accuracy: 0.8185 - loss: 0.1258Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 12ms/step - accuracy: 0.6599 - loss: 0.2245\n",
      "\u001b[1m 3684/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:37\u001b[0m 20ms/step - accuracy: 0.8189 - loss: 0.1256Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 15ms/step - accuracy: 0.7955 - loss: 0.1426\n",
      "\u001b[1m 4618/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.1267Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 17ms/step - accuracy: 0.8165 - loss: 0.1281\n",
      "\u001b[1m 8943/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 12ms/step - accuracy: 0.6593 - loss: 0.2246Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 16ms/step - accuracy: 0.7942 - loss: 0.1469\n",
      "\u001b[1m12361/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.8208 - loss: 0.1246Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 19ms/step - accuracy: 0.8187 - loss: 0.1257\n",
      "\u001b[1m 8488/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 19ms/step - accuracy: 0.8152 - loss: 0.1276Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 23ms/step - accuracy: 0.8164 - loss: 0.1268\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.8011 - loss: 0.1403\n",
      "\u001b[1m10420/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 19ms/step - accuracy: 0.8189 - loss: 0.1259Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 18ms/step - accuracy: 0.8161 - loss: 0.1270\n",
      "\u001b[1m10102/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 21ms/step - accuracy: 0.8167 - loss: 0.1266Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 19ms/step - accuracy: 0.8167 - loss: 0.1275\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 21ms/step - accuracy: 0.8218 - loss: 0.1234\n",
      "\u001b[1m10657/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 17ms/step - accuracy: 0.8085 - loss: 0.1341Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 19ms/step - accuracy: 0.8169 - loss: 0.1278\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 21ms/step - accuracy: 0.8167 - loss: 0.1266\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 17ms/step - accuracy: 0.8123 - loss: 0.1319\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 18ms/step - accuracy: 0.8163 - loss: 0.1276\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 19ms/step - accuracy: 0.8156 - loss: 0.1275\n",
      "\u001b[1m 4549/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 19ms/step - accuracy: 0.8169 - loss: 0.1268Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.8182 - loss: 0.1256\n",
      "\u001b[1m 6660/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 16ms/step - accuracy: 0.7947 - loss: 0.1471Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 21ms/step - accuracy: 0.8166 - loss: 0.1263\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 19ms/step - accuracy: 0.8173 - loss: 0.1264\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 18ms/step - accuracy: 0.8138 - loss: 0.1312\n",
      "\u001b[1m12061/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m55s\u001b[0m 21ms/step - accuracy: 0.8176 - loss: 0.1268Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 19ms/step - accuracy: 0.8207 - loss: 0.1244\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 21ms/step - accuracy: 0.8207 - loss: 0.1243\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 21ms/step - accuracy: 0.8200 - loss: 0.1247\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 12ms/step - accuracy: 0.6596 - loss: 0.2246\n",
      "\u001b[1m  176/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:03\u001b[0m 21ms/step - accuracy: 0.8114 - loss: 0.1263Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 18ms/step - accuracy: 0.8199 - loss: 0.1250\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 19ms/step - accuracy: 0.8174 - loss: 0.1274\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 20ms/step - accuracy: 0.8214 - loss: 0.1241\n",
      "\u001b[1m  228/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 18ms/step - accuracy: 0.8101 - loss: 0.1292Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 19ms/step - accuracy: 0.8149 - loss: 0.1282\n",
      "\u001b[1m10265/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 21ms/step - accuracy: 0.8157 - loss: 0.1272Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 19ms/step - accuracy: 0.8195 - loss: 0.1253\n",
      "\u001b[1m 3699/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 18ms/step - accuracy: 0.8217 - loss: 0.1242Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 16ms/step - accuracy: 0.8144 - loss: 0.1305\n",
      "\u001b[1m 8279/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 19ms/step - accuracy: 0.8202 - loss: 0.1241Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 19ms/step - accuracy: 0.8162 - loss: 0.1278\n",
      "\u001b[1m 7408/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 21ms/step - accuracy: 0.8211 - loss: 0.1237Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 18ms/step - accuracy: 0.8178 - loss: 0.1265\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 18ms/step - accuracy: 0.8203 - loss: 0.1245\n",
      "\u001b[1m13287/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - accuracy: 0.8171 - loss: 0.1259Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 19ms/step - accuracy: 0.8166 - loss: 0.1270\n",
      "\u001b[1m 7997/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 21ms/step - accuracy: 0.8216 - loss: 0.1237Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.8203 - loss: 0.1243\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 15ms/step - accuracy: 0.7919 - loss: 0.1480\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.8204 - loss: 0.1252\n",
      "\u001b[1m  240/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 13ms/step - accuracy: 0.6610 - loss: 0.2242Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 19ms/step - accuracy: 0.8200 - loss: 0.1243\n",
      "\u001b[1m  333/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 15ms/step - accuracy: 0.7967 - loss: 0.1390Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 12ms/step - accuracy: 0.6592 - loss: 0.2220\n",
      "\u001b[1m 4203/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 18ms/step - accuracy: 0.8183 - loss: 0.1257Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 19ms/step - accuracy: 0.8164 - loss: 0.1278\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 20ms/step - accuracy: 0.8179 - loss: 0.1260\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 19ms/step - accuracy: 0.8164 - loss: 0.1277\n",
      "\u001b[1m 1914/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 14ms/step - accuracy: 0.7988 - loss: 0.1401Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 19ms/step - accuracy: 0.8174 - loss: 0.1269\n",
      "\u001b[1m 8540/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 21ms/step - accuracy: 0.8163 - loss: 0.1267Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 20ms/step - accuracy: 0.8209 - loss: 0.1241\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 21ms/step - accuracy: 0.8215 - loss: 0.1238\n",
      "\u001b[1m 9768/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 17ms/step - accuracy: 0.8224 - loss: 0.1243Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 21ms/step - accuracy: 0.8210 - loss: 0.1238\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 19ms/step - accuracy: 0.8168 - loss: 0.1262\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 12ms/step - accuracy: 0.6592 - loss: 0.2246\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 15ms/step - accuracy: 0.8038 - loss: 0.1384\n",
      "\u001b[1m 6254/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 16ms/step - accuracy: 0.8105 - loss: 0.1334Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 19ms/step - accuracy: 0.8190 - loss: 0.1255\n",
      "\u001b[1m 6651/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 19ms/step - accuracy: 0.8167 - loss: 0.1278Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 17ms/step - accuracy: 0.8204 - loss: 0.1249\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 20ms/step - accuracy: 0.8170 - loss: 0.1265\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 17ms/step - accuracy: 0.8166 - loss: 0.1275\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 16ms/step - accuracy: 0.8100 - loss: 0.1337\n",
      "\u001b[1m 6050/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 21ms/step - accuracy: 0.8220 - loss: 0.1236Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 18ms/step - accuracy: 0.8185 - loss: 0.1257\n",
      "\u001b[1m 9488/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 19ms/step - accuracy: 0.8214 - loss: 0.1243Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 19ms/step - accuracy: 0.8187 - loss: 0.1252\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 17ms/step - accuracy: 0.8173 - loss: 0.1270\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.6598 - loss: 0.2245\n",
      "\u001b[1m12857/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.8176 - loss: 0.1266Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 12ms/step - accuracy: 0.6594 - loss: 0.2219\n",
      "\u001b[1m13791/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.8127 - loss: 0.1318Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 19ms/step - accuracy: 0.8170 - loss: 0.1274\n",
      "\u001b[1m10560/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 19ms/step - accuracy: 0.8214 - loss: 0.1243Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 18ms/step - accuracy: 0.8192 - loss: 0.1254\n",
      "\u001b[1m 4771/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 21ms/step - accuracy: 0.8189 - loss: 0.1256Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 18ms/step - accuracy: 0.8194 - loss: 0.1255\n",
      "\u001b[1m 6917/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 20ms/step - accuracy: 0.8206 - loss: 0.1235Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 17ms/step - accuracy: 0.8127 - loss: 0.1318\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 19ms/step - accuracy: 0.8158 - loss: 0.1277\n",
      "\u001b[1m 7726/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 19ms/step - accuracy: 0.8177 - loss: 0.1276Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 15ms/step - accuracy: 0.8002 - loss: 0.1398\n",
      "\u001b[1m  448/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25\u001b[0m 19ms/step - accuracy: 0.8158 - loss: 0.1266Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 18ms/step - accuracy: 0.8207 - loss: 0.1244\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 12ms/step - accuracy: 0.6593 - loss: 0.2246\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 19ms/step - accuracy: 0.8176 - loss: 0.1266\n",
      "\u001b[1m 9003/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 15ms/step - accuracy: 0.8023 - loss: 0.1390Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 17ms/step - accuracy: 0.8189 - loss: 0.1267\n",
      "\u001b[1m 9394/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 12ms/step - accuracy: 0.6604 - loss: 0.2243Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 19ms/step - accuracy: 0.8211 - loss: 0.1246\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 21ms/step - accuracy: 0.8207 - loss: 0.1240\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 19ms/step - accuracy: 0.8178 - loss: 0.1274\n",
      "\u001b[1m 2148/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 20ms/step - accuracy: 0.8183 - loss: 0.1262Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 20ms/step - accuracy: 0.8183 - loss: 0.1260\n",
      "\u001b[1m12726/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.8196 - loss: 0.1257Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 19ms/step - accuracy: 0.8185 - loss: 0.1258\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 20ms/step - accuracy: 0.8209 - loss: 0.1235\n",
      "\u001b[1m10177/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 17ms/step - accuracy: 0.8165 - loss: 0.1271Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 21ms/step - accuracy: 0.8216 - loss: 0.1238\n",
      "\u001b[1m 3025/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 22ms/step - accuracy: 0.8195 - loss: 0.1260Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.8154 - loss: 0.1299\n",
      "\u001b[1m11065/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m56s\u001b[0m 15ms/step - accuracy: 0.8095 - loss: 0.1337Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 19ms/step - accuracy: 0.8141 - loss: 0.1301\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8205 - loss: 0.1248\n",
      "\u001b[1m10029/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 18ms/step - accuracy: 0.8190 - loss: 0.1256Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 12ms/step - accuracy: 0.6585 - loss: 0.2249\n",
      "\u001b[1m 7819/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 21ms/step - accuracy: 0.8207 - loss: 0.1243Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 18ms/step - accuracy: 0.8120 - loss: 0.1320\n",
      "\u001b[1m14558/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8187 - loss: 0.1258Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 18ms/step - accuracy: 0.8225 - loss: 0.1238\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 20ms/step - accuracy: 0.8172 - loss: 0.1269\n",
      "\u001b[1m14332/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8170 - loss: 0.1272Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 22ms/step - accuracy: 0.8187 - loss: 0.1258\n",
      "\u001b[1m13285/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8000 - loss: 0.1400Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 18ms/step - accuracy: 0.8199 - loss: 0.1249\n",
      "\u001b[1m 4137/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 17ms/step - accuracy: 0.7955 - loss: 0.1451Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 20ms/step - accuracy: 0.8170 - loss: 0.1272\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 15ms/step - accuracy: 0.8000 - loss: 0.1400\n",
      "\u001b[1m 4196/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 18ms/step - accuracy: 0.8202 - loss: 0.1251Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 19ms/step - accuracy: 0.8155 - loss: 0.1298\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 18ms/step - accuracy: 0.8185 - loss: 0.1260\n",
      "\u001b[1m 9643/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 17ms/step - accuracy: 0.8210 - loss: 0.1244Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 16ms/step - accuracy: 0.8170 - loss: 0.1274\n",
      "\u001b[1m 8318/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 21ms/step - accuracy: 0.8176 - loss: 0.1261Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.1264\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 20ms/step - accuracy: 0.8162 - loss: 0.1275\n",
      "\u001b[1m  615/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:26\u001b[0m 19ms/step - accuracy: 0.8228 - loss: 0.1223Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.8007 - loss: 0.1393\n",
      "\u001b[1m 8613/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 19ms/step - accuracy: 0.8154 - loss: 0.1301Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 21ms/step - accuracy: 0.8180 - loss: 0.1259\n",
      "\u001b[1m   61/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 14ms/step - accuracy: 0.8094 - loss: 0.1346Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 16ms/step - accuracy: 0.8101 - loss: 0.1334\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 22ms/step - accuracy: 0.8219 - loss: 0.1239\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 17ms/step - accuracy: 0.8190 - loss: 0.1255\n",
      "\u001b[1m 9356/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 15ms/step - accuracy: 0.7998 - loss: 0.1396Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 16ms/step - accuracy: 0.8159 - loss: 0.1276\n",
      "\u001b[1m 9153/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 15ms/step - accuracy: 0.8030 - loss: 0.1390Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.8199 - loss: 0.1249\n",
      "\u001b[1m 8594/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 12ms/step - accuracy: 0.6599 - loss: 0.2244Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 21ms/step - accuracy: 0.8195 - loss: 0.1252\n",
      "\u001b[1m 5841/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 20ms/step - accuracy: 0.8140 - loss: 0.1289Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 20ms/step - accuracy: 0.8198 - loss: 0.1255\n",
      "\u001b[1m 5221/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 22ms/step - accuracy: 0.8216 - loss: 0.1239Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 17ms/step - accuracy: 0.8210 - loss: 0.1242\n",
      "\u001b[1m 3482/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 11ms/step - accuracy: 0.6590 - loss: 0.2247Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 11ms/step - accuracy: 0.6587 - loss: 0.2249\n",
      "\u001b[1m 9507/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 17ms/step - accuracy: 0.8170 - loss: 0.1271Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 18ms/step - accuracy: 0.7963 - loss: 0.1451\n",
      "\u001b[1m 3847/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:08\u001b[0m 23ms/step - accuracy: 0.8186 - loss: 0.1251Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 21ms/step - accuracy: 0.8177 - loss: 0.1263\n",
      "\u001b[1m13039/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.8154 - loss: 0.1282Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 20ms/step - accuracy: 0.8243 - loss: 0.1223\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 20ms/step - accuracy: 0.8184 - loss: 0.1261\n",
      "\u001b[1m 1236/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 17ms/step - accuracy: 0.7953 - loss: 0.1457Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.8216 - loss: 0.1239\n",
      "\u001b[1m 6054/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 16ms/step - accuracy: 0.8171 - loss: 0.1271Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 18ms/step - accuracy: 0.8195 - loss: 0.1250\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1256\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 22ms/step - accuracy: 0.8197 - loss: 0.1252\n",
      "\u001b[1m11706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m52s\u001b[0m 18ms/step - accuracy: 0.8229 - loss: 0.1234Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 16ms/step - accuracy: 0.8174 - loss: 0.1270\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 20ms/step - accuracy: 0.8202 - loss: 0.1254\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 11ms/step - accuracy: 0.6583 - loss: 0.2250\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 21ms/step - accuracy: 0.8195 - loss: 0.1245\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 14ms/step - accuracy: 0.8012 - loss: 0.1393\n",
      "\u001b[1m 8913/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 21ms/step - accuracy: 0.8181 - loss: 0.1260Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 15ms/step - accuracy: 0.8177 - loss: 0.1286\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 11ms/step - accuracy: 0.6598 - loss: 0.2245\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 18ms/step - accuracy: 0.8203 - loss: 0.1248\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 16ms/step - accuracy: 0.8208 - loss: 0.1248\n",
      "\u001b[1m11484/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 14ms/step - accuracy: 0.8026 - loss: 0.1384Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8228 - loss: 0.1234\n",
      "\u001b[1m 8071/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 16ms/step - accuracy: 0.8174 - loss: 0.1269Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 20ms/step - accuracy: 0.8242 - loss: 0.1220\n",
      "\u001b[1m10151/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 22ms/step - accuracy: 0.8201 - loss: 0.1241Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 11ms/step - accuracy: 0.6584 - loss: 0.2249\n",
      "\u001b[1m12778/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.8227 - loss: 0.1229Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 16ms/step - accuracy: 0.8166 - loss: 0.1271\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17ms/step - accuracy: 0.8181 - loss: 0.1259\n",
      "\u001b[1m13003/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.8180 - loss: 0.1260Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 18ms/step - accuracy: 0.8193 - loss: 0.1255\n",
      "\u001b[1m12065/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8195 - loss: 0.1266Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 15ms/step - accuracy: 0.8118 - loss: 0.1325\n",
      "\u001b[1m 5544/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 23ms/step - accuracy: 0.8189 - loss: 0.1257Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.6609 - loss: 0.2213\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8189 - loss: 0.1255\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 19ms/step - accuracy: 0.8228 - loss: 0.1229\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 21ms/step - accuracy: 0.8183 - loss: 0.1268\n",
      "\u001b[1m 8589/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 22ms/step - accuracy: 0.8203 - loss: 0.1246Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 17ms/step - accuracy: 0.8217 - loss: 0.1236\n",
      "\u001b[1m 6646/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 23ms/step - accuracy: 0.8189 - loss: 0.1257Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 22ms/step - accuracy: 0.8181 - loss: 0.1260\n",
      "\u001b[1m12861/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.8059 - loss: 0.1376Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 15ms/step - accuracy: 0.7994 - loss: 0.1397\n",
      "\u001b[1m13794/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.8233 - loss: 0.1232Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 16ms/step - accuracy: 0.8193 - loss: 0.1267\n",
      "\u001b[1m13055/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.8182 - loss: 0.1255Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 19ms/step - accuracy: 0.8165 - loss: 0.1287\n",
      "\u001b[1m 2651/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 21ms/step - accuracy: 0.8206 - loss: 0.1240Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 16ms/step - accuracy: 0.8176 - loss: 0.1267\n",
      "\u001b[1m 4458/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 17ms/step - accuracy: 0.8234 - loss: 0.1229Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 22ms/step - accuracy: 0.8236 - loss: 0.1226\n",
      "\u001b[1m 1422/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 19ms/step - accuracy: 0.8118 - loss: 0.1309Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 23ms/step - accuracy: 0.8186 - loss: 0.1256\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 11ms/step - accuracy: 0.6584 - loss: 0.2249\n",
      "\u001b[1m 6304/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 11ms/step - accuracy: 0.6584 - loss: 0.2249Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 21ms/step - accuracy: 0.8172 - loss: 0.1266\n",
      "\u001b[1m 6625/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 15ms/step - accuracy: 0.6603 - loss: 0.2243Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 16ms/step - accuracy: 0.8180 - loss: 0.1268\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 17ms/step - accuracy: 0.8188 - loss: 0.1251\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 17ms/step - accuracy: 0.8192 - loss: 0.1253\n",
      "\u001b[1m  174/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:54\u001b[0m 29ms/step - accuracy: 0.8087 - loss: 0.1278Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 15ms/step - accuracy: 0.8165 - loss: 0.1289\n",
      "\u001b[1m 4855/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 24ms/step - accuracy: 0.8187 - loss: 0.1253Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 0.2247\n",
      "\u001b[1m 9922/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 21ms/step - accuracy: 0.8201 - loss: 0.1247Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8023 - loss: 0.1382\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 17ms/step - accuracy: 0.8237 - loss: 0.1230\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8213 - loss: 0.1238\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 22ms/step - accuracy: 0.8229 - loss: 0.1231\n",
      "\u001b[1m 1813/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:43\u001b[0m 22ms/step - accuracy: 0.8147 - loss: 0.1287Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 20ms/step - accuracy: 0.8155 - loss: 0.1295\n",
      "\u001b[1m 2181/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 14ms/step - accuracy: 0.8128 - loss: 0.1327Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 22ms/step - accuracy: 0.8209 - loss: 0.1246\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.1261\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.6724 - loss: 0.2174\n",
      "\u001b[1m12708/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1253Epoch 21/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/steptep - accuracy: 0.8211 - loss: 0.1222\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 11ms/step - accuracy: 0.6590 - loss: 0.2248\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8032 - loss: 0.1378\n",
      "\u001b[1m 4561/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.1282Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 18ms/step - accuracy: 0.8210 - loss: 0.1240\n",
      "\u001b[1m10647/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - accuracy: 0.6591 - loss: 0.2247Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 15ms/step - accuracy: 0.8162 - loss: 0.1297\n",
      "\u001b[1m 8797/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 18ms/step - accuracy: 0.7981 - loss: 0.1435Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 20ms/step - accuracy: 0.8246 - loss: 0.1218\n",
      "\u001b[1m14343/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1253Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 23ms/step - accuracy: 0.8237 - loss: 0.1224\n",
      "\u001b[1m14703/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.1257Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.1257\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 24ms/step - accuracy: 0.8187 - loss: 0.1253\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 16ms/step - accuracy: 0.8212 - loss: 0.1243\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1253\n",
      "\u001b[1m 2747/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 15ms/step - accuracy: 0.6828 - loss: 0.2106Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 21ms/step - accuracy: 0.8186 - loss: 0.1260\n",
      "\u001b[1m 6874/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 14ms/step - accuracy: 0.8054 - loss: 0.1372Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 23ms/step - accuracy: 0.8206 - loss: 0.1246\n",
      "\u001b[1m13671/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8179 - loss: 0.1281Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 20ms/step - accuracy: 0.8211 - loss: 0.1248\n",
      "\u001b[1m 6991/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 24ms/step - accuracy: 0.8205 - loss: 0.1239Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 17ms/step - accuracy: 0.8231 - loss: 0.1229\n",
      "\u001b[1m14048/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.8223 - loss: 0.1235Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 15ms/step - accuracy: 0.6849 - loss: 0.2104\n",
      "\u001b[1m 8507/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 21ms/step - accuracy: 0.8187 - loss: 0.1253Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8043 - loss: 0.1370\n",
      "\u001b[1m 6317/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 18ms/step - accuracy: 0.8257 - loss: 0.1212Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8222 - loss: 0.1236\n",
      "\u001b[1m11538/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - accuracy: 0.8220 - loss: 0.1239Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 20ms/step - accuracy: 0.8179 - loss: 0.1281\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 15ms/step - accuracy: 0.8135 - loss: 0.1317\n",
      "\u001b[1m 7825/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 23ms/step - accuracy: 0.8205 - loss: 0.1240Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 21ms/step - accuracy: 0.8203 - loss: 0.1242\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 11ms/step - accuracy: 0.6586 - loss: 0.2248\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/stepstep - accuracy: 0.8220 - loss: 0.122\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 21ms/step - accuracy: 0.8178 - loss: 0.1266\n",
      "\u001b[1m 9652/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 20ms/step - accuracy: 0.8175 - loss: 0.1284Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.1244\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 23ms/step - accuracy: 0.8236 - loss: 0.1225\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 21ms/step - accuracy: 0.8194 - loss: 0.1254\n",
      "\u001b[1m 5578/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 24ms/step - accuracy: 0.8209 - loss: 0.1238Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 15ms/step - accuracy: 0.8205 - loss: 0.1244\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 15ms/step - accuracy: 0.8224 - loss: 0.1233\n",
      "\u001b[1m 7767/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 15ms/step - accuracy: 0.8241 - loss: 0.1227Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 20ms/step - accuracy: 0.8159 - loss: 0.1292\n",
      "\u001b[1m 4571/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 21ms/step - accuracy: 0.8189 - loss: 0.1260Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 13ms/step - accuracy: 0.8137 - loss: 0.1318\n",
      "\u001b[1m 7088/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 21ms/step - accuracy: 0.8187 - loss: 0.1259Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 17ms/step - accuracy: 0.7992 - loss: 0.1415\n",
      "\u001b[1m 5747/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 19ms/step - accuracy: 0.8164 - loss: 0.1300Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 24ms/step - accuracy: 0.8210 - loss: 0.1240\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.1264\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.6599 - loss: 0.2217\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 15ms/step - accuracy: 0.8204 - loss: 0.1244\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 18ms/step - accuracy: 0.8001 - loss: 0.1420\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 21ms/step - accuracy: 0.8192 - loss: 0.1254\n",
      "\u001b[1m 7206/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 19ms/step - accuracy: 0.8163 - loss: 0.1301Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8135 - loss: 0.1316\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 23ms/step - accuracy: 0.8198 - loss: 0.1248\n",
      "\u001b[1m 4176/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 15ms/step - accuracy: 0.8210 - loss: 0.1251Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 15ms/step - accuracy: 0.8230 - loss: 0.1231\n",
      "\u001b[1m 9042/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 20ms/step - accuracy: 0.8154 - loss: 0.1291Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 20ms/step - accuracy: 0.8198 - loss: 0.1254\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 22ms/step - accuracy: 0.8218 - loss: 0.1237\n",
      "\u001b[1m12698/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.8226 - loss: 0.1232Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.1365\n",
      "\u001b[1m 9703/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 21ms/step - accuracy: 0.8212 - loss: 0.1243Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 15ms/step - accuracy: 0.8238 - loss: 0.1226\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.8210 - loss: 0.1246\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.1256\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 16ms/step - accuracy: 0.8219 - loss: 0.1236\n",
      "\u001b[1m 1205/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:20\u001b[0m 19ms/step - accuracy: 0.8089 - loss: 0.1331Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 18ms/step - accuracy: 0.8275 - loss: 0.1204\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 22ms/step - accuracy: 0.8221 - loss: 0.1241\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8185 - loss: 0.1265\n",
      "\u001b[1m14002/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.8138 - loss: 0.1310Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8225 - loss: 0.1232\n",
      "\u001b[1m 1383/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 18ms/step - accuracy: 0.8247 - loss: 0.1214Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 23ms/step - accuracy: 0.8225 - loss: 0.1237\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 21ms/step - accuracy: 0.8212 - loss: 0.1238\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8138 - loss: 0.1310\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.8215 - loss: 0.1238\n",
      "\u001b[1m11839/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m49s\u001b[0m 17ms/step - accuracy: 0.7978 - loss: 0.1431Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 16ms/step - accuracy: 0.8006 - loss: 0.1412\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8196 - loss: 0.1256\n",
      "\u001b[1m 7232/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 0.1365Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 22ms/step - accuracy: 0.8196 - loss: 0.1248\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 16ms/step - accuracy: 0.8223 - loss: 0.1235\n",
      "\u001b[1m 7887/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 0.1365Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.1259\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 21ms/step - accuracy: 0.8211 - loss: 0.1242\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 16ms/step - accuracy: 0.8214 - loss: 0.1242\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.1315\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 16ms/step - accuracy: 0.8235 - loss: 0.1231\n",
      "\u001b[1m13331/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.1264Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 21ms/step - accuracy: 0.8185 - loss: 0.1257\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 23ms/step - accuracy: 0.8204 - loss: 0.1243\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 22ms/step - accuracy: 0.8250 - loss: 0.1218\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 19ms/step - accuracy: 0.8144 - loss: 0.1306\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 20ms/step - accuracy: 0.8184 - loss: 0.1262\n",
      "\u001b[1m 8812/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 14ms/step - accuracy: 0.6833 - loss: 0.2089Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 16ms/step - accuracy: 0.8230 - loss: 0.1236\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 20ms/step - accuracy: 0.8208 - loss: 0.1243\n",
      "\u001b[1m 7218/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 20ms/step - accuracy: 0.8256 - loss: 0.1211Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 21ms/step - accuracy: 0.8204 - loss: 0.1241\n",
      "\u001b[1m 6385/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 17ms/step - accuracy: 0.8239 - loss: 0.1225Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 22ms/step - accuracy: 0.8220 - loss: 0.1237\n",
      "\u001b[1m 8237/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 17ms/step - accuracy: 0.8259 - loss: 0.1215Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 19ms/step - accuracy: 0.8197 - loss: 0.1251\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.8202 - loss: 0.1249\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 19ms/step - accuracy: 0.8190 - loss: 0.1255\n",
      "\u001b[1m14052/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8228 - loss: 0.1230Epoch 19/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/stepstep - accuracy: 0.7990 - loss: 0.142\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 17ms/step - accuracy: 0.8218 - loss: 0.1234\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 19ms/step - accuracy: 0.8211 - loss: 0.1242\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 16ms/step - accuracy: 0.8245 - loss: 0.1221\n",
      "\u001b[1m12677/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.8233 - loss: 0.1227Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 20ms/step - accuracy: 0.8237 - loss: 0.1222\n",
      "\u001b[1m 2168/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 17ms/step - accuracy: 0.8212 - loss: 0.1238Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 15ms/step - accuracy: 0.8220 - loss: 0.1239\n",
      "\u001b[1m 7526/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 13ms/step - accuracy: 0.8007 - loss: 0.1409Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 18ms/step - accuracy: 0.8247 - loss: 0.1216\n",
      "\u001b[1m 2779/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 15ms/step - accuracy: 0.8202 - loss: 0.1254Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 16ms/step - accuracy: 0.8211 - loss: 0.1242\n",
      "\u001b[1m 4744/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 18ms/step - accuracy: 0.8238 - loss: 0.1229Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 18ms/step - accuracy: 0.8260 - loss: 0.1212\n",
      "\u001b[1m 4376/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 18ms/step - accuracy: 0.8216 - loss: 0.1237Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 18ms/step - accuracy: 0.8201 - loss: 0.1246\n",
      "\u001b[1m 4896/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 15ms/step - accuracy: 0.8249 - loss: 0.1223Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 18ms/step - accuracy: 0.8279 - loss: 0.1198\n",
      "Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/stepstep - accuracy: 0.8214 - loss: 0.126\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - accuracy: 0.8223 - loss: 0.1235\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 16ms/step - accuracy: 0.8251 - loss: 0.1218\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 16ms/step - accuracy: 0.8213 - loss: 0.1238\n",
      "\u001b[1m12799/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.8154 - loss: 0.1305Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 15ms/step - accuracy: 0.8232 - loss: 0.1229\n",
      "\u001b[1m 2266/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 12ms/step - accuracy: 0.8054 - loss: 0.1397Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 15ms/step - accuracy: 0.8185 - loss: 0.1260\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 15ms/step - accuracy: 0.8235 - loss: 0.1230\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/stepstep - accuracy: 0.8204 - loss: 0.124\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8230 - loss: 0.1232\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 15ms/step - accuracy: 0.8189 - loss: 0.1257\n",
      "\u001b[1m 8042/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 18ms/step - accuracy: 0.8214 - loss: 0.1237Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 0.1245\n",
      "\u001b[1m14231/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8235 - loss: 0.1229Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 15ms/step - accuracy: 0.8250 - loss: 0.1218\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 13ms/step - accuracy: 0.8154 - loss: 0.1305\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 17ms/step - accuracy: 0.8222 - loss: 0.1234\n",
      "\u001b[1m12331/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 14ms/step - accuracy: 0.8218 - loss: 0.1236Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 18ms/step - accuracy: 0.8235 - loss: 0.1229\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 15ms/step - accuracy: 0.8239 - loss: 0.1227\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/stepstep - accuracy: 0.8200 - loss: 0.129\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 15ms/step - accuracy: 0.8192 - loss: 0.1256\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 16ms/step - accuracy: 0.8218 - loss: 0.1237\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11ms/step - accuracy: 0.8142 - loss: 0.1302\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8245 - loss: 0.1217\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8231 - loss: 0.1231\n",
      "\u001b[1m 5786/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 14ms/step - accuracy: 0.8284 - loss: 0.1198Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8193 - loss: 0.1258\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8226 - loss: 0.1238\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8258 - loss: 0.1216\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/stepstep - accuracy: 0.8182 - loss: 0.129\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8194 - loss: 0.1257\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 14ms/step - accuracy: 0.8212 - loss: 0.1239\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 13ms/step - accuracy: 0.8193 - loss: 0.1253\n",
      "\u001b[1m 7606/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 15ms/step - accuracy: 0.8223 - loss: 0.1227Epoch 22/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/steptep - accuracy: 0.8247 - loss: 0.1225\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 15ms/step - accuracy: 0.8237 - loss: 0.1223\n",
      "\u001b[1m 6728/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 13ms/step - accuracy: 0.8203 - loss: 0.1253Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12ms/step - accuracy: 0.8224 - loss: 0.1234\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 12ms/step - accuracy: 0.8261 - loss: 0.1211\n",
      "\u001b[1m 8618/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 13ms/step - accuracy: 0.8240 - loss: 0.1214Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 12ms/step - accuracy: 0.8215 - loss: 0.1245\n",
      "\u001b[1m10449/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 14ms/step - accuracy: 0.8255 - loss: 0.1217Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 13ms/step - accuracy: 0.8258 - loss: 0.1213\n",
      "\u001b[1m 2183/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 13ms/step - accuracy: 0.8249 - loss: 0.1224Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 13ms/step - accuracy: 0.8240 - loss: 0.1225\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 13ms/step - accuracy: 0.8231 - loss: 0.1226\n",
      "\u001b[1m 5001/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 14ms/step - accuracy: 0.8219 - loss: 0.1237Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 13ms/step - accuracy: 0.8235 - loss: 0.1226\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10ms/step - accuracy: 0.8184 - loss: 0.1275\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.8148 - loss: 0.1300\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8254 - loss: 0.1218\n",
      "\u001b[1m13815/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8165 - loss: 0.1292Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 12ms/step - accuracy: 0.8226 - loss: 0.1230\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 13ms/step - accuracy: 0.8245 - loss: 0.1221\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 12ms/step - accuracy: 0.8253 - loss: 0.1214\n",
      "\u001b[1m 3921/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 12ms/step - accuracy: 0.8276 - loss: 0.1204Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 11ms/step - accuracy: 0.8217 - loss: 0.1243\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12ms/step - accuracy: 0.8212 - loss: 0.1243\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 12ms/step - accuracy: 0.8254 - loss: 0.1218\n",
      "\u001b[1m10311/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.1221Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8253 - loss: 0.1216\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 12ms/step - accuracy: 0.8231 - loss: 0.1230\n",
      "\u001b[1m 3632/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 11ms/step - accuracy: 0.8232 - loss: 0.1231Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 11ms/step - accuracy: 0.8168 - loss: 0.1287\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/stepstep - accuracy: 0.8203 - loss: 0.12\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8235 - loss: 0.1222\n",
      "\u001b[1m 9014/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 13ms/step - accuracy: 0.8278 - loss: 0.1204Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8259 - loss: 0.1217\n",
      "\u001b[1m 6629/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 12ms/step - accuracy: 0.8213 - loss: 0.1246Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11ms/step - accuracy: 0.8203 - loss: 0.1252\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 13ms/step - accuracy: 0.8263 - loss: 0.1204\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 12ms/step - accuracy: 0.8229 - loss: 0.1232\n",
      "\u001b[1m11164/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 13ms/step - accuracy: 0.8277 - loss: 0.1205Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 11ms/step - accuracy: 0.8196 - loss: 0.1248\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8255 - loss: 0.1213\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 11ms/step - accuracy: 0.8198 - loss: 0.1256\n",
      "\u001b[1m 4955/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 12ms/step - accuracy: 0.8252 - loss: 0.1215Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8276 - loss: 0.1205\n",
      "\u001b[1m14137/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.1237Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.1237\n",
      "\u001b[1m12133/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 12ms/step - accuracy: 0.8216 - loss: 0.1243Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8298 - loss: 0.1190\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 11ms/step - accuracy: 0.8210 - loss: 0.1247\n",
      "\u001b[1m14159/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8199 - loss: 0.1251Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 0.1229\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8222 - loss: 0.1230\n",
      "\u001b[1m 2625/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 11ms/step - accuracy: 0.8197 - loss: 0.1247Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 11ms/step - accuracy: 0.8199 - loss: 0.1251\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 11ms/step - accuracy: 0.8217 - loss: 0.1246\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 12ms/step - accuracy: 0.8239 - loss: 0.1227\n",
      "Epoch 24/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/stepstep - accuracy: 0.8255 - loss: 0.123\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/stepstep - accuracy: 0.8271 - loss: 0.120\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepstep - accuracy: 0.8216 - loss: 0.121\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 12ms/step - accuracy: 0.8217 - loss: 0.1242\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 11ms/step - accuracy: 0.8199 - loss: 0.1255\n",
      "\u001b[1m 8793/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 12ms/step - accuracy: 0.8249 - loss: 0.1216Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12ms/step - accuracy: 0.8256 - loss: 0.1213\n",
      "\u001b[1m 2634/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 12ms/step - accuracy: 0.8243 - loss: 0.1232Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 12ms/step - accuracy: 0.8250 - loss: 0.1220\n",
      "\u001b[1m 3029/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 12ms/step - accuracy: 0.8241 - loss: 0.1232Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12ms/step - accuracy: 0.8244 - loss: 0.1222\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepstep - accuracy: 0.8262 - loss: 0.122\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 11ms/step - accuracy: 0.8250 - loss: 0.1220\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/steptep - accuracy: 0.8277 - loss: 0.1121\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 12ms/step - accuracy: 0.8266 - loss: 0.1211\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 10ms/step - accuracy: 0.8196 - loss: 0.1254\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 12ms/step - accuracy: 0.8270 - loss: 0.1203\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 12ms/step - accuracy: 0.8258 - loss: 0.1211\n",
      "\u001b[1m11027/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 11ms/step - accuracy: 0.8254 - loss: 0.1220Epoch 23/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/steptep - accuracy: 0.8221 - loss: 0.1220\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/stepep - accuracy: 0.8276 - loss: 0.12241\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 11ms/step - accuracy: 0.8275 - loss: 0.1200\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 0.1229\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 10ms/step - accuracy: 0.8197 - loss: 0.1250\n",
      "Epoch 24/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8229 - loss: 0.1220\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 11ms/step - accuracy: 0.8233 - loss: 0.1228\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 11ms/step - accuracy: 0.8251 - loss: 0.1221\n",
      "\u001b[1m 5967/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 10ms/step - accuracy: 0.8271 - loss: 0.1212Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 10ms/step - accuracy: 0.8215 - loss: 0.1242\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 10ms/step - accuracy: 0.8262 - loss: 0.1213\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 10ms/step - accuracy: 0.8220 - loss: 0.1242\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.8270 - loss: 0.1214\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/steptep - accuracy: 0.8237 - loss: 0.1223\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepcuracy: 0.8269 - loss: 0.12ss: 0.1233\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.8248 - loss: 0.1217\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepuracy: 0.8254 - loss: 0.11loss: 0.121\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 9ms/step - accuracy: 0.8205 - loss: 0.1248\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 10ms/step - accuracy: 0.8232 - loss: 0.1225\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepstep - accuracy: 0.8260 - loss: 0.120\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepstep - accuracy: 0.8226 - loss: 0.12\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - accuracy: 0.8240 - loss: 0.1225\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 9ms/step - accuracy: 0.8251 - loss: 0.1216\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 10ms/step - accuracy: 0.8266 - loss: 0.1214\n",
      "Epoch 24/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepep - accuracy: 0.8258 - loss: 0.1222\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9ms/step - accuracy: 0.8258 - loss: 0.1207\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 9ms/step - accuracy: 0.8275 - loss: 0.1202\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 9ms/step - accuracy: 0.8231 - loss: 0.1227\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 8ms/step - accuracy: 0.8240 - loss: 0.1223\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepp - accuracy: 0.8243 - loss: 0.12221\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 8ms/step - accuracy: 0.8269 - loss: 0.1203\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.8243 - loss: 0.1224\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 9ms/step - accuracy: 0.8263 - loss: 0.1215\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/steptep - accuracy: 0.8265 - loss: 0.121\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepep - accuracy: 0.8255 - loss: 0.1221\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 8ms/step - accuracy: 0.8254 - loss: 0.1214\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepep - accuracy: 0.8262 - loss: 0.1211\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8ms/step - accuracy: 0.8269 - loss: 0.1212\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8ms/step - accuracy: 0.8263 - loss: 0.1206\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 8ms/step - accuracy: 0.8279 - loss: 0.1200\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 8ms/step - accuracy: 0.8248 - loss: 0.1223\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/stepep - accuracy: 0.8254 - loss: 0.1221\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/steptep - accuracy: 0.8260 - loss: 0.12\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 8ms/step - accuracy: 0.8252 - loss: 0.1218\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepep - accuracy: 0.8264 - loss: 0.1220\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 7ms/step - accuracy: 0.8269 - loss: 0.1210\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/stepp - accuracy: 0.8270 - loss: 0.12\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 7ms/step - accuracy: 0.8270 - loss: 0.1207\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 6ms/step - accuracy: 0.7196 - loss: 0.1881\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.1465\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7ms/step - accuracy: 0.7986 - loss: 0.1420\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6ms/step - accuracy: 0.8033 - loss: 0.1376\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8055 - loss: 0.1364\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6ms/step - accuracy: 0.8089 - loss: 0.1339\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8104 - loss: 0.1327\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 6ms/step - accuracy: 0.8113 - loss: 0.1323\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.1322\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.1311\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.1311\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.1304\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.1298\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.1301\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6ms/step - accuracy: 0.8131 - loss: 0.1307\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.1300\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.1300\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.1294\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8166 - loss: 0.1289\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 7ms/step - accuracy: 0.8157 - loss: 0.1295\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.1292\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.1290\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.1285\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6ms/step - accuracy: 0.8150 - loss: 0.1295\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.1283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_rnn_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=neurons, input_shape=(34, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))  # Regression output\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create Keras classifier\n",
    "model = KerasClassifier(model=create_rnn_model, epochs = 25, batch_size = 32)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "neurons = [1, 5, 10, 20, 25, 30, 35, 40, 45, 50]\n",
    "param_grid = dict(model__neurons=neurons)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs = -1)\n",
    "grid_result = grid_search.fit(X_train_rnn, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a2cfeef-4f03-4a53-8336-7d6768592a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.819196 using {'model__neurons': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f465e1d6-f252-4339-8889-5f61c35651ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "2024-11-07 18:38:09.467937: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.467937: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.467937: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.469372: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.475088: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.484124: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.505341: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.564343: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.565385: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.568404: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.573316: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.574965: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.581961: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.591010: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.599617: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.599667: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.620416: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.620592: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.628003: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.629081: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.635695: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.635803: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.636093: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:09.636420: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.720783: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720777: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720780: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720773: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720777: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720786: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720773: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720777: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720839: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720845: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720968: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720964: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720964: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720969: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.720966: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.721186: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 18:38:09.721737: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721740: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721758: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721771: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721773: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721775: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721776: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721783: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721787: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721891: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721890: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721890: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721895: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.721894: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.722003: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.725804: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725815: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725805: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725804: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725804: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725814: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725818: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725805: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725816: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.725814: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726215: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.726935: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 18:38:09.737261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.737994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:09.739184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 18:38:09.756626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756627: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756627: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.756844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.757336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.757335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.757336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.757334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.757332: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.759013: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 18:38:09.761978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761983: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.761987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762123: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762701: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762703: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762703: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.762712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.764456: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 18:38:09.775731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775728: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775728: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775776: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.775777: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.776579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.776578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.776591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.776600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.776608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.778749: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 18:38:09.779276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "\u001b[1m    9/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 14ms/step - accuracy: 0.3617 - loss: 1.63318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 18:38:11.748777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.748978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.748975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.749004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.750165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.750747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.750767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.750770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.751786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.753979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.759004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.761350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.762040: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.796785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.797486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-07 18:38:11.836064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  359/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 12ms/step - accuracy: 0.5163 - loss: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 18:38:16.234563: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.234936: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.245294: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.249042: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.273694: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.278450: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.280068: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.292625: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.292930: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.296292: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.297672: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.299977: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:16.305674: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:16.320278: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-11-07 18:38:16.328772: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-07 18:38:16.348172: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  422/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 12ms/step - accuracy: 0.4558 - loss: 0.5985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  426/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 12ms/step - accuracy: 0.4563 - loss: 0.5966Epoch 1/25\n",
      "\u001b[1m  436/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 12ms/step - accuracy: 0.5313 - loss: 0.3571Epoch 1/25\n",
      "\u001b[1m  432/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 12ms/step - accuracy: 0.5322 - loss: 0.2823Epoch 1/25\n",
      "\u001b[1m  446/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 11ms/step - accuracy: 0.4882 - loss: 0.4299Epoch 1/25\n",
      "\u001b[1m  408/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 12ms/step - accuracy: 0.5308 - loss: 0.3981Epoch 1/25\n",
      "\u001b[1m  444/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 11ms/step - accuracy: 0.4184 - loss: 0.7305Epoch 1/25\n",
      "\u001b[1m  417/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 12ms/step - accuracy: 0.4486 - loss: 1.1017Epoch 1/25\n",
      "Epoch 1/25\n",
      "\u001b[1m  440/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 12ms/step - accuracy: 0.5316 - loss: 0.3565Epoch 1/25\n",
      "\u001b[1m  438/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 12ms/step - accuracy: 0.4844 - loss: 0.4210Epoch 1/25\n",
      "Epoch 1/25\n",
      "\u001b[1m  436/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 12ms/step - accuracy: 0.5324 - loss: 0.2821Epoch 1/25\n",
      "Epoch 1/25\n",
      "\u001b[1m  425/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 12ms/step - accuracy: 0.5253 - loss: 0.5864Epoch 1/25\n",
      "\u001b[1m  455/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 11ms/step - accuracy: 0.4388 - loss: 1.3006Epoch 1/25\n",
      "\u001b[1m  419/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 12ms/step - accuracy: 0.4921 - loss: 0.9034Epoch 1/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.6591 - loss: 0.2360\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.6968 - loss: 0.1990\n",
      "\u001b[1m12742/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.7058 - loss: 0.2038Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7107 - loss: 0.1910\n",
      "\u001b[1m13218/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6762 - loss: 0.2115Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.6896 - loss: 0.2079\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.6746 - loss: 0.2529\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.6585 - loss: 0.2219\n",
      "\u001b[1m13300/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.6763 - loss: 0.2114Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.6900 - loss: 0.2097\n",
      "\u001b[1m13254/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7121 - loss: 0.1985Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.6564 - loss: 0.2268\n",
      "\u001b[1m13283/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7162 - loss: 0.1857Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.6734 - loss: 0.2557\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.6234 - loss: 0.2500\n",
      "\u001b[1m13368/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.7049 - loss: 0.1936Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.6798 - loss: 0.2123\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.6768 - loss: 0.2118\n",
      "\u001b[1m  324/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 13ms/step - accuracy: 0.7900 - loss: 0.1482Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7096 - loss: 0.2029\n",
      "\u001b[1m14370/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6877 - loss: 0.2202Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7055 - loss: 0.2061\n",
      "\u001b[1m  724/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.7797 - loss: 0.1537Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.6936 - loss: 0.1992\n",
      "\u001b[1m  645/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 13ms/step - accuracy: 0.7788 - loss: 0.1563Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.6651 - loss: 0.2293\n",
      "\u001b[1m14455/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6601 - loss: 0.2732Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7089 - loss: 0.2037\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.6766 - loss: 0.2188\n",
      "\u001b[1m  751/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 13ms/step - accuracy: 0.7736 - loss: 0.1603Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.6396 - loss: 0.2930\n",
      "\u001b[1m  326/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 13ms/step - accuracy: 0.7777 - loss: 0.1586Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.6237 - loss: 0.2444\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.6611 - loss: 0.2719\n",
      "\u001b[1m14640/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6517 - loss: 0.2400Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.6253 - loss: 0.2487\n",
      "\u001b[1m 1104/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 13ms/step - accuracy: 0.7810 - loss: 0.1525Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.6890 - loss: 0.2192\n",
      "\u001b[1m  473/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 13ms/step - accuracy: 0.7786 - loss: 0.1585Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.6524 - loss: 0.2289\n",
      "\u001b[1m14223/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7221 - loss: 0.1945Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.6519 - loss: 0.2398\n",
      "\u001b[1m  200/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 13ms/step - accuracy: 0.7620 - loss: 0.1641Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.6792 - loss: 0.2771\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 14ms/step - accuracy: 0.6762 - loss: 0.2476\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.7253 - loss: 0.1914\n",
      "\u001b[1m  689/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 13ms/step - accuracy: 0.7808 - loss: 0.1562Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 14ms/step - accuracy: 0.6184 - loss: 0.2974\n",
      "\u001b[1m  315/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 13ms/step - accuracy: 0.7540 - loss: 0.1706Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 15ms/step - accuracy: 0.6545 - loss: 0.2485\n",
      "\u001b[1m 1550/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 13ms/step - accuracy: 0.7906 - loss: 0.1486Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.7083 - loss: 0.2085\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.7272 - loss: 0.1810\n",
      "\u001b[1m14649/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7206 - loss: 0.1834Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.6591 - loss: 0.2354\n",
      "\u001b[1m  488/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 13ms/step - accuracy: 0.7558 - loss: 0.1718 0.191Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.7236 - loss: 0.1933\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.6786 - loss: 0.2099\n",
      "\u001b[1m    6/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 10ms/step - accuracy: 0.8128 - loss: 0.1329 Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7095 - loss: 0.1910\n",
      "\u001b[1m 1529/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 13ms/step - accuracy: 0.7855 - loss: 0.1534Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7208 - loss: 0.1833\n",
      "\u001b[1m 1644/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 13ms/step - accuracy: 0.7819 - loss: 0.1522Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7174 - loss: 0.1947\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7365 - loss: 0.1770\n",
      "\u001b[1m  873/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 13ms/step - accuracy: 0.7805 - loss: 0.1558Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 14ms/step - accuracy: 0.7121 - loss: 0.1991\n",
      "Epoch 2/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 13ms/step - accuracy: 0.7874 - loss: 0.1502\n",
      "\u001b[1m12876/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.7803 - loss: 0.1540Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 13ms/step - accuracy: 0.7869 - loss: 0.1496\n",
      "\u001b[1m   43/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 13ms/step - accuracy: 0.7703 - loss: 0.1668Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7862 - loss: 0.1506\n",
      "\u001b[1m12977/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.7803 - loss: 0.1540Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7828 - loss: 0.1534\n",
      "\u001b[1m13475/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7905 - loss: 0.1476Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7860 - loss: 0.1513\n",
      "\u001b[1m14649/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7929 - loss: 0.1470Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7929 - loss: 0.1470\n",
      "\u001b[1m14705/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7911 - loss: 0.1471Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7911 - loss: 0.1471\n",
      "\u001b[1m   86/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 13ms/step - accuracy: 0.7940 - loss: 0.1421Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7785 - loss: 0.1573\n",
      "\u001b[1m12894/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.7827 - loss: 0.1503Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7840 - loss: 0.1530\n",
      "\u001b[1m13617/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2248Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.7873 - loss: 0.1509\n",
      "\u001b[1m 8890/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 14ms/step - accuracy: 0.7778 - loss: 0.1548Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.7787 - loss: 0.1553\n",
      "\u001b[1m 9022/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 14ms/step - accuracy: 0.7550 - loss: 0.1684Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7500 - loss: 0.1709\n",
      "\u001b[1m13624/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.7632 - loss: 0.1673Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7785 - loss: 0.1535\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.1519\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8018 - loss: 0.1381\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7995 - loss: 0.1421\n",
      "\u001b[1m 9635/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 14ms/step - accuracy: 0.7551 - loss: 0.1683Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7908 - loss: 0.1473\n",
      "\u001b[1m 9269/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.1401Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2248\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7710 - loss: 0.1609\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7605 - loss: 0.1676\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7635 - loss: 0.1672\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7775 - loss: 0.1553\n",
      "\u001b[1m14336/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7557 - loss: 0.1651Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7805 - loss: 0.1538\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7933 - loss: 0.1455\n",
      "\u001b[1m14680/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.1355Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.1355\n",
      "\u001b[1m  369/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 13ms/step - accuracy: 0.7669 - loss: 0.1638Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8018 - loss: 0.1356\n",
      "\u001b[1m14570/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7559 - loss: 0.1650Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7831 - loss: 0.1501\n",
      "\u001b[1m 2228/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 12ms/step - accuracy: 0.7932 - loss: 0.1463Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7560 - loss: 0.1649\n",
      "\u001b[1m10118/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.1373Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7959 - loss: 0.1406\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6594 - loss: 0.2246\n",
      "\u001b[1m  134/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 13ms/step - accuracy: 0.7739 - loss: 0.1596Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7990 - loss: 0.1395\n",
      "\u001b[1m  242/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07\u001b[0m 13ms/step - accuracy: 0.7955 - loss: 0.1445Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7717 - loss: 0.1609\n",
      "\u001b[1m  439/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 13ms/step - accuracy: 0.8135 - loss: 0.1297Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.7565 - loss: 0.1673\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.6656 - loss: 0.2187\n",
      "\u001b[1m 5255/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 13ms/step - accuracy: 0.7979 - loss: 0.1423Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.7641 - loss: 0.1660\n",
      "Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.7789 - loss: 0.1545\n",
      "\u001b[1m 3809/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.1412Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8006 - loss: 0.1395\n",
      "\u001b[1m 4278/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 14ms/step - accuracy: 0.6601 - loss: 0.2244Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 0.1370\n",
      "\u001b[1m 4194/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 14ms/step - accuracy: 0.7787 - loss: 0.1551Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8005 - loss: 0.1378\n",
      "\u001b[1m 4424/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 14ms/step - accuracy: 0.6601 - loss: 0.2244Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 14ms/step - accuracy: 0.7848 - loss: 0.1486\n",
      "\u001b[1m 4302/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 14ms/step - accuracy: 0.8092 - loss: 0.1309Epoch 3/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7934 - loss: 0.1461\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.7965 - loss: 0.1442\n",
      "\u001b[1m12708/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.7899 - loss: 0.1469Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.7927 - loss: 0.1469\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.7933 - loss: 0.1463\n",
      "\u001b[1m11908/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 0.1408Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7880 - loss: 0.1524\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.1308\n",
      "\u001b[1m12729/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 0.2245Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.7974 - loss: 0.1431\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.7973 - loss: 0.1429\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7994 - loss: 0.1415\n",
      "\u001b[1m13485/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.7886 - loss: 0.1484Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8043 - loss: 0.1389\n",
      "\u001b[1m14417/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7958 - loss: 0.1449Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8023 - loss: 0.1392\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7938 - loss: 0.1453\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7958 - loss: 0.1448\n",
      "\u001b[1m  131/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 13ms/step - accuracy: 0.8011 - loss: 0.1369Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7872 - loss: 0.1513\n",
      "\u001b[1m 9614/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 13ms/step - accuracy: 0.6900 - loss: 0.2017Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7900 - loss: 0.1468\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.7874 - loss: 0.1508\n",
      "\u001b[1m13527/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.1319Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.7998 - loss: 0.1407\n",
      "\u001b[1m 1020/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 0.1285Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 0.1561\n",
      "\u001b[1m14237/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7929 - loss: 0.1439Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7661 - loss: 0.1624\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.1481\n",
      "\u001b[1m 2473/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 13ms/step - accuracy: 0.7954 - loss: 0.1456Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8063 - loss: 0.1323\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.6596 - loss: 0.2246\n",
      "\u001b[1m 5368/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 14ms/step - accuracy: 0.7953 - loss: 0.1423Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7887 - loss: 0.1483\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7929 - loss: 0.1439\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 0.1458\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.7728 - loss: 0.1616\n",
      "\u001b[1m 2006/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 13ms/step - accuracy: 0.8172 - loss: 0.1285Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8016 - loss: 0.1362\n",
      "\u001b[1m10762/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 13ms/step - accuracy: 0.6919 - loss: 0.2009Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 0.2245\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.1319\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8011 - loss: 0.1406\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8082 - loss: 0.1331\n",
      "\u001b[1m 1827/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1412Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.7832 - loss: 0.1530\n",
      "\u001b[1m 2700/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 0.1419Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7747 - loss: 0.1608\n",
      "\u001b[1m 9449/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 14ms/step - accuracy: 0.8044 - loss: 0.1335Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.6984 - loss: 0.1979\n",
      "\u001b[1m 3228/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 14ms/step - accuracy: 0.7938 - loss: 0.1473Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7877 - loss: 0.1505\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.7700 - loss: 0.1592\n",
      "\u001b[1m 8289/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:30\u001b[0m 14ms/step - accuracy: 0.8041 - loss: 0.1345Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8079 - loss: 0.1346\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8083 - loss: 0.1316\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8046 - loss: 0.1334\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.7975 - loss: 0.1408\n",
      "Epoch 4/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.7968 - loss: 0.1435\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7977 - loss: 0.1444\n",
      "\u001b[1m12961/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.1416Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8033 - loss: 0.1401\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8018 - loss: 0.1404\n",
      "\u001b[1m 3304/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.1315Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8157 - loss: 0.1288\n",
      "\u001b[1m14628/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8006 - loss: 0.1419Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8006 - loss: 0.1419\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8000 - loss: 0.1410\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7971 - loss: 0.1426\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7903 - loss: 0.1513\n",
      "\u001b[1m12415/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - accuracy: 0.8042 - loss: 0.1387Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8051 - loss: 0.1375\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8057 - loss: 0.1368\n",
      "\u001b[1m13449/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2247Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.1416\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8026 - loss: 0.1381\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7961 - loss: 0.1425\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 0.1455\n",
      "\u001b[1m13262/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.7747 - loss: 0.1606Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8104 - loss: 0.1346\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 0.1476\n",
      "\u001b[1m14501/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7926 - loss: 0.1456Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7926 - loss: 0.1455\n",
      "\u001b[1m14073/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.7928 - loss: 0.1452Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7809 - loss: 0.1541\n",
      "\u001b[1m14476/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2247Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7717 - loss: 0.1591\n",
      "\u001b[1m  211/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.1527Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2247\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1289\n",
      "\u001b[1m 3014/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 12ms/step - accuracy: 0.7991 - loss: 0.1439Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7974 - loss: 0.1407\n",
      "\u001b[1m  394/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 14ms/step - accuracy: 0.7830 - loss: 0.1516Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7928 - loss: 0.1452\n",
      "\u001b[1m 1697/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 13ms/step - accuracy: 0.8029 - loss: 0.1403Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7970 - loss: 0.1420\n",
      "\u001b[1m   44/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 13ms/step - accuracy: 0.8100 - loss: 0.1381Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8040 - loss: 0.1345\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7747 - loss: 0.1605\n",
      "\u001b[1m 2261/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 13ms/step - accuracy: 0.8086 - loss: 0.1346Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6595 - loss: 0.2246\n",
      "\u001b[1m 1462/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 14ms/step - accuracy: 0.8105 - loss: 0.1292Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8043 - loss: 0.1386\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.1318\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8102 - loss: 0.1315\n",
      "\u001b[1m 2642/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 13ms/step - accuracy: 0.8086 - loss: 0.1348Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.7942 - loss: 0.1469\n",
      "\u001b[1m 1076/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 14ms/step - accuracy: 0.7955 - loss: 0.1409Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7795 - loss: 0.1574\n",
      "\u001b[1m 5505/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 13ms/step - accuracy: 0.7997 - loss: 0.1417Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.7538 - loss: 0.1690\n",
      "\u001b[1m 5828/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 13ms/step - accuracy: 0.8003 - loss: 0.1406Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.7916 - loss: 0.1461\n",
      "\u001b[1m10070/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 14ms/step - accuracy: 0.8107 - loss: 0.1297Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8073 - loss: 0.1315\n",
      "\u001b[1m11254/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 13ms/step - accuracy: 0.8033 - loss: 0.1387Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7974 - loss: 0.1428\n",
      "\u001b[1m12475/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.8004 - loss: 0.1416Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 0.1428\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8180 - loss: 0.1275\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.7994 - loss: 0.1415\n",
      "\u001b[1m12963/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8107 - loss: 0.1298Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.1390\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8085 - loss: 0.1353\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7931 - loss: 0.1492\n",
      "\u001b[1m13890/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7720 - loss: 0.1583Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8043 - loss: 0.1386\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8034 - loss: 0.1386\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8007 - loss: 0.1416\n",
      "\u001b[1m13926/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8030 - loss: 0.1415Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1352\n",
      "\u001b[1m12109/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m36s\u001b[0m 14ms/step - accuracy: 0.7773 - loss: 0.1580Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 0.1398\n",
      "\u001b[1m13816/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.7971 - loss: 0.1427Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8140 - loss: 0.1325\n",
      "\u001b[1m13862/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.1366Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.7721 - loss: 0.1583\n",
      "\u001b[1m  854/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.7915 - loss: 0.1505Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8030 - loss: 0.1414\n",
      "\u001b[1m12790/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.8109 - loss: 0.1297Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.8060 - loss: 0.1365\n",
      "\u001b[1m12481/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.1301Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7985 - loss: 0.1449\n",
      "\u001b[1m  756/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 13ms/step - accuracy: 0.8053 - loss: 0.1357Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.1324\n",
      "\u001b[1m13191/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8004 - loss: 0.1381Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7950 - loss: 0.1444\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7972 - loss: 0.1426\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8107 - loss: 0.1298\n",
      "\u001b[1m  547/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 13ms/step - accuracy: 0.8074 - loss: 0.1364Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.1365\n",
      "Epoch 5/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7835 - loss: 0.1524\n",
      "\u001b[1m  311/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 13ms/step - accuracy: 0.8031 - loss: 0.1381Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8127 - loss: 0.1281\n",
      "\u001b[1m 1389/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 13ms/step - accuracy: 0.8083 - loss: 0.1355Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.7770 - loss: 0.1561\n",
      "\u001b[1m 1188/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.8066 - loss: 0.1333Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.6594 - loss: 0.2246\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8004 - loss: 0.1381\n",
      "\u001b[1m 4246/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 13ms/step - accuracy: 0.8039 - loss: 0.1408Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.7965 - loss: 0.1434\n",
      "\u001b[1m14494/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8055 - loss: 0.1373Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.7999 - loss: 0.1391\n",
      "\u001b[1m 1640/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 13ms/step - accuracy: 0.8122 - loss: 0.1322Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8056 - loss: 0.1330\n",
      "\u001b[1m 2288/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 13ms/step - accuracy: 0.8115 - loss: 0.1328Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.6582 - loss: 0.2249\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8056 - loss: 0.1373\n",
      "\u001b[1m 2119/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 13ms/step - accuracy: 0.8087 - loss: 0.1352Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8110 - loss: 0.1297\n",
      "\u001b[1m14633/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7773 - loss: 0.1580Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.7773 - loss: 0.1580\n",
      "\u001b[1m 4167/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 13ms/step - accuracy: 0.7986 - loss: 0.1424Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8124 - loss: 0.1301\n",
      "\u001b[1m 6262/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 13ms/step - accuracy: 0.8113 - loss: 0.1290Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.1554\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7645 - loss: 0.1626\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 13ms/step - accuracy: 0.7962 - loss: 0.1459\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8112 - loss: 0.1292\n",
      "\u001b[1m 4205/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 14ms/step - accuracy: 0.7963 - loss: 0.1432Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.1412\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7999 - loss: 0.1414\n",
      "\u001b[1m11848/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.8107 - loss: 0.1300Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 0.1279\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 0.1343\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 13ms/step - accuracy: 0.8087 - loss: 0.1365\n",
      "\u001b[1m 7626/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 14ms/step - accuracy: 0.7833 - loss: 0.1543Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7939 - loss: 0.1487\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.1368\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8015 - loss: 0.1397\n",
      "\u001b[1m11143/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.1298Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8061 - loss: 0.1377\n",
      "\u001b[1m13183/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.8016 - loss: 0.1399Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8040 - loss: 0.1370\n",
      "\u001b[1m 7019/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 14ms/step - accuracy: 0.7773 - loss: 0.1577Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8142 - loss: 0.1321\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8034 - loss: 0.1404\n",
      "\u001b[1m 9686/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 14ms/step - accuracy: 0.7804 - loss: 0.1545Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8095 - loss: 0.1346\n",
      "\u001b[1m 1506/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 13ms/step - accuracy: 0.8179 - loss: 0.1266Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8077 - loss: 0.1346\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8001 - loss: 0.1435\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.7955 - loss: 0.1442\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8128 - loss: 0.1317\n",
      "\u001b[1m 7884/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 14ms/step - accuracy: 0.6583 - loss: 0.2250Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.1428\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8111 - loss: 0.1298\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8016 - loss: 0.1399\n",
      "\u001b[1m 8510/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 14ms/step - accuracy: 0.8027 - loss: 0.1359Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1405\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8054 - loss: 0.1353\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7888 - loss: 0.1493\n",
      "\u001b[1m 9584/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 14ms/step - accuracy: 0.7769 - loss: 0.1556Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8146 - loss: 0.1270\n",
      "\u001b[1m 1407/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 13ms/step - accuracy: 0.8094 - loss: 0.1353Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8075 - loss: 0.1368\n",
      "\u001b[1m 2393/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1338Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8119 - loss: 0.1284\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8047 - loss: 0.1365\n",
      "\u001b[1m 9748/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 14ms/step - accuracy: 0.6585 - loss: 0.2249Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8128 - loss: 0.1297\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.7803 - loss: 0.1544\n",
      "Epoch 6/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.7689 - loss: 0.1600\n",
      "\u001b[1m13621/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.7782 - loss: 0.1572Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 14ms/step - accuracy: 0.7842 - loss: 0.1541\n",
      "\u001b[1m 3224/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1283Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.7777 - loss: 0.1553\n",
      "\u001b[1m 6856/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 13ms/step - accuracy: 0.8115 - loss: 0.1336Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.6606 - loss: 0.2242\n",
      "\u001b[1m 4067/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 14ms/step - accuracy: 0.8041 - loss: 0.1369Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.7969 - loss: 0.1430\n",
      "\u001b[1m 7967/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 13ms/step - accuracy: 0.8088 - loss: 0.1360Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.7783 - loss: 0.1572\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 14ms/step - accuracy: 0.8030 - loss: 0.1358\n",
      "\u001b[1m 7456/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 13ms/step - accuracy: 0.8122 - loss: 0.1336Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.6587 - loss: 0.2248\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.1317\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.1440\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8116 - loss: 0.1289\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.1403\n",
      "\u001b[1m13323/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8011 - loss: 0.1404Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8177 - loss: 0.1270\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.1403\n",
      "\u001b[1m14612/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8085 - loss: 0.1371Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8085 - loss: 0.1371\n",
      "\u001b[1m   85/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 14ms/step - accuracy: 0.8048 - loss: 0.1429Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.7936 - loss: 0.1488\n",
      "\u001b[1m14235/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8063 - loss: 0.1355Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1357\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8063 - loss: 0.1355\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8059 - loss: 0.1387\n",
      "\u001b[1m 2843/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 14ms/step - accuracy: 0.6608 - loss: 0.2242Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8122 - loss: 0.1336\n",
      "\u001b[1m 7108/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.1345Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 0.1358\n",
      "\u001b[1m 3247/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 14ms/step - accuracy: 0.8060 - loss: 0.1321Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8114 - loss: 0.1335\n",
      "\u001b[1m 1371/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 13ms/step - accuracy: 0.8019 - loss: 0.1402Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8094 - loss: 0.1339\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8037 - loss: 0.1387\n",
      "\u001b[1m 3806/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 14ms/step - accuracy: 0.7870 - loss: 0.1524Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.7953 - loss: 0.1438\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8152 - loss: 0.1312\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8145 - loss: 0.1272\n",
      "\u001b[1m13265/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.7908 - loss: 0.1482Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8030 - loss: 0.1421\n",
      "\u001b[1m  677/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.8103 - loss: 0.1333Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.1418\n",
      "\u001b[1m 1183/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 12ms/step - accuracy: 0.8109 - loss: 0.1329Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 13ms/step - accuracy: 0.8124 - loss: 0.1318\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8067 - loss: 0.1394\n",
      "\u001b[1m 9836/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 13ms/step - accuracy: 0.7712 - loss: 0.1589Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8031 - loss: 0.1392\n",
      "\u001b[1m10040/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 13ms/step - accuracy: 0.7712 - loss: 0.1588Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8143 - loss: 0.1269\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.1341\n",
      "\u001b[1m 1048/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.1439Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8159 - loss: 0.1263\n",
      "\u001b[1m 1052/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 14ms/step - accuracy: 0.8029 - loss: 0.1393Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.7907 - loss: 0.1481\n",
      "\u001b[1m 1946/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 13ms/step - accuracy: 0.8063 - loss: 0.1365Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1356\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8055 - loss: 0.1357\n",
      "\u001b[1m 3277/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 13ms/step - accuracy: 0.8084 - loss: 0.1338Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1289\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.1533\n",
      "Epoch 7/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7716 - loss: 0.1586\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7807 - loss: 0.1559\n",
      "\u001b[1m14452/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1343Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1343\n",
      "\u001b[1m 9080/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 0.1409Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1415\n",
      "\u001b[1m14494/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 0.2245Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 0.2245\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8089 - loss: 0.1307\n",
      "\u001b[1m 6463/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 14ms/step - accuracy: 0.8011 - loss: 0.1410Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.7867 - loss: 0.1516\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.7809 - loss: 0.1539\n",
      "\u001b[1m11213/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.1378Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8085 - loss: 0.1308\n",
      "\u001b[1m13213/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.7870 - loss: 0.1492Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.6598 - loss: 0.2245\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8061 - loss: 0.1390\n",
      "\u001b[1m14204/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1433Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8183 - loss: 0.1265\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.1433\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7818 - loss: 0.1522\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1351\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.1362\n",
      "\u001b[1m11668/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8074 - loss: 0.1334Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.7956 - loss: 0.1473\n",
      "\u001b[1m 6335/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 14ms/step - accuracy: 0.8005 - loss: 0.1420Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.1323\n",
      "\u001b[1m  964/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.6620 - loss: 0.2238Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.1337\n",
      "\u001b[1m 6720/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 14ms/step - accuracy: 0.6575 - loss: 0.2252Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8118 - loss: 0.1332\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8078 - loss: 0.1379\n",
      "\u001b[1m  405/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 12ms/step - accuracy: 0.8188 - loss: 0.1309Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8124 - loss: 0.1331\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8073 - loss: 0.1359\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8065 - loss: 0.1370\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.7984 - loss: 0.1432\n",
      "\u001b[1m 2090/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 13ms/step - accuracy: 0.6852 - loss: 0.2104Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 0.1309\n",
      "\u001b[1m13968/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1267Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1270\n",
      "\u001b[1m 4818/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 13ms/step - accuracy: 0.7887 - loss: 0.1493Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8062 - loss: 0.1391\n",
      "\u001b[1m 3228/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 13ms/step - accuracy: 0.8061 - loss: 0.1395Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.1413\n",
      "\u001b[1m 1002/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 13ms/step - accuracy: 0.8056 - loss: 0.1358Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.1419\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1379\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8160 - loss: 0.1300\n",
      "Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1267\n",
      "\u001b[1m 3057/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 13ms/step - accuracy: 0.7015 - loss: 0.2010Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8075 - loss: 0.1333\n",
      "\u001b[1m 1065/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 14ms/step - accuracy: 0.8169 - loss: 0.1281Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.1259\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8092 - loss: 0.1354\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.1290\n",
      "\u001b[1m  636/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26\u001b[0m 15ms/step - accuracy: 0.8052 - loss: 0.1405Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 0.1337\n",
      "\u001b[1m 1858/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 13ms/step - accuracy: 0.8154 - loss: 0.1308Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7816 - loss: 0.1533\n",
      "\u001b[1m12511/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.8078 - loss: 0.1329Epoch 8/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7766 - loss: 0.1548\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7793 - loss: 0.1556\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.1390\n",
      "\u001b[1m12659/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.8124 - loss: 0.1320Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8192 - loss: 0.1263\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7446 - loss: 0.1748\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8105 - loss: 0.1358\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 0.1340\n",
      "\u001b[1m10581/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 14ms/step - accuracy: 0.8099 - loss: 0.1325Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7952 - loss: 0.1467\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8098 - loss: 0.1331\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8122 - loss: 0.1328\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.8124 - loss: 0.1320\n",
      "\u001b[1m 6677/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1278Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8096 - loss: 0.1370\n",
      "\u001b[1m 7990/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 14ms/step - accuracy: 0.8075 - loss: 0.1327Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.1371\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8087 - loss: 0.1350\n",
      "\u001b[1m   91/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 0.1263Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.8146 - loss: 0.1323\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.7987 - loss: 0.1427\n",
      "\u001b[1m13321/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.8185 - loss: 0.1250Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8044 - loss: 0.1414\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8169 - loss: 0.1262\n",
      "\u001b[1m 4911/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 14ms/step - accuracy: 0.7881 - loss: 0.1498Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1280\n",
      "\u001b[1m  744/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 13ms/step - accuracy: 0.8028 - loss: 0.1384Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8165 - loss: 0.1311\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8154 - loss: 0.1303\n",
      "\u001b[1m 8201/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 14ms/step - accuracy: 0.6588 - loss: 0.2248Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.1411\n",
      "\u001b[1m 9845/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 14ms/step - accuracy: 0.7801 - loss: 0.1535Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8060 - loss: 0.1381\n",
      "\u001b[1m 8341/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 14ms/step - accuracy: 0.8010 - loss: 0.1404Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8073 - loss: 0.1388\n",
      "\u001b[1m 1677/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1351Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.1257\n",
      "\u001b[1m 9237/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 13ms/step - accuracy: 0.7827 - loss: 0.1543Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8184 - loss: 0.1250\n",
      "\u001b[1m 2325/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.1325Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 0.1348\n",
      "\u001b[1m 1891/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 14ms/step - accuracy: 0.7972 - loss: 0.1433Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 14ms/step - accuracy: 0.8017 - loss: 0.1426\n",
      "\u001b[1m14555/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.1286Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.1286\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8100 - loss: 0.1324\n",
      "\u001b[1m 6592/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 14ms/step - accuracy: 0.7809 - loss: 0.1539Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7859 - loss: 0.1519\n",
      "Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7805 - loss: 0.1532\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8081 - loss: 0.1325\n",
      "\u001b[1m 5419/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 13ms/step - accuracy: 0.8149 - loss: 0.1277Epoch 9/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7829 - loss: 0.1543\n",
      "\u001b[1m 1516/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 14ms/step - accuracy: 0.7852 - loss: 0.1533Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8096 - loss: 0.1320\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.6591 - loss: 0.2247\n",
      "\u001b[1m 1941/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 14ms/step - accuracy: 0.8008 - loss: 0.1408Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8011 - loss: 0.1404\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8129 - loss: 0.1282\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7999 - loss: 0.1421\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.1256\n",
      "\u001b[1m  536/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.1335Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8157 - loss: 0.1301\n",
      "\u001b[1m14242/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8089 - loss: 0.1363Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1274\n",
      "\u001b[1m12482/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.8117 - loss: 0.1313Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8045 - loss: 0.1415\n",
      "\u001b[1m14277/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8076 - loss: 0.1384Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8172 - loss: 0.1307\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8089 - loss: 0.1363\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.1259\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8076 - loss: 0.1384\n",
      "\u001b[1m 4524/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 14ms/step - accuracy: 0.7909 - loss: 0.1473Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8183 - loss: 0.1245\n",
      "\u001b[1m 5382/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 14ms/step - accuracy: 0.7838 - loss: 0.1530Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8115 - loss: 0.1342\n",
      "\u001b[1m 6810/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 13ms/step - accuracy: 0.7907 - loss: 0.1485Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1288\n",
      "\u001b[1m 2098/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 13ms/step - accuracy: 0.8031 - loss: 0.1421Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8117 - loss: 0.1313\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8028 - loss: 0.1419\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7848 - loss: 0.1524\n",
      "\u001b[1m 5757/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 13ms/step - accuracy: 0.8087 - loss: 0.1371Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 14ms/step - accuracy: 0.8019 - loss: 0.1405\n",
      "\u001b[1m 9443/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 14ms/step - accuracy: 0.6576 - loss: 0.2252Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7821 - loss: 0.1514\n",
      "\u001b[1m 3901/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 14ms/step - accuracy: 0.8228 - loss: 0.1233Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8095 - loss: 0.1318\n",
      "Epoch 10/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7836 - loss: 0.1538\n",
      "\u001b[1m 5843/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.1341Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 0.1310\n",
      "\u001b[1m 8699/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 13ms/step - accuracy: 0.8118 - loss: 0.1353Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.6589 - loss: 0.2247\n",
      "\u001b[1m 4978/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.1341Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8017 - loss: 0.1403\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8118 - loss: 0.1283\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7904 - loss: 0.1484\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.6581 - loss: 0.2250\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7836 - loss: 0.1529\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7923 - loss: 0.1467\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8192 - loss: 0.1263\n",
      "\u001b[1m11721/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.8003 - loss: 0.1420Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8076 - loss: 0.1377\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8045 - loss: 0.1392\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8119 - loss: 0.1353\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8128 - loss: 0.1336\n",
      "\u001b[1m 2957/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 13ms/step - accuracy: 0.7904 - loss: 0.1476Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8104 - loss: 0.1324\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8092 - loss: 0.1357\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1369\n",
      "\u001b[1m 9928/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1323Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8134 - loss: 0.1314\n",
      "\u001b[1m13509/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.8157 - loss: 0.1297Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1343\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8135 - loss: 0.1323\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8004 - loss: 0.1419\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.1419\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.1249\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8157 - loss: 0.1296\n",
      "\u001b[1m 4501/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 13ms/step - accuracy: 0.7841 - loss: 0.1524Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1276\n",
      "\u001b[1m14603/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.1347Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 0.1300\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.1347\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8077 - loss: 0.1383\n",
      "\u001b[1m10082/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.1397Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8177 - loss: 0.1251\n",
      "\u001b[1m  675/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 14ms/step - accuracy: 0.8210 - loss: 0.1223Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.1241\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8121 - loss: 0.1339\n",
      "\u001b[1m13077/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1322Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1286\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1302\n",
      "\u001b[1m10589/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 13ms/step - accuracy: 0.8121 - loss: 0.1299Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 13ms/step - accuracy: 0.7977 - loss: 0.1453\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1322\n",
      "\u001b[1m  975/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1299Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7867 - loss: 0.1519\n",
      "\u001b[1m 6820/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 13ms/step - accuracy: 0.8112 - loss: 0.1357Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8032 - loss: 0.1398\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7813 - loss: 0.1513\n",
      "\u001b[1m12892/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - accuracy: 0.8030 - loss: 0.1412Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8111 - loss: 0.1312\n",
      "Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7849 - loss: 0.1533\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.1300\n",
      "\u001b[1m11554/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.7899 - loss: 0.1480Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8034 - loss: 0.1393\n",
      "\u001b[1m 6136/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 14ms/step - accuracy: 0.7937 - loss: 0.1460Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.1274\n",
      "\u001b[1m 6887/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1277Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.8029 - loss: 0.1413\n",
      "\u001b[1m11387/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 14ms/step - accuracy: 0.6587 - loss: 0.2249Epoch 11/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 0.1480\n",
      "\u001b[1m 9877/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 14ms/step - accuracy: 0.8152 - loss: 0.1320Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7824 - loss: 0.1527\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.6588 - loss: 0.2248\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.6598 - loss: 0.2245\n",
      "\u001b[1m11163/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m48s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1275Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8192 - loss: 0.1260\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8084 - loss: 0.1368\n",
      "\u001b[1m 5889/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 14ms/step - accuracy: 0.7828 - loss: 0.1539Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8115 - loss: 0.1354\n",
      "\u001b[1m 7158/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 14ms/step - accuracy: 0.7837 - loss: 0.1509Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8098 - loss: 0.1353\n",
      "\u001b[1m 7722/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 14ms/step - accuracy: 0.7870 - loss: 0.1516Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8048 - loss: 0.1388\n",
      "\u001b[1m 6493/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 14ms/step - accuracy: 0.8108 - loss: 0.1309Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1332\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8099 - loss: 0.1369\n",
      "\u001b[1m 7977/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 14ms/step - accuracy: 0.7837 - loss: 0.1509Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8116 - loss: 0.1318\n",
      "\u001b[1m12654/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.8169 - loss: 0.1306Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8126 - loss: 0.1314\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.1347\n",
      "\u001b[1m14207/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.1244Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.1412\n",
      "\u001b[1m11895/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1278Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8005 - loss: 0.1416\n",
      "\u001b[1m 9157/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 14ms/step - accuracy: 0.7836 - loss: 0.1508Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1321\n",
      "\u001b[1m 3187/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 14ms/step - accuracy: 0.6578 - loss: 0.2251Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8164 - loss: 0.1296\n",
      "\u001b[1m12687/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1332Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.1244\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1274\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8095 - loss: 0.1375\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 0.1254\n",
      "\u001b[1m 1181/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1309Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 14ms/step - accuracy: 0.8170 - loss: 0.1305\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 14ms/step - accuracy: 0.8113 - loss: 0.1338\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 14ms/step - accuracy: 0.7935 - loss: 0.1462\n",
      "\u001b[1m 8651/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.1278Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8175 - loss: 0.1250\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.1332\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7983 - loss: 0.1453\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1300\n",
      "\u001b[1m14683/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1278Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1278\n",
      "\u001b[1m 6777/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 14ms/step - accuracy: 0.7839 - loss: 0.1518Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1313\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7874 - loss: 0.1514\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7834 - loss: 0.1508\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8024 - loss: 0.1401\n",
      "\u001b[1m13957/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 0.1307Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 0.1307\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.7827 - loss: 0.1538\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.1303\n",
      "\u001b[1m 6539/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 14ms/step - accuracy: 0.8182 - loss: 0.1241Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8017 - loss: 0.1401\n",
      "\u001b[1m 2359/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 14ms/step - accuracy: 0.7895 - loss: 0.1505Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8135 - loss: 0.1275\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8021 - loss: 0.1422\n",
      "Epoch 12/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7900 - loss: 0.1480\n",
      "Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7832 - loss: 0.1519\n",
      "\u001b[1m 9259/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.1445Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.6591 - loss: 0.2247\n",
      "\u001b[1m13633/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1367Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8192 - loss: 0.1264\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.6591 - loss: 0.2247\n",
      "\u001b[1m11884/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.8039 - loss: 0.1412Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1367\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 0.1348\n",
      "\u001b[1m10275/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 13ms/step - accuracy: 0.8183 - loss: 0.1245Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8126 - loss: 0.1347\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8040 - loss: 0.1386\n",
      "\u001b[1m  836/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 14ms/step - accuracy: 0.8017 - loss: 0.1406Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8129 - loss: 0.1330\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8111 - loss: 0.1362\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8126 - loss: 0.1315\n",
      "\u001b[1m 9615/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.1316Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8112 - loss: 0.1342\n",
      "\u001b[1m 1461/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 13ms/step - accuracy: 0.8019 - loss: 0.1381Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.1312\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8041 - loss: 0.1412\n",
      "\u001b[1m12116/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - accuracy: 0.8134 - loss: 0.1327Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8020 - loss: 0.1403\n",
      "\u001b[1m 3543/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 14ms/step - accuracy: 0.6576 - loss: 0.2252Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8161 - loss: 0.1293\n",
      "\u001b[1m 1920/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 13ms/step - accuracy: 0.8083 - loss: 0.1362Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.1241\n",
      "\u001b[1m  306/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 13ms/step - accuracy: 0.8136 - loss: 0.1303Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.1267\n",
      "\u001b[1m 8617/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 13ms/step - accuracy: 0.7817 - loss: 0.1541Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8094 - loss: 0.1379\n",
      "\u001b[1m 3017/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 13ms/step - accuracy: 0.8121 - loss: 0.1347Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8170 - loss: 0.1256\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8118 - loss: 0.1340\n",
      "\u001b[1m12876/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1296Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7973 - loss: 0.1448\n",
      "\u001b[1m11075/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m49s\u001b[0m 14ms/step - accuracy: 0.7880 - loss: 0.1510Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 0.1244\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8132 - loss: 0.1328\n",
      "\u001b[1m11372/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 14ms/step - accuracy: 0.7847 - loss: 0.1505Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7984 - loss: 0.1448\n",
      "\u001b[1m 4771/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 13ms/step - accuracy: 0.8031 - loss: 0.1382Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1280\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.1296\n",
      "\u001b[1m11062/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m49s\u001b[0m 14ms/step - accuracy: 0.8136 - loss: 0.1295Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.1316\n",
      "\u001b[1m 7541/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 14ms/step - accuracy: 0.6583 - loss: 0.2250Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.1324\n",
      "\u001b[1m 6482/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.1353Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7879 - loss: 0.1510\n",
      "\u001b[1m 7174/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 13ms/step - accuracy: 0.8026 - loss: 0.1389Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 14ms/step - accuracy: 0.8181 - loss: 0.1297\n",
      "\u001b[1m 4901/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 14ms/step - accuracy: 0.8160 - loss: 0.1295Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7844 - loss: 0.1505\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8033 - loss: 0.1398\n",
      "\u001b[1m 3243/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 14ms/step - accuracy: 0.8120 - loss: 0.1332Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7824 - loss: 0.1539\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8133 - loss: 0.1296\n",
      "\u001b[1m  698/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.1378Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1298\n",
      "\u001b[1m 5977/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 14ms/step - accuracy: 0.8088 - loss: 0.1381Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1273\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7914 - loss: 0.1477\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7837 - loss: 0.1516\n",
      "\u001b[1m10387/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 14ms/step - accuracy: 0.8019 - loss: 0.1407Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.6587 - loss: 0.2248\n",
      "\u001b[1m 5708/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 14ms/step - accuracy: 0.7843 - loss: 0.1522Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8093 - loss: 0.1366\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.6596 - loss: 0.2245\n",
      "\u001b[1m11544/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.1403Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8022 - loss: 0.1398\n",
      "\u001b[1m12462/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.1316Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8182 - loss: 0.1263\n",
      "\u001b[1m11468/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 14ms/step - accuracy: 0.8214 - loss: 0.1234Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.1413\n",
      "\u001b[1m14268/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8134 - loss: 0.1325Epoch 13/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.1346\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 13ms/step - accuracy: 0.8099 - loss: 0.1348\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8023 - loss: 0.1396\n",
      "\u001b[1m 9432/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 14ms/step - accuracy: 0.7968 - loss: 0.1455Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8133 - loss: 0.1325\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8105 - loss: 0.1364\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.1309\n",
      "\u001b[1m13365/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.8212 - loss: 0.1235Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1315\n",
      "\u001b[1m 1830/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.1414Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8115 - loss: 0.1335\n",
      "\u001b[1m14108/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.1235Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8166 - loss: 0.1292\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8062 - loss: 0.1404\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8019 - loss: 0.1407\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.1235\n",
      "\u001b[1m  950/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 14ms/step - accuracy: 0.8157 - loss: 0.1321Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8156 - loss: 0.1266\n",
      "\u001b[1m 8758/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 14ms/step - accuracy: 0.8116 - loss: 0.1299Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8182 - loss: 0.1243\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.1378\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.1332\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7958 - loss: 0.1453\n",
      "\u001b[1m 3874/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.1416Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.1243\n",
      "\u001b[1m10684/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 14ms/step - accuracy: 0.7852 - loss: 0.1498Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1334\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1297\n",
      "\u001b[1m10882/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.1298Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8160 - loss: 0.1276\n",
      "\u001b[1m 1846/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 13ms/step - accuracy: 0.8096 - loss: 0.1372Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.7973 - loss: 0.1453\n",
      "\u001b[1m 1444/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 13ms/step - accuracy: 0.8041 - loss: 0.1392Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1310\n",
      "\u001b[1m 8745/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 13ms/step - accuracy: 0.7922 - loss: 0.1472Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1319\n",
      "\u001b[1m 6666/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1340Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7857 - loss: 0.1516\n",
      "\u001b[1m 6067/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 13ms/step - accuracy: 0.8153 - loss: 0.1301Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.1301\n",
      "\u001b[1m 7657/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 13ms/step - accuracy: 0.8114 - loss: 0.1344Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7847 - loss: 0.1500\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8035 - loss: 0.1396\n",
      "\u001b[1m 1163/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 13ms/step - accuracy: 0.8020 - loss: 0.1412Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.7826 - loss: 0.1539\n",
      "\u001b[1m 3773/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.1277Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.1297\n",
      "Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1292\n",
      "\u001b[1m 1631/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 14ms/step - accuracy: 0.7926 - loss: 0.1483Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1265\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.7922 - loss: 0.1472\n",
      "\u001b[1m 4286/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 14ms/step - accuracy: 0.7843 - loss: 0.1493Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7846 - loss: 0.1511\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2248\n",
      "\u001b[1m 6174/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.1404Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8103 - loss: 0.1359\n",
      "\u001b[1m11593/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8123 - loss: 0.1333Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6594 - loss: 0.2246\n",
      "\u001b[1m11259/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.1244Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8186 - loss: 0.1262\n",
      "\u001b[1m 7085/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 14ms/step - accuracy: 0.8159 - loss: 0.1312Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.1344\n",
      "\u001b[1m 9291/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1295Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8113 - loss: 0.1341\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7808 - loss: 0.1532\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8027 - loss: 0.1414\n",
      "\u001b[1m13433/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1304Epoch 14/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8137 - loss: 0.1328\n",
      "\u001b[1m10944/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.1233Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1367\n",
      "\u001b[1m14542/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1304Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1304\n",
      "\u001b[1m12311/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.8040 - loss: 0.1390Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8144 - loss: 0.1310\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8121 - loss: 0.1334\n",
      "\u001b[1m10139/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1313Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 0.1409\n",
      "\u001b[1m10043/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 14ms/step - accuracy: 0.8019 - loss: 0.1404Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8167 - loss: 0.1293\n",
      "\u001b[1m13653/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1324Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.1243\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8162 - loss: 0.1263\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.1248\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.1374\n",
      "\u001b[1m 8039/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1267Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1324\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.1390\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8198 - loss: 0.1234\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.1325\n",
      "\u001b[1m12285/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1313Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1278\n",
      "\u001b[1m 6529/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 13ms/step - accuracy: 0.8098 - loss: 0.1354Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7984 - loss: 0.1452\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1294\n",
      "\u001b[1m   57/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 14ms/step - accuracy: 0.7918 - loss: 0.1485Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1313\n",
      "\u001b[1m 3414/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 14ms/step - accuracy: 0.8182 - loss: 0.1246Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.1403\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1313\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7894 - loss: 0.1502\n",
      "\u001b[1m 1192/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1317Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8185 - loss: 0.1297\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7836 - loss: 0.1497\n",
      "\u001b[1m 2765/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 14ms/step - accuracy: 0.8004 - loss: 0.1444Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7833 - loss: 0.1536\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1291\n",
      "\u001b[1m 7909/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 14ms/step - accuracy: 0.8103 - loss: 0.1363Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1292\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1267\n",
      "\u001b[1m10238/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 13ms/step - accuracy: 0.8134 - loss: 0.1343 Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.7916 - loss: 0.1472\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7841 - loss: 0.1514\n",
      "\u001b[1m 7467/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 14ms/step - accuracy: 0.8003 - loss: 0.1443Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6598 - loss: 0.2245\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1357\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8114 - loss: 0.1340\n",
      "\u001b[1m10143/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 13ms/step - accuracy: 0.8189 - loss: 0.1242Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.6590 - loss: 0.2247\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1343\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8201 - loss: 0.1257\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7649 - loss: 0.1620\n",
      "\u001b[1m11902/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - accuracy: 0.8204 - loss: 0.1233Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1331\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8106 - loss: 0.1362\n",
      "\u001b[1m 6729/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 13ms/step - accuracy: 0.7846 - loss: 0.1530Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1309\n",
      "\u001b[1m 2030/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 14ms/step - accuracy: 0.6602 - loss: 0.2244Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.1308\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8113 - loss: 0.1339\n",
      "\u001b[1m 7652/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 14ms/step - accuracy: 0.8136 - loss: 0.1291Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.1415\n",
      "\u001b[1m 4582/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 13ms/step - accuracy: 0.7920 - loss: 0.1468Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8180 - loss: 0.1283\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8203 - loss: 0.1233\n",
      "\u001b[1m 1064/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.1309Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8172 - loss: 0.1255\n",
      "\u001b[1m10448/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.1321Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8175 - loss: 0.1249\n",
      "\u001b[1m10521/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 14ms/step - accuracy: 0.8138 - loss: 0.1321Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8099 - loss: 0.1374\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8045 - loss: 0.1389\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.1241\n",
      "\u001b[1m 1755/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 14ms/step - accuracy: 0.8095 - loss: 0.1350Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8134 - loss: 0.1326\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8128 - loss: 0.1325\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 14ms/step - accuracy: 0.8027 - loss: 0.1419\n",
      "Epoch 15/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8157 - loss: 0.1277\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.1310\n",
      "\u001b[1m14280/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.1319Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.1319\n",
      "\u001b[1m 4391/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 13ms/step - accuracy: 0.8173 - loss: 0.1284Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8025 - loss: 0.1402\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7889 - loss: 0.1507\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8177 - loss: 0.1299\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7828 - loss: 0.1504\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.7979 - loss: 0.1446\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.1397\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7848 - loss: 0.1530\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1287\n",
      "Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1289\n",
      "\u001b[1m 9576/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1346Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7922 - loss: 0.1467\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7839 - loss: 0.1511\n",
      "\u001b[1m 8715/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.1324Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8108 - loss: 0.1360\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6582 - loss: 0.2250\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.1342\n",
      "\u001b[1m14242/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8011 - loss: 0.1412Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8219 - loss: 0.1249\n",
      "\u001b[1m 1173/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 14ms/step - accuracy: 0.8070 - loss: 0.1382Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8131 - loss: 0.1345\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1269\n",
      "\u001b[1m 5679/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 14ms/step - accuracy: 0.8038 - loss: 0.1397Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 0.2245\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.1412\n",
      "\u001b[1m10063/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 14ms/step - accuracy: 0.8117 - loss: 0.1331Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1327\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8106 - loss: 0.1356\n",
      "\u001b[1m11600/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8054 - loss: 0.1388Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8140 - loss: 0.1303\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8158 - loss: 0.1303\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13ms/step - accuracy: 0.8115 - loss: 0.1338\n",
      "\u001b[1m13708/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.8189 - loss: 0.1241Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8050 - loss: 0.1408\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8176 - loss: 0.1284\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8190 - loss: 0.1240\n",
      "\u001b[1m 3063/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1365Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1273\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.1298\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1312\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8030 - loss: 0.1404\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8190 - loss: 0.1293\n",
      "\u001b[1m 9464/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 13ms/step - accuracy: 0.8092 - loss: 0.1363Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7989 - loss: 0.1444\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7870 - loss: 0.1511\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7847 - loss: 0.1496\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8037 - loss: 0.1397\n",
      "\u001b[1m11263/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m46s\u001b[0m 14ms/step - accuracy: 0.7927 - loss: 0.1471Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7861 - loss: 0.1524\n",
      "\u001b[1m 9167/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 14ms/step - accuracy: 0.8074 - loss: 0.1374Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 14ms/step - accuracy: 0.8034 - loss: 0.1416\n",
      "\u001b[1m 1979/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 14ms/step - accuracy: 0.8068 - loss: 0.1387Epoch 16/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1289\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.1286\n",
      "Epoch 17/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.1444\n",
      "\u001b[1m 1905/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 14ms/step - accuracy: 0.7886 - loss: 0.1487Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8093 - loss: 0.1362\n",
      "\u001b[1m13400/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.1338Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6582 - loss: 0.2250\n",
      "\u001b[1m 5243/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 13ms/step - accuracy: 0.7889 - loss: 0.1494Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.1338\n",
      "\u001b[1m 9829/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 14ms/step - accuracy: 0.8128 - loss: 0.1325Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8205 - loss: 0.1254\n",
      "\u001b[1m14142/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1321Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8067 - loss: 0.1377\n",
      "\u001b[1m 3154/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 14ms/step - accuracy: 0.8129 - loss: 0.1318Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 13ms/step - accuracy: 0.8122 - loss: 0.1337\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.6587 - loss: 0.2248\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1262\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1322\n",
      "\u001b[1m 2733/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 13ms/step - accuracy: 0.7955 - loss: 0.1459Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8126 - loss: 0.1357\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.1304\n",
      "\u001b[1m 3008/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 14ms/step - accuracy: 0.6569 - loss: 0.2254Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8110 - loss: 0.1337\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.1405\n",
      "\u001b[1m 8708/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 14ms/step - accuracy: 0.7886 - loss: 0.1497Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1302\n",
      "\u001b[1m 2480/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 14ms/step - accuracy: 0.8190 - loss: 0.1265Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8191 - loss: 0.1279\n",
      "\u001b[1m 3821/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 14ms/step - accuracy: 0.8024 - loss: 0.1416Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8215 - loss: 0.1228\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8175 - loss: 0.1250\n",
      "\u001b[1m 4740/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 14ms/step - accuracy: 0.6570 - loss: 0.2254Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8018 - loss: 0.1385\n",
      "\u001b[1m 8999/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.1400Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8102 - loss: 0.1372\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8052 - loss: 0.1387\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8201 - loss: 0.1234\n",
      "\u001b[1m 2508/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.1327Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.1324\n",
      "\u001b[1m10079/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 13ms/step - accuracy: 0.7848 - loss: 0.1529Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1317\n",
      "\u001b[1m 1189/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 14ms/step - accuracy: 0.8215 - loss: 0.1240Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.1315\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8040 - loss: 0.1394\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7988 - loss: 0.1440\n",
      "Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7887 - loss: 0.1499\n",
      "\u001b[1m 2525/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 14ms/step - accuracy: 0.8166 - loss: 0.1259Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.1295\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.7835 - loss: 0.1500\n",
      "\u001b[1m 4737/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.1256Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7849 - loss: 0.1528\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8025 - loss: 0.1398\n",
      "\u001b[1m   31/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 0.1257Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.1284\n",
      "\u001b[1m 8884/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.1327Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1444\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.1312\n",
      "\u001b[1m11561/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.1262Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7954 - loss: 0.1460\n",
      "\u001b[1m 9842/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.1305Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7840 - loss: 0.1511\n",
      "\u001b[1m12904/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1337Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8103 - loss: 0.1359\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8203 - loss: 0.1255\n",
      "\u001b[1m 6162/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 13ms/step - accuracy: 0.7871 - loss: 0.1488Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.6582 - loss: 0.2250\n",
      "\u001b[1m12299/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1305Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.1262\n",
      "\u001b[1m 5745/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 13ms/step - accuracy: 0.7855 - loss: 0.1523Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8119 - loss: 0.1337\n",
      "\u001b[1m   36/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 13ms/step - accuracy: 0.6757 - loss: 0.2192Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8133 - loss: 0.1327\n",
      "\u001b[1m 3045/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 13ms/step - accuracy: 0.7952 - loss: 0.1464Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8106 - loss: 0.1362\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1301\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8120 - loss: 0.1333\n",
      "\u001b[1m10509/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.1278Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8067 - loss: 0.1403\n",
      "\u001b[1m 1982/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1262Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1305\n",
      "\u001b[1m 3423/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.1388Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 0.1280\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8210 - loss: 0.1228\n",
      "\u001b[1m 9918/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.1439Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8160 - loss: 0.1264\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8164 - loss: 0.1253\n",
      "\u001b[1m 4734/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 14ms/step - accuracy: 0.6590 - loss: 0.2247Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8101 - loss: 0.1377\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8046 - loss: 0.1389\n",
      "\u001b[1m10663/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.1302Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8204 - loss: 0.1234\n",
      "\u001b[1m 5325/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 14ms/step - accuracy: 0.7999 - loss: 0.1422Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1317\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8122 - loss: 0.1323\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.1267\n",
      "\u001b[1m 5757/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.1337Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.1278\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.7862 - loss: 0.1493\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.7851 - loss: 0.1525\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.1289\n",
      "\u001b[1m10286/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.1335Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8005 - loss: 0.1443\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.7959 - loss: 0.1463\n",
      "\u001b[1m14550/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7847 - loss: 0.1509Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7847 - loss: 0.1509\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.8114 - loss: 0.1355\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.6590 - loss: 0.2247\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 14ms/step - accuracy: 0.8048 - loss: 0.1391\n",
      "\u001b[1m 9079/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 14ms/step - accuracy: 0.8127 - loss: 0.1327Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8017 - loss: 0.1417\n",
      "\u001b[1m13670/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.1260Epoch 18/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8141 - loss: 0.1335\n",
      "\u001b[1m 1682/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 14ms/step - accuracy: 0.8074 - loss: 0.1366Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8118 - loss: 0.1338\n",
      "\u001b[1m10687/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.1255Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8035 - loss: 0.1410\n",
      "\u001b[1m12586/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.1301Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.1283\n",
      "Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8202 - loss: 0.1253\n",
      "\u001b[1m  165/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.1300Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.1260\n",
      "\u001b[1m 1094/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 14ms/step - accuracy: 0.8091 - loss: 0.1379Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.6593 - loss: 0.2246\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 0.1288\n",
      "\u001b[1m 1055/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1291Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8212 - loss: 0.1231\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8186 - loss: 0.1242\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8172 - loss: 0.1257\n",
      "\u001b[1m 9715/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 14ms/step - accuracy: 0.8081 - loss: 0.1376Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8067 - loss: 0.1378\n",
      "\u001b[1m 4734/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 14ms/step - accuracy: 0.8019 - loss: 0.1419Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8207 - loss: 0.1231\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1325\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1319\n",
      "\u001b[1m 8979/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1443Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1272\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8166 - loss: 0.1278\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.1306\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8055 - loss: 0.1392\n",
      "\u001b[1m 3162/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 14ms/step - accuracy: 0.8189 - loss: 0.1251Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 13ms/step - accuracy: 0.7994 - loss: 0.1434\n",
      "\u001b[1m 3362/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 14ms/step - accuracy: 0.8188 - loss: 0.1251Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.1499\n",
      "Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8181 - loss: 0.1293\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7855 - loss: 0.1495\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8088 - loss: 0.1375\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.7863 - loss: 0.1525\n",
      "\u001b[1m 9713/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 13ms/step - accuracy: 0.8105 - loss: 0.1340Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7849 - loss: 0.1508\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8091 - loss: 0.1360\n",
      "\u001b[1m 1719/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 13ms/step - accuracy: 0.8005 - loss: 0.1440Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.7944 - loss: 0.1458\n",
      "\u001b[1m 3715/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 14ms/step - accuracy: 0.7876 - loss: 0.1514Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2247\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.1391\n",
      "\u001b[1m 5114/14706\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 14ms/step - accuracy: 0.7874 - loss: 0.1513Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8108 - loss: 0.1339\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8009 - loss: 0.1422\n",
      "\u001b[1m11010/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.8192 - loss: 0.1279Epoch 19/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8061 - loss: 0.1386\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8152 - loss: 0.1332\n",
      "\u001b[1m12681/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.8159 - loss: 0.1306Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1285\n",
      "\u001b[1m 9605/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 14ms/step - accuracy: 0.6588 - loss: 0.2248Epoch 20/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.1256\n",
      "\u001b[1m12386/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - accuracy: 0.8054 - loss: 0.1404Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1320\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.1355\n",
      "\u001b[1m11472/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 14ms/step - accuracy: 0.8196 - loss: 0.1234Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1307\n",
      "\u001b[1m11505/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.1326Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8123 - loss: 0.1332\n",
      "\u001b[1m10231/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.1275Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.1294\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8054 - loss: 0.1404\n",
      "\u001b[1m  903/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 13ms/step - accuracy: 0.8105 - loss: 0.1353Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8151 - loss: 0.1302\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8189 - loss: 0.1280\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8206 - loss: 0.1233\n",
      "\u001b[1m  338/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.1265Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8181 - loss: 0.1250\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8161 - loss: 0.1311\n",
      "\u001b[1m 6114/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1336Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8029 - loss: 0.1400\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.7989 - loss: 0.1437\n",
      "\u001b[1m13754/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.7853 - loss: 0.1522Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8196 - loss: 0.1290\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 14ms/step - accuracy: 0.7865 - loss: 0.1512\n",
      "Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7853 - loss: 0.1496\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7853 - loss: 0.1522\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.1286\n",
      "\u001b[1m 9509/14706\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.1251Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8003 - loss: 0.1441\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7858 - loss: 0.1502\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.1454\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13ms/step - accuracy: 0.8107 - loss: 0.1354\n",
      "\u001b[1m 7479/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 14ms/step - accuracy: 0.8162 - loss: 0.1312Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8113 - loss: 0.1353\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8119 - loss: 0.1333\n",
      "\u001b[1m 1748/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 14ms/step - accuracy: 0.8040 - loss: 0.1392Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1295\n",
      "\u001b[1m 3034/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 14ms/step - accuracy: 0.6574 - loss: 0.2252Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8062 - loss: 0.1401\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8192 - loss: 0.1277\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 0.1296\n",
      "\u001b[1m11418/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.1267Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8209 - loss: 0.1228\n",
      "\u001b[1m 2382/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.1315Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.1247\n",
      "\u001b[1m10342/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 13ms/step - accuracy: 0.7995 - loss: 0.1432Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.1255\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8048 - loss: 0.1384\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8208 - loss: 0.1230\n",
      "\u001b[1m11578/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7994 - loss: 0.1433Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.6588 - loss: 0.2248\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1260\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1313\n",
      "\u001b[1m 1688/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 14ms/step - accuracy: 0.8192 - loss: 0.1246Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8133 - loss: 0.1317\n",
      "\u001b[1m 2016/14706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 13ms/step - accuracy: 0.8187 - loss: 0.1262Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8168 - loss: 0.1268\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 14ms/step - accuracy: 0.8152 - loss: 0.1307\n",
      "Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8010 - loss: 0.1437\n",
      "\u001b[1m 9872/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.1319Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8176 - loss: 0.1269\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8105 - loss: 0.1354\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7858 - loss: 0.1504\n",
      "\u001b[1m 3329/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 14ms/step - accuracy: 0.7868 - loss: 0.1504Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.7952 - loss: 0.1457\n",
      "\u001b[1m 9992/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 13ms/step - accuracy: 0.8069 - loss: 0.1396Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8120 - loss: 0.1336\n",
      "\u001b[1m 7761/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 14ms/step - accuracy: 0.8179 - loss: 0.1248Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8112 - loss: 0.1371\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.6590 - loss: 0.2247\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.1399\n",
      "\u001b[1m 7606/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 14ms/step - accuracy: 0.8162 - loss: 0.1270Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8033 - loss: 0.1415\n",
      "\u001b[1m 3323/14706\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.1287Epoch 21/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8055 - loss: 0.1381\n",
      "\u001b[1m  973/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 13ms/step - accuracy: 0.8153 - loss: 0.1343Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8145 - loss: 0.1333\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8162 - loss: 0.1279\n",
      "\u001b[1m 1385/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 14ms/step - accuracy: 0.6648 - loss: 0.2229Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8205 - loss: 0.1251\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8146 - loss: 0.1319\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8136 - loss: 0.1326\n",
      "\u001b[1m 8601/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 13ms/step - accuracy: 0.7998 - loss: 0.1435Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8110 - loss: 0.1354\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.1298\n",
      "\u001b[1m 8498/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 0.1312Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8203 - loss: 0.1230\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.6585 - loss: 0.2249\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8160 - loss: 0.1317\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.1321\n",
      "\u001b[1m 5971/14706\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.1392Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.1252\n",
      "\u001b[1m 7796/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 13ms/step - accuracy: 0.7843 - loss: 0.1510Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8164 - loss: 0.1269\n",
      "\u001b[1m 1409/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 14ms/step - accuracy: 0.8209 - loss: 0.1222Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1314\n",
      "\u001b[1m 1337/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1313Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.1436\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 0.1311\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8047 - loss: 0.1390\n",
      "\u001b[1m11966/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.1279Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7863 - loss: 0.1506\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.7858 - loss: 0.1522\n",
      "\u001b[1m 7692/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 13ms/step - accuracy: 0.8131 - loss: 0.1330Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.7857 - loss: 0.1491\n",
      "\u001b[1m 1038/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 13ms/step - accuracy: 0.8021 - loss: 0.1409Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8157 - loss: 0.1281\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1278\n",
      "\u001b[1m12351/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.1296Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 0.1372\n",
      "\u001b[1m13467/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1318Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1332\n",
      "\u001b[1m13767/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1446Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.1410\n",
      "\u001b[1m13801/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.1446Epoch 22/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.1445\n",
      "\u001b[1m10933/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.8170 - loss: 0.1256Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8202 - loss: 0.1253\n",
      "\u001b[1m 6868/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 14ms/step - accuracy: 0.8071 - loss: 0.1384Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8144 - loss: 0.1318\n",
      "\u001b[1m 1172/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 13ms/step - accuracy: 0.8116 - loss: 0.1334Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8129 - loss: 0.1330\n",
      "\u001b[1m 6866/14706\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 14ms/step - accuracy: 0.7852 - loss: 0.1512Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.1353\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8150 - loss: 0.1295\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.1394\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.1278\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.1297\n",
      "\u001b[1m 2414/14706\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.1325Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8179 - loss: 0.1244\n",
      "\u001b[1m 3937/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 13ms/step - accuracy: 0.8092 - loss: 0.1372Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.1228\n",
      "\u001b[1m13401/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.8219 - loss: 0.1222Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8050 - loss: 0.1389\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8170 - loss: 0.1256\n",
      "\u001b[1m 8790/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.1276Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 14ms/step - accuracy: 0.8157 - loss: 0.1278\n",
      "\u001b[1m 5363/14706\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.1331Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.8218 - loss: 0.1223\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.1315\n",
      "\u001b[1m12218/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.7998 - loss: 0.1437Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.1315\n",
      "\u001b[1m10796/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.7841 - loss: 0.1497Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.6594 - loss: 0.2246\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.8165 - loss: 0.1257\n",
      "\u001b[1m 7461/14706\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 14ms/step - accuracy: 0.7978 - loss: 0.1452Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 13ms/step - accuracy: 0.8159 - loss: 0.1278\n",
      "\u001b[1m 1405/14706\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 13ms/step - accuracy: 0.7885 - loss: 0.1508Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8181 - loss: 0.1269\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13ms/step - accuracy: 0.7866 - loss: 0.1500\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.1359\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.7971 - loss: 0.1453\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8130 - loss: 0.1337\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 0.2248\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 14ms/step - accuracy: 0.8110 - loss: 0.1368\n",
      "\u001b[1m11759/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.8164 - loss: 0.1290Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8056 - loss: 0.1388\n",
      "Epoch 24/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/steptep - accuracy: 0.8176 - loss: 0.1245\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/stepstep - accuracy: 0.8075 - loss: 0.131\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.1330\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13ms/step - accuracy: 0.8077 - loss: 0.1374\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 14ms/step - accuracy: 0.8037 - loss: 0.1410\n",
      "Epoch 23/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.1446\n",
      "\u001b[1m 4129/14706\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.1274Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 13ms/step - accuracy: 0.8213 - loss: 0.1249\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 13ms/step - accuracy: 0.8140 - loss: 0.1321\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/steptep - accuracy: 0.8158 - loss: 0.1257\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/steptep - accuracy: 0.8177 - loss: 0.1237\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/stepep - accuracy: 0.8156 - loss: 0.12224\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13ms/step - accuracy: 0.8204 - loss: 0.1232\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 13ms/step - accuracy: 0.8156 - loss: 0.1282\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.8149 - loss: 0.1319\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 13ms/step - accuracy: 0.8140 - loss: 0.1318\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.6603 - loss: 0.2243\n",
      "\u001b[1m 8189/14706\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 13ms/step - accuracy: 0.7861 - loss: 0.1502Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 13ms/step - accuracy: 0.8167 - loss: 0.1255\n",
      "\u001b[1m 961/3677\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 3ms/stepEpoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/steptep - accuracy: 0.8222 - loss: 0.1220\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepstep - accuracy: 0.8186 - loss: 0.126\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/stepstep - accuracy: 0.8104 - loss: 0.130\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 12ms/step - accuracy: 0.7985 - loss: 0.1443\n",
      "\u001b[1m  415/14706\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 11ms/step - accuracy: 0.6605 - loss: 0.2242Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 12ms/step - accuracy: 0.8171 - loss: 0.1305\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 12ms/step - accuracy: 0.8221 - loss: 0.1223\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 12ms/step - accuracy: 0.8041 - loss: 0.1394\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 12ms/step - accuracy: 0.7866 - loss: 0.1520\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 12ms/step - accuracy: 0.7865 - loss: 0.1503\n",
      "\u001b[1m10047/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 11ms/step - accuracy: 0.8094 - loss: 0.1373Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepstep - accuracy: 0.6611 - loss: 0.225\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 12ms/step - accuracy: 0.7866 - loss: 0.1489\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/stepstep - accuracy: 0.8185 - loss: 0.122\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8051 - loss: 0.1427\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12ms/step - accuracy: 0.8168 - loss: 0.1276\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepstep - accuracy: 0.8171 - loss: 0.127\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.1306\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 12ms/step - accuracy: 0.8176 - loss: 0.1273\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 12ms/step - accuracy: 0.8168 - loss: 0.1268\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/steptep - accuracy: 0.8245 - loss: 0.122\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 11ms/step - accuracy: 0.7860 - loss: 0.1503\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepstep - accuracy: 0.8073 - loss: 0.135\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 11ms/step - accuracy: 0.7973 - loss: 0.1455\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/stepstep - accuracy: 0.8167 - loss: 0.127\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/steptep - accuracy: 0.8241 - loss: 0.1224\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/stepstep - accuracy: 0.6603 - loss: 0.227\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 11ms/step - accuracy: 0.8095 - loss: 0.1373\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 11ms/step - accuracy: 0.6588 - loss: 0.2248\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 10ms/step - accuracy: 0.8048 - loss: 0.1384\n",
      "Epoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10ms/step - accuracy: 0.8045 - loss: 0.1409\n",
      "Epoch 24/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9ms/step - accuracy: 0.8197 - loss: 0.1287\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 9ms/step - accuracy: 0.8184 - loss: 0.1277\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9ms/step - accuracy: 0.8067 - loss: 0.1377\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/stepstep - accuracy: 0.8052 - loss: 0.138\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 9ms/step - accuracy: 0.8172 - loss: 0.1257\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/steptep - accuracy: 0.7855 - loss: 0.1538\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/steptep - accuracy: 0.6597 - loss: 0.2242\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 9ms/step - accuracy: 0.8175 - loss: 0.1252\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/stepstep - accuracy: 0.8054 - loss: 0.138\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 9ms/step - accuracy: 0.8156 - loss: 0.1279\n",
      "\u001b[1m1415/3677\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2ms/stepEpoch 25/25\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 8ms/step - accuracy: 0.7992 - loss: 0.1436\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/stepep - accuracy: 0.6597 - loss: 0.22326\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 8ms/step - accuracy: 0.6597 - loss: 0.2245\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/stepstep - accuracy: 0.8182 - loss: 0.126\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/steptep - accuracy: 0.8054 - loss: 0.1326\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7ms/step - accuracy: 0.8227 - loss: 0.1223\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 7ms/step - accuracy: 0.8163 - loss: 0.1302\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/stepep - accuracy: 0.7860 - loss: 0.15427\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 7ms/step - accuracy: 0.7860 - loss: 0.1507\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/steptep - accuracy: 0.8172 - loss: 0.12\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/stepep - accuracy: 0.8028 - loss: 0.142\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.1387\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - accuracy: 0.8028 - loss: 0.1417\n",
      "Epoch 25/25\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/stepstep - accuracy: 0.8002 - loss: 0.14\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 6ms/step - accuracy: 0.8164 - loss: 0.1276\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/steptep - accuracy: 0.8032 - loss: 0.140\n",
      "\u001b[1m14706/14706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 6ms/step - accuracy: 0.8033 - loss: 0.1410\n",
      "\u001b[1m3677/3677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.6845 - loss: 0.2108\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6ms/step - accuracy: 0.7974 - loss: 0.1414\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 0.1366\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 0.1342\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7ms/step - accuracy: 0.8106 - loss: 0.1326\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7ms/step - accuracy: 0.8111 - loss: 0.1319\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.1313\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8132 - loss: 0.1309\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7ms/step - accuracy: 0.8124 - loss: 0.1311\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 7ms/step - accuracy: 0.8149 - loss: 0.1301\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.1303\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - accuracy: 0.8162 - loss: 0.1295\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 0.1289\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - accuracy: 0.8161 - loss: 0.1293\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - accuracy: 0.8165 - loss: 0.1293\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8168 - loss: 0.1289\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8168 - loss: 0.1288\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.1292\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 7ms/step - accuracy: 0.8173 - loss: 0.1290\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 0.1289\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - accuracy: 0.8165 - loss: 0.1289\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7ms/step - accuracy: 0.8170 - loss: 0.1288\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8170 - loss: 0.1288\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8170 - loss: 0.1290\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7ms/step - accuracy: 0.8173 - loss: 0.1287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_rnn_model(dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=10, input_shape=(34, 1)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1))  # Regression output\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create Keras classifier\n",
    "model = KerasClassifier(model=create_rnn_model, epochs = 25, batch_size = 32)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "dropout = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "param_grid = dict(model__dropout_rate=dropout)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs = -1)\n",
    "grid_result = grid_search.fit(X_train_rnn, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777012b-920b-438c-8e39-1af06c88248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.816755 using {'model__dropout_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1aa3387-a68e-4f13-ae78-f913e36af132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNNLAY(layers):\n",
    "    RNN = Sequential()\n",
    "    if layers == 1:\n",
    "        RNN.add(LSTM(units = 10, input_shape = (34, 1))) \n",
    "        RNN.add(Dropout(0.2))\n",
    "    if layers == 2:\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10))\n",
    "        RNN.add(Dropout(0.2))\n",
    "    if layers == 3:\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True, input_shape = (34, 1)))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10))\n",
    "        RNN.add(Dropout(0.2))\n",
    "    elif layers == 4:\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True, input_shape = (34, 1)))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10, return_sequences = True))\n",
    "        RNN.add(Dropout(0.2))\n",
    "        RNN.add(LSTM(units = 10))\n",
    "        RNN.add(Dropout(0.2))\n",
    "    \n",
    "    RNN.add(Dense(units = 1))\n",
    "    \n",
    "    RNN.compile(optimizer= 'adam', loss = 'mean_squared_error',  metrics=['accuracy'])\n",
    "    \n",
    "    history = RNN.fit(X_train_rnn, y_train, epochs = 25, batch_size = 32) # train\n",
    "    \n",
    "    preds = RNN.predict(X_test) \n",
    "    \n",
    "    # find best cut off point of probability for 0 or 1\n",
    "    def OptimalCutoff(pred): # since NN predictions are probabilities we have to find the best cut off point to make those hard predictions\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "        i = np.arange(len(tpr)) # index for df\n",
    "        roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "        roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "            \n",
    "        return list(roc_t['thresholds'])\n",
    "    \n",
    "    c = OptimalCutoff(preds)\n",
    "    \n",
    "    y_pred = np.zeros(len(preds))\n",
    "    for i in range(len(preds)):\n",
    "        if preds[[i]][0][0] >= c:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "            \n",
    "\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return RMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2cba2cc-6dad-4c4a-8315-0825e0ce1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.1842\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7ms/step - accuracy: 0.7971 - loss: 0.1423\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 7ms/step - accuracy: 0.8034 - loss: 0.1372\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7ms/step - accuracy: 0.8090 - loss: 0.1342\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.1330\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7ms/step - accuracy: 0.8115 - loss: 0.1321\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.1315\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7ms/step - accuracy: 0.8144 - loss: 0.1308\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.1307\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.1303\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7ms/step - accuracy: 0.8147 - loss: 0.1305\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.1301\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.1301\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8159 - loss: 0.1294\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.1287\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.1286\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.1290\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7ms/step - accuracy: 0.8161 - loss: 0.1288\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8162 - loss: 0.1288\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7ms/step - accuracy: 0.8174 - loss: 0.1280\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.1283\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6ms/step - accuracy: 0.8172 - loss: 0.1284\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.1278\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.1281\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.1283\n",
      "\u001b[1m1127/1127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 13ms/step - accuracy: 0.7564 - loss: 0.1660\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 13ms/step - accuracy: 0.8051 - loss: 0.1353\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 13ms/step - accuracy: 0.8093 - loss: 0.1322\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 12ms/step - accuracy: 0.8118 - loss: 0.1306\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 13ms/step - accuracy: 0.8137 - loss: 0.1295\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 13ms/step - accuracy: 0.8145 - loss: 0.1294\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 13ms/step - accuracy: 0.8160 - loss: 0.1283\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 13ms/step - accuracy: 0.8169 - loss: 0.1278\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 12ms/step - accuracy: 0.8156 - loss: 0.1283\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 13ms/step - accuracy: 0.8170 - loss: 0.1276\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 13ms/step - accuracy: 0.8172 - loss: 0.1278\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 13ms/step - accuracy: 0.8174 - loss: 0.1274\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 13ms/step - accuracy: 0.8172 - loss: 0.1275\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 13ms/step - accuracy: 0.8169 - loss: 0.1273\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 13ms/step - accuracy: 0.8180 - loss: 0.1268\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 13ms/step - accuracy: 0.8178 - loss: 0.1270\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 13ms/step - accuracy: 0.8181 - loss: 0.1271\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 13ms/step - accuracy: 0.8179 - loss: 0.1268\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 13ms/step - accuracy: 0.8171 - loss: 0.1273\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 13ms/step - accuracy: 0.8186 - loss: 0.1268\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 13ms/step - accuracy: 0.8174 - loss: 0.1270\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 13ms/step - accuracy: 0.8189 - loss: 0.1264\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 0.1264\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 13ms/step - accuracy: 0.8193 - loss: 0.1259\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 13ms/step - accuracy: 0.8191 - loss: 0.1263\n",
      "\u001b[1m1127/1127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 19ms/step - accuracy: 0.7495 - loss: 0.1724\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 19ms/step - accuracy: 0.8047 - loss: 0.1366\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 19ms/step - accuracy: 0.8069 - loss: 0.1343\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 20ms/step - accuracy: 0.8116 - loss: 0.1311\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 19ms/step - accuracy: 0.8128 - loss: 0.1305\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 20ms/step - accuracy: 0.8139 - loss: 0.1292\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 20ms/step - accuracy: 0.8143 - loss: 0.1291\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 20ms/step - accuracy: 0.8150 - loss: 0.1287\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 20ms/step - accuracy: 0.8172 - loss: 0.1276\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 20ms/step - accuracy: 0.8171 - loss: 0.1277\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 19ms/step - accuracy: 0.8172 - loss: 0.1275\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 20ms/step - accuracy: 0.8173 - loss: 0.1277\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 20ms/step - accuracy: 0.8175 - loss: 0.1274\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 20ms/step - accuracy: 0.8188 - loss: 0.1268\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 20ms/step - accuracy: 0.8191 - loss: 0.1265\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.1275\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 19ms/step - accuracy: 0.8178 - loss: 0.1271\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 19ms/step - accuracy: 0.8189 - loss: 0.1265\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 19ms/step - accuracy: 0.8175 - loss: 0.1270\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 20ms/step - accuracy: 0.8181 - loss: 0.1268\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 19ms/step - accuracy: 0.8186 - loss: 0.1267\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 20ms/step - accuracy: 0.8190 - loss: 0.1265\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 19ms/step - accuracy: 0.8188 - loss: 0.1264\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 19ms/step - accuracy: 0.8184 - loss: 0.1266\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 19ms/step - accuracy: 0.8177 - loss: 0.1268\n",
      "\u001b[1m1127/1127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 26ms/step - accuracy: 0.7377 - loss: 0.1765\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 27ms/step - accuracy: 0.8017 - loss: 0.1381\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 27ms/step - accuracy: 0.8091 - loss: 0.1325\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 26ms/step - accuracy: 0.8123 - loss: 0.1307\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 26ms/step - accuracy: 0.8137 - loss: 0.1294\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 27ms/step - accuracy: 0.8148 - loss: 0.1292\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 27ms/step - accuracy: 0.8156 - loss: 0.1286\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 27ms/step - accuracy: 0.8163 - loss: 0.1283\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 27ms/step - accuracy: 0.8158 - loss: 0.1285\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 26ms/step - accuracy: 0.8163 - loss: 0.1281\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 27ms/step - accuracy: 0.8176 - loss: 0.1275\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 26ms/step - accuracy: 0.8165 - loss: 0.1275\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 27ms/step - accuracy: 0.8162 - loss: 0.1279\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 26ms/step - accuracy: 0.8180 - loss: 0.1271\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 26ms/step - accuracy: 0.8174 - loss: 0.1271\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 27ms/step - accuracy: 0.8180 - loss: 0.1270\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 26ms/step - accuracy: 0.8172 - loss: 0.1272\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 26ms/step - accuracy: 0.8183 - loss: 0.1271\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 26ms/step - accuracy: 0.8184 - loss: 0.1268\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 26ms/step - accuracy: 0.8185 - loss: 0.1266\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 27ms/step - accuracy: 0.8177 - loss: 0.1270\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 26ms/step - accuracy: 0.8184 - loss: 0.1268\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 26ms/step - accuracy: 0.8188 - loss: 0.1264\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 27ms/step - accuracy: 0.8186 - loss: 0.1267\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 27ms/step - accuracy: 0.8193 - loss: 0.1263\n",
      "\u001b[1m1127/1127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "one = RNNLAY(1)\n",
    "two = RNNLAY(2)\n",
    "three = RNNLAY(3)\n",
    "four = RNNLAY(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "721f8e9c-2aae-4206-b117-f860c7bbcb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list([one, two, three, four])\n",
    "m = min(l)\n",
    "m\n",
    "l.index(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f9da6a4-df8c-4698-8b3f-832fbb49be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40082144285603294,\n",
       " 0.3983227913293522,\n",
       " 0.39752130115104833,\n",
       " 0.3989836775223776]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "046c514f-944b-431b-b7ac-b4f0848c0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 20ms/step - accuracy: 0.7488 - loss: 0.1701\n",
      "Epoch 2/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 20ms/step - accuracy: 0.8061 - loss: 0.1343\n",
      "Epoch 3/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 20ms/step - accuracy: 0.8099 - loss: 0.1319\n",
      "Epoch 4/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 20ms/step - accuracy: 0.8122 - loss: 0.1302\n",
      "Epoch 5/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 20ms/step - accuracy: 0.8134 - loss: 0.1295\n",
      "Epoch 6/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 20ms/step - accuracy: 0.8155 - loss: 0.1286\n",
      "Epoch 7/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 20ms/step - accuracy: 0.8163 - loss: 0.1281\n",
      "Epoch 8/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 20ms/step - accuracy: 0.8163 - loss: 0.1281\n",
      "Epoch 9/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 20ms/step - accuracy: 0.8160 - loss: 0.1284\n",
      "Epoch 10/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 20ms/step - accuracy: 0.8165 - loss: 0.1278\n",
      "Epoch 11/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 20ms/step - accuracy: 0.8172 - loss: 0.1276\n",
      "Epoch 12/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 20ms/step - accuracy: 0.8178 - loss: 0.1275\n",
      "Epoch 13/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 20ms/step - accuracy: 0.8178 - loss: 0.1271\n",
      "Epoch 14/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 20ms/step - accuracy: 0.8181 - loss: 0.1269\n",
      "Epoch 15/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 21ms/step - accuracy: 0.8181 - loss: 0.1266\n",
      "Epoch 16/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 21ms/step - accuracy: 0.8181 - loss: 0.1271\n",
      "Epoch 17/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 20ms/step - accuracy: 0.8186 - loss: 0.1264\n",
      "Epoch 18/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 20ms/step - accuracy: 0.8190 - loss: 0.1262\n",
      "Epoch 19/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 20ms/step - accuracy: 0.8180 - loss: 0.1264\n",
      "Epoch 20/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.1268\n",
      "Epoch 21/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 20ms/step - accuracy: 0.8182 - loss: 0.1264\n",
      "Epoch 22/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 20ms/step - accuracy: 0.8189 - loss: 0.1262\n",
      "Epoch 23/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 20ms/step - accuracy: 0.8195 - loss: 0.1258\n",
      "Epoch 24/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 20ms/step - accuracy: 0.8197 - loss: 0.1258\n",
      "Epoch 25/25\n",
      "\u001b[1m18383/18383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 21ms/step - accuracy: 0.8187 - loss: 0.1263\n",
      "\u001b[1m1127/1127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9195104315558799"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_rnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1) # reshape train data to 3 dim input\n",
    "\n",
    "RNN = Sequential()\n",
    "        \n",
    "RNN.add(LSTM(units = 10, return_sequences = True, input_shape = (34, 1))) \n",
    "RNN.add(Dropout(0.2))\n",
    "\n",
    "RNN.add(LSTM(units = 10, return_sequences=True))\n",
    "RNN.add(Dropout(0.2))\n",
    "\n",
    "RNN.add(LSTM(units = 10))\n",
    "RNN.add(Dropout(0.2))\n",
    "\n",
    "RNN.add(Dense(units = 1))\n",
    "\n",
    "RNN.compile(optimizer= 'adam', loss = 'mean_squared_error',  metrics=['accuracy'])\n",
    "\n",
    "history = RNN.fit(X_train_rnn, y_train, epochs = 25, batch_size = 32) # train\n",
    "\n",
    "preds = RNN.predict(X_test) \n",
    "preds\n",
    "\n",
    "\n",
    "ppdevrnn = pd.DataFrame(preds)\n",
    "# ppdevrnn.to_excel(\"PredictedProbabilitiesDevRNN.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# find best cut off point of probability for 0 or 1\n",
    "def OptimalCutoff(pred): # since NN predictions are probabilities we have to find the best cut off point to make those hard predictions\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "    i = np.arange(len(tpr)) # index for df\n",
    "    roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "        \n",
    "    return list(roc_t['thresholds'])\n",
    "\n",
    "c = OptimalCutoff(preds)\n",
    "\n",
    "y_pred = np.zeros(len(preds))\n",
    "for i in range(len(preds)):\n",
    "    if preds[[i]][0][0] >= c:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "        \n",
    "# Validation\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "def misclassificationrate(cm):\n",
    "    error = cm[0,1] + cm[1,0]\n",
    "    total = cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1]\n",
    "    mr = error / total * 100\n",
    "    return round(mr, 2)\n",
    "    \n",
    "def Sensitivity(cm):\n",
    "    sen = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    return sen\n",
    "    \n",
    "def Specificity(cm):\n",
    "    spe = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    return spe\n",
    "    \n",
    "mr = misclassificationrate(cm)\n",
    "sen = Sensitivity(cm)\n",
    "spe = Specificity(cm)\n",
    "mr\n",
    "sen\n",
    "spe\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, preds[:,0][:][:][:])\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a678f73a-b389-47e8-8ac4-a59a0cb45894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  preds[:,0][:][:][:])\n",
    "plt.plot(fpr,tpr,label=\"FIES data, auc=\"+str(auc))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e7fcc59-2dda-4ddf-af11-65102cb2292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9195104315558799\n",
      "Accuracy: 0.8401741638471352\n",
      "Sensitivity 0.8402906878485719\n",
      "Specificity 0.8401512889419728\n",
      "Precision: 0.9640246687985381\n",
      "Recall: 0.8401512889419728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('AUC', auc)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Sensitivity\", sen)\n",
    "print('Specificity', spe)\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b497e9fc-f954-47f4-ab28-5db454d0a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = B.drop(columns=['eDWID'])\n",
    "# Use set B for external cross validation\n",
    "XB = B.loc[:, B.columns != 'FIES']\n",
    "yB = B['FIES']\n",
    "\n",
    "\n",
    "# Cross validation on set Bs predictions vs the true values in set B\n",
    "def CrossValExt(pred):        \n",
    "    cm = metrics.confusion_matrix(yB, pred)\n",
    "    auc = metrics.roc_auc_score(yB, pred)\n",
    "    sen = Sensitivity(cm)\n",
    "    spe = Specificity(cm)\n",
    "    \n",
    "    # ROC Curve plot\n",
    "    fig, ax = plt.subplots()\n",
    "    fpr, tpr, _ = metrics.roc_curve(yB,  pred)\n",
    "    plt.plot(fpr,tpr,label=\"FIES data, auc=\"+str(auc))\n",
    "    plt.xlabel('1-Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    print('AUC', auc)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(yB, pred))\n",
    "    print(\"Sensitivity\", sen)\n",
    "    print('Specificity', spe)\n",
    "    print(\"Precision:\",metrics.precision_score(yB, pred))\n",
    "    print(\"Recall:\",metrics.recall_score(yB, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "150fd584-01d0-4f2c-bbe0-7329818e5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4874/4874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.8102189453117803\n",
      "Accuracy: 0.8102178080698628\n",
      "Sensitivity 0.8102222569430881\n",
      "Specificity 0.8102156336804727\n",
      "Precision: 0.8972789547126728\n",
      "Recall: 0.8102156336804727\n"
     ]
    }
   ],
   "source": [
    "yre = RNN.predict(XB)\n",
    "\n",
    "def OptimalCutoffANN(pred): # since NN predictions are probabilities we have to find the best cut off point to make those hard predictions\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yB, pred)\n",
    "    i = np.arange(len(tpr)) # index for df\n",
    "    roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "        \n",
    "    return list(roc_t['thresholds'])\n",
    "\n",
    "d = OptimalCutoffANN(yre[:,0])\n",
    "\n",
    "y_pred_r = np.zeros(len(yre[:,0]))\n",
    "for i in range(len(yre[:,0])):\n",
    "    if yre[:,0][i] >= d: # may have to adjust value based on above threshold value\n",
    "        y_pred_r[i] = 1\n",
    "    else:\n",
    "        y_pred_r[i] = 0\n",
    "        \n",
    "CrossValExt(y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c5fba3f-e46d-416a-8279-48276bd2b038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def CrossValExt(pred):        \n",
    "    cm = metrics.confusion_matrix(yB, pred)\n",
    "    auc = metrics.roc_auc_score(yB, pred)\n",
    "    sen = Sensitivity(cm)\n",
    "    spe = Specificity(cm)\n",
    "    \n",
    "    # ROC Curve plot\n",
    "    fig, ax = plt.subplots()\n",
    "    fpr, tpr, _ = metrics.roc_curve(yB,  pred)\n",
    "    plt.plot(fpr,tpr,label=\"FIES data, auc=\"+str(auc))\n",
    "    plt.xlabel('1-Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "CrossValExt(y_pred_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
